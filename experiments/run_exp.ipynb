{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_exp.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KB0bqRI-3h6B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611209520628,"user_tz":360,"elapsed":64655,"user":{"displayName":"E Yang","photoUrl":"","userId":"00321264058976725553"}},"outputId":"ea4c94be-d34b-491d-8e8a-4f40c7b12610"},"source":["from google.colab import drive\n","drive.mount('/ME')\n","predir='/ME/My Drive/'\n","\n","import sys\n","datadirs=predir+'Colab Notebooks/LLFA/'\n","sys.path.insert(1, datadirs)\n","\n","savepath = datadirs+'save/'\n","datapath = datadirs+'data/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /ME\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6GEsesMf3uCt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611209527653,"user_tz":360,"elapsed":4373,"user":{"displayName":"E Yang","photoUrl":"","userId":"00321264058976725553"}},"outputId":"0ced13d7-2857-4ff4-d36f-44f736c72349"},"source":["import torch\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aZqKcbU-4dK7"},"source":["## Set-up"]},{"cell_type":"code","metadata":{"id":"1BUwdwerYhXE"},"source":["class PARS:\n","    def __init__(self, device, datapath, savepath, dataset = 'Cifar10', architecture = 'CONV', \n","                 num_channel = 64, process='E2E', update='BP', optimizer='SGD', loss='CE', \n","                 nonlinear='hardtanh', lr=0.1, epochs=100, batchsize=500, \n","                 repeat = 5, loadnet=None):\n","        self.dataset = dataset # 'Cifar10', 'Cifar100'\n","        self.architecture = architecture # 'LW', 'CONV'\n","        self.NUM_CHANNEL = num_channel # for 'LW'\n","        self.process = process # 'E2E', 'GLL', 'RLL'\n","        self.update = update # 'BP', 'FA', 'UF', 'US'\n","        self.OPT = optimizer # 'SGD', 'Adam', Only SGD with RLL\n","        self.loss = loss # 'CE', 'Hinge'\n","        self.nonlinear = nonlinear # 'hartanh','tanh'\n","        self.LR = lr\n","        self.epochs = epochs # Epochs per layer\n","        self.batch_size = batchsize\n","        self.repeat = repeat\n","        self.device = device\n","        self.datapath = datapath\n","        self.savepath = savepath\n","        self.loadnet = loadnet\n","    \n","    def __str__(self):\n","        res = \"\"\n","        for key, val in self.__dict__.items():\n","            if key != 'loadnet':\n","                res += \"{}: {}\\n\".format(key, val)\n","            else:\n","                res += \"{}: {}\\n\".format(key, val.keys() if val else val)\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAysQACKuQoM"},"source":["from utils import *\n","from setup_net import setup_net\n","import os\n","\n","def main(pars):\n","    print(pars)\n","    expdir = pars.savepath+pars.architecture+\"/\"+pars.loss+\"/\"\n","    if not os.path.exists(expdir):\n","        os.makedirs(expdir)\n","    EXP_NAME = 'epoch_{}_{}_{}_{}_LR_{}_Epochs_{}'.format(pars.process, pars.update, pars.OPT, pars.nonlinear, pars.LR, pars.epochs)\n","\n","    if pars.loss == 'Hinge':\n","        pars.criterion = HingeLoss(pars.device)\n","    else:\n","        pars.criterion = torch.nn.CrossEntropyLoss()\n","\n","    dtype = torch.float32\n","    data = get_data(pars.datapath, pars.dataset, num_train=45000)\n","    \n","    test_acc_all = []\n","    netDict = []\n","    for rep in range(pars.repeat):\n","        print(\"\\nRep {}\".format(rep+1))\n","\n","        net, classifier = setup_net(pars)\n","        if pars.loadnet:\n","            net.load_state_dict(pars.loadnet)\n","        print(net)\n","        print(classifier)\n","      \n","        val_loss = []\n","        val_acc = []\n","        lw_test_acc = []\n","        \n","        if pars.process == 'RLL':\n","            train_model_rand(data, net, classifier, pars, val_loss, val_acc)\n","            lw_test_acc = check_accuracy_rand(data[4], data[5], net, classifier, pars)\n","            print('Rep: {}, te.acc = {}'.format(rep+1, [round(x,4) for x in lw_test_acc]))    \n","        elif pars.process == 'GLL':\n","            for i in range(pars.NUM_LAYER):\n","                print('LAYER:%d'%i)\n","                fix = net[:i]\n","                print(fix)\n","                model = nn.Sequential(\n","                    net[i],\n","                    classifier[i]\n","                )            \n","                print(model)\n","                 \n","                train_model(data, fix, model, pars, val_loss, val_acc)\n","                test_acc = check_accuracy(data[4], data[5], fix, model, pars) \n","                print('Rep: %d, Layer: %d, te.acc = %.4f' % (rep+1, i, test_acc))\n","                lw_test_acc.append(test_acc)\n","                print()\n","        else: # 'E2E'\n","            train_model(data, net, classifier, pars, val_loss, val_acc)\n","            test_acc = check_accuracy(data[4], data[5], net, classifier, pars)\n","            print('Rep: %d, te.acc = %.4f' % (rep+1, test_acc))\n","            lw_test_acc.append(test_acc)\n","        \n","        np.save(expdir+'loss_rep_{}_'.format(rep+1) + EXP_NAME, val_loss)\n","        np.save(expdir+'val.acc_rep_{}_'.format(rep+1) + EXP_NAME, val_acc)\n","        np.save(expdir+'te.acc_rep_{}_'.format(rep+1) + EXP_NAME, lw_test_acc) \n","                \n","        test_acc_all.append(lw_test_acc)\n","        netDict.append(net.state_dict())\n","\n","    print('\\nAll reps test.acc:')\n","    for acc in test_acc_all:\n","        print(acc)\n","    np.save(expdir+'te.acc.all_' + EXP_NAME, test_acc_all)\n","\n","    return netDict"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V7xZox1al7I5"},"source":["# CONV - GLL - BP - LR_0.05"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfu2wUlMl7I6","executionInfo":{"status":"ok","timestamp":1606893082655,"user_tz":360,"elapsed":1296,"user":{"displayName":"E Yang","photoUrl":"","userId":"00321264058976725553"}},"outputId":"1e7c6816-adbb-4f46-8720-19ef6dff888e"},"source":["pars = PARS(device, datapath, savepath)\n","pars.process = 'GLL'\n","pars.LR = 0.05\n","print(pars)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["architecture: CONV\n","process: GLL\n","update: BP\n","OPT: SGD\n","loss: CE\n","nonlinear: hardtanh\n","LR: 0.05\n","epochs: 100\n","batch_size: 500\n","repeat: 5\n","device: cuda:0\n","datapath: /ME/My Drive/Colab Notebooks/LLFA/data/\n","savepath: /ME/My Drive/Colab Notebooks/LLFA/save/\n","cuDNN: False\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9eJVE-k0uyAj","executionInfo":{"status":"ok","timestamp":1606895899917,"user_tz":360,"elapsed":2815810,"user":{"displayName":"E Yang","photoUrl":"","userId":"00321264058976725553"}},"outputId":"498cbf80-3603-498a-b5cf-6870e839ddaa"},"source":["main(pars)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["architecture: CONV\n","process: GLL\n","update: BP\n","OPT: SGD\n","loss: CE\n","nonlinear: hardtanh\n","LR: 0.05\n","epochs: 100\n","batch_size: 500\n","repeat: 5\n","device: cuda:0\n","datapath: /ME/My Drive/Colab Notebooks/LLFA/data/\n","savepath: /ME/My Drive/Colab Notebooks/LLFA/save/\n","cuDNN: False\n","\n","Files already downloaded and verified\n","Files already downloaded and verified\n","\n","Rep 1\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","LAYER:0\n","Sequential()\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.7911, val.acc = 0.4268\n","Epoch 1, loss = 1.5977, val.acc = 0.4512\n","Epoch 2, loss = 1.5037, val.acc = 0.4742\n","Epoch 3, loss = 1.4187, val.acc = 0.5020\n","Epoch 4, loss = 1.3568, val.acc = 0.5202\n","Epoch 5, loss = 1.3115, val.acc = 0.5316\n","Epoch 6, loss = 1.2711, val.acc = 0.5444\n","Epoch 7, loss = 1.2359, val.acc = 0.5500\n","Epoch 8, loss = 1.2055, val.acc = 0.5598\n","Epoch 9, loss = 1.1801, val.acc = 0.5656\n","Epoch 10, loss = 1.1558, val.acc = 0.5720\n","Epoch 11, loss = 1.1307, val.acc = 0.5810\n","Epoch 12, loss = 1.1081, val.acc = 0.5890\n","Epoch 13, loss = 1.0866, val.acc = 0.5968\n","Epoch 14, loss = 1.0666, val.acc = 0.6030\n","Epoch 15, loss = 1.0477, val.acc = 0.6062\n","Epoch 16, loss = 1.0300, val.acc = 0.6114\n","Epoch 17, loss = 1.0139, val.acc = 0.6136\n","Epoch 18, loss = 0.9956, val.acc = 0.5804\n","Epoch 19, loss = 0.9871, val.acc = 0.6184\n","Epoch 20, loss = 0.9689, val.acc = 0.6216\n","Epoch 21, loss = 0.9600, val.acc = 0.6288\n","Epoch 22, loss = 0.9485, val.acc = 0.6104\n","Epoch 23, loss = 0.9336, val.acc = 0.6328\n","Epoch 24, loss = 0.9231, val.acc = 0.6348\n","Epoch 25, loss = 0.9089, val.acc = 0.6254\n","Epoch 26, loss = 0.9039, val.acc = 0.6306\n","Epoch 27, loss = 0.8853, val.acc = 0.6328\n","Epoch 28, loss = 0.8937, val.acc = 0.6204\n","Epoch 29, loss = 0.8696, val.acc = 0.6374\n","Epoch 30, loss = 0.8654, val.acc = 0.6206\n","Epoch 31, loss = 0.8516, val.acc = 0.6350\n","Epoch 32, loss = 0.8469, val.acc = 0.6430\n","Epoch 33, loss = 0.8417, val.acc = 0.6328\n","Epoch 34, loss = 0.8263, val.acc = 0.6434\n","Epoch 35, loss = 0.8199, val.acc = 0.6428\n","Epoch 36, loss = 0.8155, val.acc = 0.6340\n","Epoch 37, loss = 0.8007, val.acc = 0.6378\n","Epoch 38, loss = 0.7995, val.acc = 0.6476\n","Epoch 39, loss = 0.7895, val.acc = 0.6272\n","Epoch 40, loss = 0.7800, val.acc = 0.6494\n","Epoch 41, loss = 0.7771, val.acc = 0.6484\n","Epoch 42, loss = 0.7666, val.acc = 0.6482\n","Epoch 43, loss = 0.7548, val.acc = 0.6460\n","Epoch 44, loss = 0.7593, val.acc = 0.6274\n","Epoch 45, loss = 0.7477, val.acc = 0.6478\n","Epoch 46, loss = 0.7395, val.acc = 0.6516\n","Epoch 47, loss = 0.7370, val.acc = 0.6480\n","Epoch 48, loss = 0.7233, val.acc = 0.6318\n","Epoch 49, loss = 0.7188, val.acc = 0.6520\n","Epoch 50, loss = 0.7201, val.acc = 0.6340\n","Epoch 51, loss = 0.7062, val.acc = 0.6452\n","Epoch 52, loss = 0.7085, val.acc = 0.6482\n","Epoch 53, loss = 0.6949, val.acc = 0.6478\n","Epoch 54, loss = 0.6952, val.acc = 0.6412\n","Epoch 55, loss = 0.6834, val.acc = 0.6452\n","Epoch 56, loss = 0.6827, val.acc = 0.6482\n","Epoch 57, loss = 0.6784, val.acc = 0.6426\n","Epoch 58, loss = 0.6680, val.acc = 0.6466\n","Epoch 59, loss = 0.6666, val.acc = 0.6524\n","Epoch 60, loss = 0.6572, val.acc = 0.6482\n","Epoch 61, loss = 0.6594, val.acc = 0.6514\n","Epoch 62, loss = 0.6512, val.acc = 0.6540\n","Epoch 63, loss = 0.6368, val.acc = 0.6552\n","Epoch 64, loss = 0.6355, val.acc = 0.6380\n","Epoch 65, loss = 0.6422, val.acc = 0.6546\n","Epoch 66, loss = 0.6294, val.acc = 0.6476\n","Epoch 67, loss = 0.6240, val.acc = 0.6498\n","Epoch 68, loss = 0.6180, val.acc = 0.6360\n","Epoch 69, loss = 0.6169, val.acc = 0.6562\n","Epoch 70, loss = 0.6099, val.acc = 0.6420\n","Epoch 71, loss = 0.6062, val.acc = 0.6552\n","Epoch 72, loss = 0.6064, val.acc = 0.6414\n","Epoch 73, loss = 0.5925, val.acc = 0.6502\n","Epoch 74, loss = 0.5964, val.acc = 0.6422\n","Epoch 75, loss = 0.5879, val.acc = 0.6550\n","Epoch 76, loss = 0.5787, val.acc = 0.6370\n","Epoch 77, loss = 0.5803, val.acc = 0.6540\n","Epoch 78, loss = 0.5839, val.acc = 0.6434\n","Epoch 79, loss = 0.5701, val.acc = 0.6532\n","Epoch 80, loss = 0.5679, val.acc = 0.6404\n","Epoch 81, loss = 0.5618, val.acc = 0.6552\n","Epoch 82, loss = 0.5604, val.acc = 0.6388\n","Epoch 83, loss = 0.5510, val.acc = 0.6526\n","Epoch 84, loss = 0.5603, val.acc = 0.6394\n","Epoch 85, loss = 0.5447, val.acc = 0.6542\n","Epoch 86, loss = 0.5454, val.acc = 0.6368\n","Epoch 87, loss = 0.5415, val.acc = 0.6542\n","Epoch 88, loss = 0.5355, val.acc = 0.6422\n","Epoch 89, loss = 0.5258, val.acc = 0.6522\n","Epoch 90, loss = 0.5379, val.acc = 0.6388\n","Epoch 91, loss = 0.5240, val.acc = 0.6522\n","Epoch 92, loss = 0.5239, val.acc = 0.6348\n","Epoch 93, loss = 0.5212, val.acc = 0.6494\n","Epoch 94, loss = 0.5107, val.acc = 0.6356\n","Epoch 95, loss = 0.5066, val.acc = 0.6518\n","Epoch 96, loss = 0.5152, val.acc = 0.6360\n","Epoch 97, loss = 0.5041, val.acc = 0.6508\n","Epoch 98, loss = 0.5022, val.acc = 0.6356\n","Epoch 99, loss = 0.5006, val.acc = 0.6482\n","Rep: 1, Layer: 0, te.acc = 0.6375\n","\n","LAYER:1\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.4585, val.acc = 0.5902\n","Epoch 1, loss = 1.1092, val.acc = 0.6368\n","Epoch 2, loss = 1.0014, val.acc = 0.6620\n","Epoch 3, loss = 0.9421, val.acc = 0.6700\n","Epoch 4, loss = 0.9024, val.acc = 0.6752\n","Epoch 5, loss = 0.8720, val.acc = 0.6808\n","Epoch 6, loss = 0.8465, val.acc = 0.6844\n","Epoch 7, loss = 0.8238, val.acc = 0.6902\n","Epoch 8, loss = 0.8030, val.acc = 0.6936\n","Epoch 9, loss = 0.7835, val.acc = 0.6938\n","Epoch 10, loss = 0.7652, val.acc = 0.6952\n","Epoch 11, loss = 0.7479, val.acc = 0.6990\n","Epoch 12, loss = 0.7313, val.acc = 0.7020\n","Epoch 13, loss = 0.7154, val.acc = 0.7012\n","Epoch 14, loss = 0.7000, val.acc = 0.7032\n","Epoch 15, loss = 0.6851, val.acc = 0.7036\n","Epoch 16, loss = 0.6707, val.acc = 0.7050\n","Epoch 17, loss = 0.6567, val.acc = 0.7044\n","Epoch 18, loss = 0.6431, val.acc = 0.7044\n","Epoch 19, loss = 0.6299, val.acc = 0.7072\n","Epoch 20, loss = 0.6170, val.acc = 0.7100\n","Epoch 21, loss = 0.6045, val.acc = 0.7094\n","Epoch 22, loss = 0.5922, val.acc = 0.7102\n","Epoch 23, loss = 0.5803, val.acc = 0.7108\n","Epoch 24, loss = 0.5686, val.acc = 0.7118\n","Epoch 25, loss = 0.5573, val.acc = 0.7114\n","Epoch 26, loss = 0.5462, val.acc = 0.7110\n","Epoch 27, loss = 0.5353, val.acc = 0.7116\n","Epoch 28, loss = 0.5247, val.acc = 0.7096\n","Epoch 29, loss = 0.5142, val.acc = 0.7102\n","Epoch 30, loss = 0.5040, val.acc = 0.7090\n","Epoch 31, loss = 0.4940, val.acc = 0.7096\n","Epoch 32, loss = 0.4842, val.acc = 0.7096\n","Epoch 33, loss = 0.4747, val.acc = 0.7092\n","Epoch 34, loss = 0.4653, val.acc = 0.7102\n","Epoch 35, loss = 0.4562, val.acc = 0.7108\n","Epoch 36, loss = 0.4472, val.acc = 0.7116\n","Epoch 37, loss = 0.4385, val.acc = 0.7108\n","Epoch 38, loss = 0.4299, val.acc = 0.7098\n","Epoch 39, loss = 0.4216, val.acc = 0.7112\n","Epoch 40, loss = 0.4134, val.acc = 0.7118\n","Epoch 41, loss = 0.4055, val.acc = 0.7126\n","Epoch 42, loss = 0.3976, val.acc = 0.7122\n","Epoch 43, loss = 0.3900, val.acc = 0.7136\n","Epoch 44, loss = 0.3825, val.acc = 0.7140\n","Epoch 45, loss = 0.3752, val.acc = 0.7148\n","Epoch 46, loss = 0.3680, val.acc = 0.7148\n","Epoch 47, loss = 0.3610, val.acc = 0.7148\n","Epoch 48, loss = 0.3541, val.acc = 0.7138\n","Epoch 49, loss = 0.3474, val.acc = 0.7144\n","Epoch 50, loss = 0.3408, val.acc = 0.7134\n","Epoch 51, loss = 0.3343, val.acc = 0.7126\n","Epoch 52, loss = 0.3279, val.acc = 0.7130\n","Epoch 53, loss = 0.3217, val.acc = 0.7130\n","Epoch 54, loss = 0.3156, val.acc = 0.7134\n","Epoch 55, loss = 0.3096, val.acc = 0.7128\n","Epoch 56, loss = 0.3038, val.acc = 0.7122\n","Epoch 57, loss = 0.2981, val.acc = 0.7124\n","Epoch 58, loss = 0.2925, val.acc = 0.7124\n","Epoch 59, loss = 0.2870, val.acc = 0.7104\n","Epoch 60, loss = 0.2816, val.acc = 0.7106\n","Epoch 61, loss = 0.2764, val.acc = 0.7100\n","Epoch 62, loss = 0.2712, val.acc = 0.7100\n","Epoch 63, loss = 0.2662, val.acc = 0.7104\n","Epoch 64, loss = 0.2613, val.acc = 0.7106\n","Epoch 65, loss = 0.2564, val.acc = 0.7102\n","Epoch 66, loss = 0.2517, val.acc = 0.7106\n","Epoch 67, loss = 0.2470, val.acc = 0.7108\n","Epoch 68, loss = 0.2425, val.acc = 0.7090\n","Epoch 69, loss = 0.2380, val.acc = 0.7100\n","Epoch 70, loss = 0.2337, val.acc = 0.7102\n","Epoch 71, loss = 0.2294, val.acc = 0.7112\n","Epoch 72, loss = 0.2252, val.acc = 0.7104\n","Epoch 73, loss = 0.2210, val.acc = 0.7098\n","Epoch 74, loss = 0.2170, val.acc = 0.7108\n","Epoch 75, loss = 0.2130, val.acc = 0.7112\n","Epoch 76, loss = 0.2092, val.acc = 0.7106\n","Epoch 77, loss = 0.2054, val.acc = 0.7102\n","Epoch 78, loss = 0.2017, val.acc = 0.7096\n","Epoch 79, loss = 0.1981, val.acc = 0.7094\n","Epoch 80, loss = 0.1946, val.acc = 0.7088\n","Epoch 81, loss = 0.1911, val.acc = 0.7080\n","Epoch 82, loss = 0.1877, val.acc = 0.7084\n","Epoch 83, loss = 0.1844, val.acc = 0.7080\n","Epoch 84, loss = 0.1811, val.acc = 0.7080\n","Epoch 85, loss = 0.1779, val.acc = 0.7076\n","Epoch 86, loss = 0.1748, val.acc = 0.7080\n","Epoch 87, loss = 0.1718, val.acc = 0.7090\n","Epoch 88, loss = 0.1688, val.acc = 0.7084\n","Epoch 89, loss = 0.1658, val.acc = 0.7076\n","Epoch 90, loss = 0.1629, val.acc = 0.7086\n","Epoch 91, loss = 0.1601, val.acc = 0.7094\n","Epoch 92, loss = 0.1573, val.acc = 0.7096\n","Epoch 93, loss = 0.1546, val.acc = 0.7104\n","Epoch 94, loss = 0.1520, val.acc = 0.7096\n","Epoch 95, loss = 0.1494, val.acc = 0.7090\n","Epoch 96, loss = 0.1468, val.acc = 0.7084\n","Epoch 97, loss = 0.1443, val.acc = 0.7088\n","Epoch 98, loss = 0.1419, val.acc = 0.7082\n","Epoch 99, loss = 0.1395, val.acc = 0.7086\n","Rep: 1, Layer: 1, te.acc = 0.6963\n","\n","LAYER:2\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.2931, val.acc = 0.6518\n","Epoch 1, loss = 0.9280, val.acc = 0.6904\n","Epoch 2, loss = 0.8167, val.acc = 0.7110\n","Epoch 3, loss = 0.7478, val.acc = 0.7270\n","Epoch 4, loss = 0.6966, val.acc = 0.7348\n","Epoch 5, loss = 0.6549, val.acc = 0.7372\n","Epoch 6, loss = 0.6190, val.acc = 0.7382\n","Epoch 7, loss = 0.5870, val.acc = 0.7426\n","Epoch 8, loss = 0.5578, val.acc = 0.7452\n","Epoch 9, loss = 0.5307, val.acc = 0.7472\n","Epoch 10, loss = 0.5053, val.acc = 0.7474\n","Epoch 11, loss = 0.4813, val.acc = 0.7486\n","Epoch 12, loss = 0.4585, val.acc = 0.7500\n","Epoch 13, loss = 0.4367, val.acc = 0.7494\n","Epoch 14, loss = 0.4160, val.acc = 0.7506\n","Epoch 15, loss = 0.3961, val.acc = 0.7494\n","Epoch 16, loss = 0.3770, val.acc = 0.7500\n","Epoch 17, loss = 0.3587, val.acc = 0.7506\n","Epoch 18, loss = 0.3411, val.acc = 0.7520\n","Epoch 19, loss = 0.3242, val.acc = 0.7520\n","Epoch 20, loss = 0.3080, val.acc = 0.7522\n","Epoch 21, loss = 0.2925, val.acc = 0.7528\n","Epoch 22, loss = 0.2777, val.acc = 0.7536\n","Epoch 23, loss = 0.2636, val.acc = 0.7526\n","Epoch 24, loss = 0.2501, val.acc = 0.7524\n","Epoch 25, loss = 0.2372, val.acc = 0.7520\n","Epoch 26, loss = 0.2249, val.acc = 0.7508\n","Epoch 27, loss = 0.2133, val.acc = 0.7510\n","Epoch 28, loss = 0.2022, val.acc = 0.7506\n","Epoch 29, loss = 0.1917, val.acc = 0.7496\n","Epoch 30, loss = 0.1818, val.acc = 0.7488\n","Epoch 31, loss = 0.1723, val.acc = 0.7488\n","Epoch 32, loss = 0.1634, val.acc = 0.7484\n","Epoch 33, loss = 0.1550, val.acc = 0.7480\n","Epoch 34, loss = 0.1471, val.acc = 0.7478\n","Epoch 35, loss = 0.1396, val.acc = 0.7478\n","Epoch 36, loss = 0.1326, val.acc = 0.7472\n","Epoch 37, loss = 0.1259, val.acc = 0.7482\n","Epoch 38, loss = 0.1197, val.acc = 0.7486\n","Epoch 39, loss = 0.1139, val.acc = 0.7486\n","Epoch 40, loss = 0.1084, val.acc = 0.7484\n","Epoch 41, loss = 0.1032, val.acc = 0.7484\n","Epoch 42, loss = 0.0983, val.acc = 0.7486\n","Epoch 43, loss = 0.0938, val.acc = 0.7478\n","Epoch 44, loss = 0.0895, val.acc = 0.7470\n","Epoch 45, loss = 0.0854, val.acc = 0.7474\n","Epoch 46, loss = 0.0817, val.acc = 0.7482\n","Epoch 47, loss = 0.0781, val.acc = 0.7476\n","Epoch 48, loss = 0.0748, val.acc = 0.7472\n","Epoch 49, loss = 0.0716, val.acc = 0.7470\n","Epoch 50, loss = 0.0687, val.acc = 0.7470\n","Epoch 51, loss = 0.0659, val.acc = 0.7458\n","Epoch 52, loss = 0.0633, val.acc = 0.7456\n","Epoch 53, loss = 0.0608, val.acc = 0.7452\n","Epoch 54, loss = 0.0585, val.acc = 0.7456\n","Epoch 55, loss = 0.0563, val.acc = 0.7462\n","Epoch 56, loss = 0.0542, val.acc = 0.7458\n","Epoch 57, loss = 0.0523, val.acc = 0.7462\n","Epoch 58, loss = 0.0504, val.acc = 0.7460\n","Epoch 59, loss = 0.0487, val.acc = 0.7456\n","Epoch 60, loss = 0.0470, val.acc = 0.7450\n","Epoch 61, loss = 0.0455, val.acc = 0.7452\n","Epoch 62, loss = 0.0440, val.acc = 0.7450\n","Epoch 63, loss = 0.0426, val.acc = 0.7444\n","Epoch 64, loss = 0.0412, val.acc = 0.7440\n","Epoch 65, loss = 0.0399, val.acc = 0.7442\n","Epoch 66, loss = 0.0387, val.acc = 0.7444\n","Epoch 67, loss = 0.0376, val.acc = 0.7446\n","Epoch 68, loss = 0.0365, val.acc = 0.7446\n","Epoch 69, loss = 0.0354, val.acc = 0.7450\n","Epoch 70, loss = 0.0344, val.acc = 0.7450\n","Epoch 71, loss = 0.0335, val.acc = 0.7452\n","Epoch 72, loss = 0.0326, val.acc = 0.7454\n","Epoch 73, loss = 0.0317, val.acc = 0.7456\n","Epoch 74, loss = 0.0309, val.acc = 0.7460\n","Epoch 75, loss = 0.0301, val.acc = 0.7462\n","Epoch 76, loss = 0.0293, val.acc = 0.7462\n","Epoch 77, loss = 0.0286, val.acc = 0.7466\n","Epoch 78, loss = 0.0279, val.acc = 0.7468\n","Epoch 79, loss = 0.0273, val.acc = 0.7464\n","Epoch 80, loss = 0.0266, val.acc = 0.7466\n","Epoch 81, loss = 0.0260, val.acc = 0.7468\n","Epoch 82, loss = 0.0254, val.acc = 0.7470\n","Epoch 83, loss = 0.0248, val.acc = 0.7470\n","Epoch 84, loss = 0.0243, val.acc = 0.7472\n","Epoch 85, loss = 0.0238, val.acc = 0.7470\n","Epoch 86, loss = 0.0233, val.acc = 0.7472\n","Epoch 87, loss = 0.0228, val.acc = 0.7470\n","Epoch 88, loss = 0.0223, val.acc = 0.7474\n","Epoch 89, loss = 0.0219, val.acc = 0.7470\n","Epoch 90, loss = 0.0214, val.acc = 0.7470\n","Epoch 91, loss = 0.0210, val.acc = 0.7474\n","Epoch 92, loss = 0.0206, val.acc = 0.7472\n","Epoch 93, loss = 0.0202, val.acc = 0.7474\n","Epoch 94, loss = 0.0198, val.acc = 0.7472\n","Epoch 95, loss = 0.0195, val.acc = 0.7474\n","Epoch 96, loss = 0.0191, val.acc = 0.7476\n","Epoch 97, loss = 0.0188, val.acc = 0.7476\n","Epoch 98, loss = 0.0184, val.acc = 0.7476\n","Epoch 99, loss = 0.0181, val.acc = 0.7474\n","Rep: 1, Layer: 2, te.acc = 0.7406\n","\n","LAYER:3\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.3219, val.acc = 0.6720\n","Epoch 1, loss = 0.8036, val.acc = 0.7144\n","Epoch 2, loss = 0.6403, val.acc = 0.7346\n","Epoch 3, loss = 0.5387, val.acc = 0.7420\n","Epoch 4, loss = 0.4633, val.acc = 0.7486\n","Epoch 5, loss = 0.4027, val.acc = 0.7504\n","Epoch 6, loss = 0.3519, val.acc = 0.7520\n","Epoch 7, loss = 0.3086, val.acc = 0.7560\n","Epoch 8, loss = 0.2714, val.acc = 0.7568\n","Epoch 9, loss = 0.2394, val.acc = 0.7582\n","Epoch 10, loss = 0.2117, val.acc = 0.7578\n","Epoch 11, loss = 0.1879, val.acc = 0.7552\n","Epoch 12, loss = 0.1674, val.acc = 0.7544\n","Epoch 13, loss = 0.1497, val.acc = 0.7562\n","Epoch 14, loss = 0.1345, val.acc = 0.7562\n","Epoch 15, loss = 0.1213, val.acc = 0.7558\n","Epoch 16, loss = 0.1098, val.acc = 0.7544\n","Epoch 17, loss = 0.0999, val.acc = 0.7542\n","Epoch 18, loss = 0.0912, val.acc = 0.7540\n","Epoch 19, loss = 0.0836, val.acc = 0.7540\n","Epoch 20, loss = 0.0769, val.acc = 0.7534\n","Epoch 21, loss = 0.0710, val.acc = 0.7530\n","Epoch 22, loss = 0.0658, val.acc = 0.7532\n","Epoch 23, loss = 0.0611, val.acc = 0.7522\n","Epoch 24, loss = 0.0569, val.acc = 0.7522\n","Epoch 25, loss = 0.0532, val.acc = 0.7520\n","Epoch 26, loss = 0.0498, val.acc = 0.7512\n","Epoch 27, loss = 0.0468, val.acc = 0.7510\n","Epoch 28, loss = 0.0441, val.acc = 0.7512\n","Epoch 29, loss = 0.0416, val.acc = 0.7508\n","Epoch 30, loss = 0.0393, val.acc = 0.7514\n","Epoch 31, loss = 0.0372, val.acc = 0.7510\n","Epoch 32, loss = 0.0353, val.acc = 0.7510\n","Epoch 33, loss = 0.0336, val.acc = 0.7512\n","Epoch 34, loss = 0.0320, val.acc = 0.7508\n","Epoch 35, loss = 0.0305, val.acc = 0.7504\n","Epoch 36, loss = 0.0292, val.acc = 0.7506\n","Epoch 37, loss = 0.0279, val.acc = 0.7506\n","Epoch 38, loss = 0.0267, val.acc = 0.7510\n","Epoch 39, loss = 0.0256, val.acc = 0.7512\n","Epoch 40, loss = 0.0246, val.acc = 0.7518\n","Epoch 41, loss = 0.0237, val.acc = 0.7512\n","Epoch 42, loss = 0.0228, val.acc = 0.7514\n","Epoch 43, loss = 0.0220, val.acc = 0.7514\n","Epoch 44, loss = 0.0212, val.acc = 0.7516\n","Epoch 45, loss = 0.0205, val.acc = 0.7520\n","Epoch 46, loss = 0.0198, val.acc = 0.7524\n","Epoch 47, loss = 0.0191, val.acc = 0.7524\n","Epoch 48, loss = 0.0185, val.acc = 0.7524\n","Epoch 49, loss = 0.0179, val.acc = 0.7524\n","Epoch 50, loss = 0.0174, val.acc = 0.7522\n","Epoch 51, loss = 0.0169, val.acc = 0.7524\n","Epoch 52, loss = 0.0164, val.acc = 0.7528\n","Epoch 53, loss = 0.0159, val.acc = 0.7530\n","Epoch 54, loss = 0.0155, val.acc = 0.7532\n","Epoch 55, loss = 0.0150, val.acc = 0.7532\n","Epoch 56, loss = 0.0146, val.acc = 0.7530\n","Epoch 57, loss = 0.0143, val.acc = 0.7530\n","Epoch 58, loss = 0.0139, val.acc = 0.7532\n","Epoch 59, loss = 0.0135, val.acc = 0.7530\n","Epoch 60, loss = 0.0132, val.acc = 0.7530\n","Epoch 61, loss = 0.0129, val.acc = 0.7530\n","Epoch 62, loss = 0.0126, val.acc = 0.7530\n","Epoch 63, loss = 0.0123, val.acc = 0.7532\n","Epoch 64, loss = 0.0120, val.acc = 0.7530\n","Epoch 65, loss = 0.0117, val.acc = 0.7528\n","Epoch 66, loss = 0.0115, val.acc = 0.7528\n","Epoch 67, loss = 0.0112, val.acc = 0.7528\n","Epoch 68, loss = 0.0110, val.acc = 0.7524\n","Epoch 69, loss = 0.0108, val.acc = 0.7524\n","Epoch 70, loss = 0.0105, val.acc = 0.7522\n","Epoch 71, loss = 0.0103, val.acc = 0.7522\n","Epoch 72, loss = 0.0101, val.acc = 0.7518\n","Epoch 73, loss = 0.0099, val.acc = 0.7518\n","Epoch 74, loss = 0.0097, val.acc = 0.7520\n","Epoch 75, loss = 0.0095, val.acc = 0.7520\n","Epoch 76, loss = 0.0094, val.acc = 0.7520\n","Epoch 77, loss = 0.0092, val.acc = 0.7520\n","Epoch 78, loss = 0.0090, val.acc = 0.7520\n","Epoch 79, loss = 0.0089, val.acc = 0.7520\n","Epoch 80, loss = 0.0087, val.acc = 0.7522\n","Epoch 81, loss = 0.0086, val.acc = 0.7524\n","Epoch 82, loss = 0.0084, val.acc = 0.7526\n","Epoch 83, loss = 0.0083, val.acc = 0.7526\n","Epoch 84, loss = 0.0081, val.acc = 0.7526\n","Epoch 85, loss = 0.0080, val.acc = 0.7524\n","Epoch 86, loss = 0.0079, val.acc = 0.7524\n","Epoch 87, loss = 0.0077, val.acc = 0.7524\n","Epoch 88, loss = 0.0076, val.acc = 0.7524\n","Epoch 89, loss = 0.0075, val.acc = 0.7522\n","Epoch 90, loss = 0.0074, val.acc = 0.7522\n","Epoch 91, loss = 0.0073, val.acc = 0.7520\n","Epoch 92, loss = 0.0072, val.acc = 0.7520\n","Epoch 93, loss = 0.0071, val.acc = 0.7518\n","Epoch 94, loss = 0.0069, val.acc = 0.7518\n","Epoch 95, loss = 0.0068, val.acc = 0.7522\n","Epoch 96, loss = 0.0068, val.acc = 0.7522\n","Epoch 97, loss = 0.0067, val.acc = 0.7522\n","Epoch 98, loss = 0.0066, val.acc = 0.7522\n","Epoch 99, loss = 0.0065, val.acc = 0.7522\n","Rep: 1, Layer: 3, te.acc = 0.7417\n","\n","\n","Rep 2\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","LAYER:0\n","Sequential()\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.7819, val.acc = 0.4322\n","Epoch 1, loss = 1.5824, val.acc = 0.4588\n","Epoch 2, loss = 1.4832, val.acc = 0.4732\n","Epoch 3, loss = 1.4078, val.acc = 0.4902\n","Epoch 4, loss = 1.3554, val.acc = 0.5052\n","Epoch 5, loss = 1.3151, val.acc = 0.5176\n","Epoch 6, loss = 1.2791, val.acc = 0.5314\n","Epoch 7, loss = 1.2476, val.acc = 0.5374\n","Epoch 8, loss = 1.2197, val.acc = 0.5498\n","Epoch 9, loss = 1.1940, val.acc = 0.5600\n","Epoch 10, loss = 1.1702, val.acc = 0.5658\n","Epoch 11, loss = 1.1471, val.acc = 0.5752\n","Epoch 12, loss = 1.1242, val.acc = 0.5818\n","Epoch 13, loss = 1.1027, val.acc = 0.5852\n","Epoch 14, loss = 1.0820, val.acc = 0.5910\n","Epoch 15, loss = 1.0600, val.acc = 0.5982\n","Epoch 16, loss = 1.0371, val.acc = 0.6050\n","Epoch 17, loss = 1.0415, val.acc = 0.6082\n","Epoch 18, loss = 1.0022, val.acc = 0.5810\n","Epoch 19, loss = 0.9995, val.acc = 0.6144\n","Epoch 20, loss = 0.9784, val.acc = 0.6212\n","Epoch 21, loss = 0.9599, val.acc = 0.6054\n","Epoch 22, loss = 0.9518, val.acc = 0.6212\n","Epoch 23, loss = 0.9409, val.acc = 0.6278\n","Epoch 24, loss = 0.9233, val.acc = 0.6138\n","Epoch 25, loss = 0.9144, val.acc = 0.6318\n","Epoch 26, loss = 0.8956, val.acc = 0.6184\n","Epoch 27, loss = 0.8950, val.acc = 0.6346\n","Epoch 28, loss = 0.8737, val.acc = 0.6220\n","Epoch 29, loss = 0.8726, val.acc = 0.6306\n","Epoch 30, loss = 0.8585, val.acc = 0.6318\n","Epoch 31, loss = 0.8472, val.acc = 0.6396\n","Epoch 32, loss = 0.8257, val.acc = 0.6266\n","Epoch 33, loss = 0.8423, val.acc = 0.6242\n","Epoch 34, loss = 0.8187, val.acc = 0.6416\n","Epoch 35, loss = 0.8100, val.acc = 0.6404\n","Epoch 36, loss = 0.7964, val.acc = 0.6224\n","Epoch 37, loss = 0.8007, val.acc = 0.6420\n","Epoch 38, loss = 0.7809, val.acc = 0.6236\n","Epoch 39, loss = 0.7845, val.acc = 0.6412\n","Epoch 40, loss = 0.7671, val.acc = 0.6298\n","Epoch 41, loss = 0.7614, val.acc = 0.6424\n","Epoch 42, loss = 0.7554, val.acc = 0.6406\n","Epoch 43, loss = 0.7484, val.acc = 0.6456\n","Epoch 44, loss = 0.7273, val.acc = 0.6400\n","Epoch 45, loss = 0.7439, val.acc = 0.6362\n","Epoch 46, loss = 0.7319, val.acc = 0.6532\n","Epoch 47, loss = 0.7086, val.acc = 0.6216\n","Epoch 48, loss = 0.7158, val.acc = 0.6372\n","Epoch 49, loss = 0.7048, val.acc = 0.6476\n","Epoch 50, loss = 0.7038, val.acc = 0.6510\n","Epoch 51, loss = 0.6937, val.acc = 0.6404\n","Epoch 52, loss = 0.6872, val.acc = 0.6504\n","Epoch 53, loss = 0.6727, val.acc = 0.6216\n","Epoch 54, loss = 0.6810, val.acc = 0.6478\n","Epoch 55, loss = 0.6640, val.acc = 0.6342\n","Epoch 56, loss = 0.6592, val.acc = 0.6380\n","Epoch 57, loss = 0.6609, val.acc = 0.6518\n","Epoch 58, loss = 0.6499, val.acc = 0.6388\n","Epoch 59, loss = 0.6467, val.acc = 0.6500\n","Epoch 60, loss = 0.6300, val.acc = 0.6348\n","Epoch 61, loss = 0.6438, val.acc = 0.6524\n","Epoch 62, loss = 0.6290, val.acc = 0.6358\n","Epoch 63, loss = 0.6268, val.acc = 0.6526\n","Epoch 64, loss = 0.6165, val.acc = 0.6446\n","Epoch 65, loss = 0.6016, val.acc = 0.6364\n","Epoch 66, loss = 0.6280, val.acc = 0.6450\n","Epoch 67, loss = 0.6060, val.acc = 0.6526\n","Epoch 68, loss = 0.5914, val.acc = 0.6536\n","Epoch 69, loss = 0.5885, val.acc = 0.6284\n","Epoch 70, loss = 0.5956, val.acc = 0.6554\n","Epoch 71, loss = 0.5854, val.acc = 0.6398\n","Epoch 72, loss = 0.5802, val.acc = 0.6488\n","Epoch 73, loss = 0.5701, val.acc = 0.6354\n","Epoch 74, loss = 0.5752, val.acc = 0.6538\n","Epoch 75, loss = 0.5655, val.acc = 0.6402\n","Epoch 76, loss = 0.5616, val.acc = 0.6466\n","Epoch 77, loss = 0.5561, val.acc = 0.6392\n","Epoch 78, loss = 0.5545, val.acc = 0.6564\n","Epoch 79, loss = 0.5455, val.acc = 0.6380\n","Epoch 80, loss = 0.5462, val.acc = 0.6496\n","Epoch 81, loss = 0.5459, val.acc = 0.6374\n","Epoch 82, loss = 0.5323, val.acc = 0.6448\n","Epoch 83, loss = 0.5366, val.acc = 0.6388\n","Epoch 84, loss = 0.5293, val.acc = 0.6572\n","Epoch 85, loss = 0.5195, val.acc = 0.6326\n","Epoch 86, loss = 0.5205, val.acc = 0.6514\n","Epoch 87, loss = 0.5245, val.acc = 0.6400\n","Epoch 88, loss = 0.5116, val.acc = 0.6482\n","Epoch 89, loss = 0.5113, val.acc = 0.6338\n","Epoch 90, loss = 0.5061, val.acc = 0.6536\n","Epoch 91, loss = 0.4998, val.acc = 0.6418\n","Epoch 92, loss = 0.4918, val.acc = 0.6268\n","Epoch 93, loss = 0.5099, val.acc = 0.6528\n","Epoch 94, loss = 0.4918, val.acc = 0.6392\n","Epoch 95, loss = 0.4854, val.acc = 0.6486\n","Epoch 96, loss = 0.4803, val.acc = 0.6388\n","Epoch 97, loss = 0.4731, val.acc = 0.6414\n","Epoch 98, loss = 0.4838, val.acc = 0.6420\n","Epoch 99, loss = 0.4811, val.acc = 0.6498\n","Rep: 2, Layer: 0, te.acc = 0.6415\n","\n","LAYER:1\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.4789, val.acc = 0.5858\n","Epoch 1, loss = 1.1145, val.acc = 0.6378\n","Epoch 2, loss = 1.0057, val.acc = 0.6650\n","Epoch 3, loss = 0.9455, val.acc = 0.6742\n","Epoch 4, loss = 0.9049, val.acc = 0.6834\n","Epoch 5, loss = 0.8735, val.acc = 0.6894\n","Epoch 6, loss = 0.8471, val.acc = 0.6950\n","Epoch 7, loss = 0.8239, val.acc = 0.6992\n","Epoch 8, loss = 0.8028, val.acc = 0.7018\n","Epoch 9, loss = 0.7834, val.acc = 0.7036\n","Epoch 10, loss = 0.7653, val.acc = 0.7058\n","Epoch 11, loss = 0.7482, val.acc = 0.7078\n","Epoch 12, loss = 0.7321, val.acc = 0.7090\n","Epoch 13, loss = 0.7165, val.acc = 0.7102\n","Epoch 14, loss = 0.7015, val.acc = 0.7138\n","Epoch 15, loss = 0.6869, val.acc = 0.7152\n","Epoch 16, loss = 0.6727, val.acc = 0.7154\n","Epoch 17, loss = 0.6590, val.acc = 0.7158\n","Epoch 18, loss = 0.6455, val.acc = 0.7160\n","Epoch 19, loss = 0.6324, val.acc = 0.7168\n","Epoch 20, loss = 0.6196, val.acc = 0.7182\n","Epoch 21, loss = 0.6070, val.acc = 0.7200\n","Epoch 22, loss = 0.5947, val.acc = 0.7218\n","Epoch 23, loss = 0.5827, val.acc = 0.7218\n","Epoch 24, loss = 0.5709, val.acc = 0.7212\n","Epoch 25, loss = 0.5593, val.acc = 0.7252\n","Epoch 26, loss = 0.5481, val.acc = 0.7254\n","Epoch 27, loss = 0.5370, val.acc = 0.7244\n","Epoch 28, loss = 0.5262, val.acc = 0.7264\n","Epoch 29, loss = 0.5156, val.acc = 0.7270\n","Epoch 30, loss = 0.5051, val.acc = 0.7276\n","Epoch 31, loss = 0.4949, val.acc = 0.7262\n","Epoch 32, loss = 0.4849, val.acc = 0.7266\n","Epoch 33, loss = 0.4752, val.acc = 0.7260\n","Epoch 34, loss = 0.4657, val.acc = 0.7272\n","Epoch 35, loss = 0.4563, val.acc = 0.7272\n","Epoch 36, loss = 0.4472, val.acc = 0.7266\n","Epoch 37, loss = 0.4382, val.acc = 0.7264\n","Epoch 38, loss = 0.4295, val.acc = 0.7266\n","Epoch 39, loss = 0.4208, val.acc = 0.7266\n","Epoch 40, loss = 0.4123, val.acc = 0.7252\n","Epoch 41, loss = 0.4041, val.acc = 0.7240\n","Epoch 42, loss = 0.3960, val.acc = 0.7234\n","Epoch 43, loss = 0.3881, val.acc = 0.7246\n","Epoch 44, loss = 0.3803, val.acc = 0.7254\n","Epoch 45, loss = 0.3727, val.acc = 0.7252\n","Epoch 46, loss = 0.3653, val.acc = 0.7252\n","Epoch 47, loss = 0.3580, val.acc = 0.7246\n","Epoch 48, loss = 0.3508, val.acc = 0.7242\n","Epoch 49, loss = 0.3439, val.acc = 0.7254\n","Epoch 50, loss = 0.3371, val.acc = 0.7256\n","Epoch 51, loss = 0.3304, val.acc = 0.7242\n","Epoch 52, loss = 0.3238, val.acc = 0.7248\n","Epoch 53, loss = 0.3174, val.acc = 0.7248\n","Epoch 54, loss = 0.3112, val.acc = 0.7254\n","Epoch 55, loss = 0.3050, val.acc = 0.7224\n","Epoch 56, loss = 0.2990, val.acc = 0.7220\n","Epoch 57, loss = 0.2931, val.acc = 0.7220\n","Epoch 58, loss = 0.2874, val.acc = 0.7216\n","Epoch 59, loss = 0.2818, val.acc = 0.7214\n","Epoch 60, loss = 0.2763, val.acc = 0.7212\n","Epoch 61, loss = 0.2708, val.acc = 0.7210\n","Epoch 62, loss = 0.2656, val.acc = 0.7210\n","Epoch 63, loss = 0.2604, val.acc = 0.7212\n","Epoch 64, loss = 0.2553, val.acc = 0.7214\n","Epoch 65, loss = 0.2503, val.acc = 0.7208\n","Epoch 66, loss = 0.2454, val.acc = 0.7210\n","Epoch 67, loss = 0.2407, val.acc = 0.7208\n","Epoch 68, loss = 0.2361, val.acc = 0.7204\n","Epoch 69, loss = 0.2315, val.acc = 0.7200\n","Epoch 70, loss = 0.2270, val.acc = 0.7200\n","Epoch 71, loss = 0.2227, val.acc = 0.7196\n","Epoch 72, loss = 0.2184, val.acc = 0.7196\n","Epoch 73, loss = 0.2143, val.acc = 0.7192\n","Epoch 74, loss = 0.2102, val.acc = 0.7186\n","Epoch 75, loss = 0.2062, val.acc = 0.7184\n","Epoch 76, loss = 0.2023, val.acc = 0.7176\n","Epoch 77, loss = 0.1985, val.acc = 0.7178\n","Epoch 78, loss = 0.1947, val.acc = 0.7176\n","Epoch 79, loss = 0.1911, val.acc = 0.7168\n","Epoch 80, loss = 0.1875, val.acc = 0.7164\n","Epoch 81, loss = 0.1840, val.acc = 0.7164\n","Epoch 82, loss = 0.1806, val.acc = 0.7168\n","Epoch 83, loss = 0.1773, val.acc = 0.7166\n","Epoch 84, loss = 0.1740, val.acc = 0.7168\n","Epoch 85, loss = 0.1708, val.acc = 0.7160\n","Epoch 86, loss = 0.1677, val.acc = 0.7152\n","Epoch 87, loss = 0.1646, val.acc = 0.7154\n","Epoch 88, loss = 0.1616, val.acc = 0.7148\n","Epoch 89, loss = 0.1587, val.acc = 0.7146\n","Epoch 90, loss = 0.1558, val.acc = 0.7150\n","Epoch 91, loss = 0.1530, val.acc = 0.7144\n","Epoch 92, loss = 0.1503, val.acc = 0.7144\n","Epoch 93, loss = 0.1476, val.acc = 0.7152\n","Epoch 94, loss = 0.1449, val.acc = 0.7154\n","Epoch 95, loss = 0.1424, val.acc = 0.7148\n","Epoch 96, loss = 0.1399, val.acc = 0.7148\n","Epoch 97, loss = 0.1374, val.acc = 0.7150\n","Epoch 98, loss = 0.1350, val.acc = 0.7142\n","Epoch 99, loss = 0.1327, val.acc = 0.7148\n","Rep: 2, Layer: 1, te.acc = 0.6945\n","\n","LAYER:2\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.3092, val.acc = 0.6432\n","Epoch 1, loss = 0.9459, val.acc = 0.6890\n","Epoch 2, loss = 0.8317, val.acc = 0.7106\n","Epoch 3, loss = 0.7600, val.acc = 0.7202\n","Epoch 4, loss = 0.7067, val.acc = 0.7304\n","Epoch 5, loss = 0.6633, val.acc = 0.7370\n","Epoch 6, loss = 0.6261, val.acc = 0.7422\n","Epoch 7, loss = 0.5930, val.acc = 0.7442\n","Epoch 8, loss = 0.5628, val.acc = 0.7474\n","Epoch 9, loss = 0.5348, val.acc = 0.7496\n","Epoch 10, loss = 0.5085, val.acc = 0.7512\n","Epoch 11, loss = 0.4837, val.acc = 0.7526\n","Epoch 12, loss = 0.4601, val.acc = 0.7532\n","Epoch 13, loss = 0.4376, val.acc = 0.7548\n","Epoch 14, loss = 0.4161, val.acc = 0.7560\n","Epoch 15, loss = 0.3955, val.acc = 0.7550\n","Epoch 16, loss = 0.3758, val.acc = 0.7562\n","Epoch 17, loss = 0.3570, val.acc = 0.7586\n","Epoch 18, loss = 0.3389, val.acc = 0.7576\n","Epoch 19, loss = 0.3216, val.acc = 0.7576\n","Epoch 20, loss = 0.3051, val.acc = 0.7586\n","Epoch 21, loss = 0.2893, val.acc = 0.7596\n","Epoch 22, loss = 0.2742, val.acc = 0.7604\n","Epoch 23, loss = 0.2598, val.acc = 0.7594\n","Epoch 24, loss = 0.2461, val.acc = 0.7606\n","Epoch 25, loss = 0.2331, val.acc = 0.7620\n","Epoch 26, loss = 0.2208, val.acc = 0.7624\n","Epoch 27, loss = 0.2090, val.acc = 0.7624\n","Epoch 28, loss = 0.1979, val.acc = 0.7622\n","Epoch 29, loss = 0.1873, val.acc = 0.7628\n","Epoch 30, loss = 0.1774, val.acc = 0.7616\n","Epoch 31, loss = 0.1680, val.acc = 0.7608\n","Epoch 32, loss = 0.1592, val.acc = 0.7612\n","Epoch 33, loss = 0.1508, val.acc = 0.7620\n","Epoch 34, loss = 0.1430, val.acc = 0.7618\n","Epoch 35, loss = 0.1356, val.acc = 0.7628\n","Epoch 36, loss = 0.1287, val.acc = 0.7616\n","Epoch 37, loss = 0.1222, val.acc = 0.7616\n","Epoch 38, loss = 0.1161, val.acc = 0.7620\n","Epoch 39, loss = 0.1103, val.acc = 0.7628\n","Epoch 40, loss = 0.1049, val.acc = 0.7626\n","Epoch 41, loss = 0.0999, val.acc = 0.7618\n","Epoch 42, loss = 0.0951, val.acc = 0.7618\n","Epoch 43, loss = 0.0907, val.acc = 0.7622\n","Epoch 44, loss = 0.0865, val.acc = 0.7618\n","Epoch 45, loss = 0.0826, val.acc = 0.7618\n","Epoch 46, loss = 0.0789, val.acc = 0.7614\n","Epoch 47, loss = 0.0755, val.acc = 0.7612\n","Epoch 48, loss = 0.0722, val.acc = 0.7610\n","Epoch 49, loss = 0.0692, val.acc = 0.7610\n","Epoch 50, loss = 0.0663, val.acc = 0.7602\n","Epoch 51, loss = 0.0636, val.acc = 0.7598\n","Epoch 52, loss = 0.0611, val.acc = 0.7598\n","Epoch 53, loss = 0.0587, val.acc = 0.7598\n","Epoch 54, loss = 0.0564, val.acc = 0.7592\n","Epoch 55, loss = 0.0543, val.acc = 0.7590\n","Epoch 56, loss = 0.0523, val.acc = 0.7592\n","Epoch 57, loss = 0.0504, val.acc = 0.7592\n","Epoch 58, loss = 0.0486, val.acc = 0.7592\n","Epoch 59, loss = 0.0469, val.acc = 0.7596\n","Epoch 60, loss = 0.0453, val.acc = 0.7596\n","Epoch 61, loss = 0.0438, val.acc = 0.7592\n","Epoch 62, loss = 0.0424, val.acc = 0.7592\n","Epoch 63, loss = 0.0410, val.acc = 0.7594\n","Epoch 64, loss = 0.0398, val.acc = 0.7598\n","Epoch 65, loss = 0.0385, val.acc = 0.7598\n","Epoch 66, loss = 0.0374, val.acc = 0.7598\n","Epoch 67, loss = 0.0363, val.acc = 0.7598\n","Epoch 68, loss = 0.0352, val.acc = 0.7596\n","Epoch 69, loss = 0.0342, val.acc = 0.7602\n","Epoch 70, loss = 0.0333, val.acc = 0.7602\n","Epoch 71, loss = 0.0324, val.acc = 0.7602\n","Epoch 72, loss = 0.0315, val.acc = 0.7602\n","Epoch 73, loss = 0.0307, val.acc = 0.7606\n","Epoch 74, loss = 0.0299, val.acc = 0.7604\n","Epoch 75, loss = 0.0291, val.acc = 0.7612\n","Epoch 76, loss = 0.0284, val.acc = 0.7614\n","Epoch 77, loss = 0.0277, val.acc = 0.7612\n","Epoch 78, loss = 0.0270, val.acc = 0.7608\n","Epoch 79, loss = 0.0264, val.acc = 0.7610\n","Epoch 80, loss = 0.0258, val.acc = 0.7612\n","Epoch 81, loss = 0.0252, val.acc = 0.7612\n","Epoch 82, loss = 0.0246, val.acc = 0.7610\n","Epoch 83, loss = 0.0241, val.acc = 0.7610\n","Epoch 84, loss = 0.0236, val.acc = 0.7608\n","Epoch 85, loss = 0.0231, val.acc = 0.7608\n","Epoch 86, loss = 0.0226, val.acc = 0.7612\n","Epoch 87, loss = 0.0221, val.acc = 0.7608\n","Epoch 88, loss = 0.0217, val.acc = 0.7608\n","Epoch 89, loss = 0.0212, val.acc = 0.7610\n","Epoch 90, loss = 0.0208, val.acc = 0.7612\n","Epoch 91, loss = 0.0204, val.acc = 0.7610\n","Epoch 92, loss = 0.0200, val.acc = 0.7612\n","Epoch 93, loss = 0.0196, val.acc = 0.7612\n","Epoch 94, loss = 0.0193, val.acc = 0.7610\n","Epoch 95, loss = 0.0189, val.acc = 0.7610\n","Epoch 96, loss = 0.0186, val.acc = 0.7610\n","Epoch 97, loss = 0.0183, val.acc = 0.7608\n","Epoch 98, loss = 0.0179, val.acc = 0.7606\n","Epoch 99, loss = 0.0176, val.acc = 0.7606\n","Rep: 2, Layer: 2, te.acc = 0.7416\n","\n","LAYER:3\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.3267, val.acc = 0.6606\n","Epoch 1, loss = 0.8213, val.acc = 0.7056\n","Epoch 2, loss = 0.6556, val.acc = 0.7252\n","Epoch 3, loss = 0.5493, val.acc = 0.7404\n","Epoch 4, loss = 0.4699, val.acc = 0.7484\n","Epoch 5, loss = 0.4058, val.acc = 0.7520\n","Epoch 6, loss = 0.3522, val.acc = 0.7538\n","Epoch 7, loss = 0.3065, val.acc = 0.7544\n","Epoch 8, loss = 0.2675, val.acc = 0.7574\n","Epoch 9, loss = 0.2341, val.acc = 0.7594\n","Epoch 10, loss = 0.2057, val.acc = 0.7626\n","Epoch 11, loss = 0.1814, val.acc = 0.7638\n","Epoch 12, loss = 0.1608, val.acc = 0.7652\n","Epoch 13, loss = 0.1431, val.acc = 0.7672\n","Epoch 14, loss = 0.1281, val.acc = 0.7656\n","Epoch 15, loss = 0.1152, val.acc = 0.7672\n","Epoch 16, loss = 0.1041, val.acc = 0.7676\n","Epoch 17, loss = 0.0945, val.acc = 0.7672\n","Epoch 18, loss = 0.0862, val.acc = 0.7660\n","Epoch 19, loss = 0.0789, val.acc = 0.7652\n","Epoch 20, loss = 0.0726, val.acc = 0.7644\n","Epoch 21, loss = 0.0670, val.acc = 0.7646\n","Epoch 22, loss = 0.0620, val.acc = 0.7656\n","Epoch 23, loss = 0.0577, val.acc = 0.7654\n","Epoch 24, loss = 0.0537, val.acc = 0.7650\n","Epoch 25, loss = 0.0502, val.acc = 0.7652\n","Epoch 26, loss = 0.0471, val.acc = 0.7652\n","Epoch 27, loss = 0.0443, val.acc = 0.7646\n","Epoch 28, loss = 0.0417, val.acc = 0.7640\n","Epoch 29, loss = 0.0394, val.acc = 0.7640\n","Epoch 30, loss = 0.0372, val.acc = 0.7640\n","Epoch 31, loss = 0.0353, val.acc = 0.7650\n","Epoch 32, loss = 0.0335, val.acc = 0.7650\n","Epoch 33, loss = 0.0319, val.acc = 0.7650\n","Epoch 34, loss = 0.0304, val.acc = 0.7648\n","Epoch 35, loss = 0.0290, val.acc = 0.7648\n","Epoch 36, loss = 0.0277, val.acc = 0.7644\n","Epoch 37, loss = 0.0266, val.acc = 0.7640\n","Epoch 38, loss = 0.0255, val.acc = 0.7636\n","Epoch 39, loss = 0.0244, val.acc = 0.7630\n","Epoch 40, loss = 0.0235, val.acc = 0.7632\n","Epoch 41, loss = 0.0226, val.acc = 0.7626\n","Epoch 42, loss = 0.0218, val.acc = 0.7626\n","Epoch 43, loss = 0.0210, val.acc = 0.7630\n","Epoch 44, loss = 0.0203, val.acc = 0.7628\n","Epoch 45, loss = 0.0196, val.acc = 0.7618\n","Epoch 46, loss = 0.0189, val.acc = 0.7624\n","Epoch 47, loss = 0.0183, val.acc = 0.7620\n","Epoch 48, loss = 0.0177, val.acc = 0.7624\n","Epoch 49, loss = 0.0172, val.acc = 0.7622\n","Epoch 50, loss = 0.0167, val.acc = 0.7622\n","Epoch 51, loss = 0.0162, val.acc = 0.7620\n","Epoch 52, loss = 0.0157, val.acc = 0.7620\n","Epoch 53, loss = 0.0153, val.acc = 0.7624\n","Epoch 54, loss = 0.0148, val.acc = 0.7622\n","Epoch 55, loss = 0.0144, val.acc = 0.7624\n","Epoch 56, loss = 0.0141, val.acc = 0.7624\n","Epoch 57, loss = 0.0137, val.acc = 0.7624\n","Epoch 58, loss = 0.0134, val.acc = 0.7624\n","Epoch 59, loss = 0.0130, val.acc = 0.7624\n","Epoch 60, loss = 0.0127, val.acc = 0.7624\n","Epoch 61, loss = 0.0124, val.acc = 0.7624\n","Epoch 62, loss = 0.0121, val.acc = 0.7624\n","Epoch 63, loss = 0.0118, val.acc = 0.7624\n","Epoch 64, loss = 0.0116, val.acc = 0.7624\n","Epoch 65, loss = 0.0113, val.acc = 0.7624\n","Epoch 66, loss = 0.0111, val.acc = 0.7622\n","Epoch 67, loss = 0.0108, val.acc = 0.7620\n","Epoch 68, loss = 0.0106, val.acc = 0.7618\n","Epoch 69, loss = 0.0104, val.acc = 0.7618\n","Epoch 70, loss = 0.0102, val.acc = 0.7618\n","Epoch 71, loss = 0.0100, val.acc = 0.7618\n","Epoch 72, loss = 0.0098, val.acc = 0.7616\n","Epoch 73, loss = 0.0096, val.acc = 0.7616\n","Epoch 74, loss = 0.0094, val.acc = 0.7618\n","Epoch 75, loss = 0.0092, val.acc = 0.7616\n","Epoch 76, loss = 0.0091, val.acc = 0.7614\n","Epoch 77, loss = 0.0089, val.acc = 0.7614\n","Epoch 78, loss = 0.0087, val.acc = 0.7614\n","Epoch 79, loss = 0.0086, val.acc = 0.7614\n","Epoch 80, loss = 0.0084, val.acc = 0.7614\n","Epoch 81, loss = 0.0083, val.acc = 0.7616\n","Epoch 82, loss = 0.0081, val.acc = 0.7616\n","Epoch 83, loss = 0.0080, val.acc = 0.7614\n","Epoch 84, loss = 0.0079, val.acc = 0.7616\n","Epoch 85, loss = 0.0077, val.acc = 0.7614\n","Epoch 86, loss = 0.0076, val.acc = 0.7614\n","Epoch 87, loss = 0.0075, val.acc = 0.7614\n","Epoch 88, loss = 0.0074, val.acc = 0.7614\n","Epoch 89, loss = 0.0073, val.acc = 0.7614\n","Epoch 90, loss = 0.0072, val.acc = 0.7614\n","Epoch 91, loss = 0.0071, val.acc = 0.7612\n","Epoch 92, loss = 0.0069, val.acc = 0.7614\n","Epoch 93, loss = 0.0068, val.acc = 0.7614\n","Epoch 94, loss = 0.0067, val.acc = 0.7614\n","Epoch 95, loss = 0.0066, val.acc = 0.7614\n","Epoch 96, loss = 0.0066, val.acc = 0.7614\n","Epoch 97, loss = 0.0065, val.acc = 0.7612\n","Epoch 98, loss = 0.0064, val.acc = 0.7612\n","Epoch 99, loss = 0.0063, val.acc = 0.7608\n","Rep: 2, Layer: 3, te.acc = 0.7421\n","\n","\n","Rep 3\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","LAYER:0\n","Sequential()\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.7910, val.acc = 0.4318\n","Epoch 1, loss = 1.6022, val.acc = 0.4524\n","Epoch 2, loss = 1.5185, val.acc = 0.4684\n","Epoch 3, loss = 1.4421, val.acc = 0.4918\n","Epoch 4, loss = 1.3749, val.acc = 0.5108\n","Epoch 5, loss = 1.3259, val.acc = 0.5228\n","Epoch 6, loss = 1.2851, val.acc = 0.5374\n","Epoch 7, loss = 1.2489, val.acc = 0.5470\n","Epoch 8, loss = 1.2160, val.acc = 0.5594\n","Epoch 9, loss = 1.1868, val.acc = 0.5704\n","Epoch 10, loss = 1.1604, val.acc = 0.5786\n","Epoch 11, loss = 1.1336, val.acc = 0.5854\n","Epoch 12, loss = 1.1092, val.acc = 0.5924\n","Epoch 13, loss = 1.0861, val.acc = 0.6018\n","Epoch 14, loss = 1.0647, val.acc = 0.6090\n","Epoch 15, loss = 1.0445, val.acc = 0.6136\n","Epoch 16, loss = 1.0259, val.acc = 0.6192\n","Epoch 17, loss = 1.0078, val.acc = 0.6234\n","Epoch 18, loss = 0.9924, val.acc = 0.6286\n","Epoch 19, loss = 0.9786, val.acc = 0.6176\n","Epoch 20, loss = 0.9601, val.acc = 0.6098\n","Epoch 21, loss = 0.9534, val.acc = 0.6344\n","Epoch 22, loss = 0.9355, val.acc = 0.6210\n","Epoch 23, loss = 0.9237, val.acc = 0.6268\n","Epoch 24, loss = 0.9081, val.acc = 0.6232\n","Epoch 25, loss = 0.9080, val.acc = 0.6402\n","Epoch 26, loss = 0.8955, val.acc = 0.6426\n","Epoch 27, loss = 0.8788, val.acc = 0.6236\n","Epoch 28, loss = 0.8717, val.acc = 0.6478\n","Epoch 29, loss = 0.8521, val.acc = 0.6366\n","Epoch 30, loss = 0.8536, val.acc = 0.6458\n","Epoch 31, loss = 0.8461, val.acc = 0.6302\n","Epoch 32, loss = 0.8300, val.acc = 0.6490\n","Epoch 33, loss = 0.8224, val.acc = 0.6456\n","Epoch 34, loss = 0.8155, val.acc = 0.6424\n","Epoch 35, loss = 0.8126, val.acc = 0.6348\n","Epoch 36, loss = 0.7892, val.acc = 0.6512\n","Epoch 37, loss = 0.7961, val.acc = 0.6456\n","Epoch 38, loss = 0.7861, val.acc = 0.6340\n","Epoch 39, loss = 0.7753, val.acc = 0.6496\n","Epoch 40, loss = 0.7716, val.acc = 0.6408\n","Epoch 41, loss = 0.7579, val.acc = 0.6482\n","Epoch 42, loss = 0.7530, val.acc = 0.6368\n","Epoch 43, loss = 0.7380, val.acc = 0.6428\n","Epoch 44, loss = 0.7477, val.acc = 0.6390\n","Epoch 45, loss = 0.7389, val.acc = 0.6514\n","Epoch 46, loss = 0.7194, val.acc = 0.6408\n","Epoch 47, loss = 0.7227, val.acc = 0.6412\n","Epoch 48, loss = 0.7146, val.acc = 0.6478\n","Epoch 49, loss = 0.7077, val.acc = 0.6536\n","Epoch 50, loss = 0.6979, val.acc = 0.6540\n","Epoch 51, loss = 0.6894, val.acc = 0.6516\n","Epoch 52, loss = 0.6849, val.acc = 0.6502\n","Epoch 53, loss = 0.6945, val.acc = 0.6560\n","Epoch 54, loss = 0.6772, val.acc = 0.6440\n","Epoch 55, loss = 0.6689, val.acc = 0.6538\n","Epoch 56, loss = 0.6631, val.acc = 0.6488\n","Epoch 57, loss = 0.6540, val.acc = 0.6542\n","Epoch 58, loss = 0.6575, val.acc = 0.6466\n","Epoch 59, loss = 0.6461, val.acc = 0.6488\n","Epoch 60, loss = 0.6448, val.acc = 0.6556\n","Epoch 61, loss = 0.6373, val.acc = 0.6470\n","Epoch 62, loss = 0.6316, val.acc = 0.6556\n","Epoch 63, loss = 0.6233, val.acc = 0.6544\n","Epoch 64, loss = 0.6261, val.acc = 0.6392\n","Epoch 65, loss = 0.6165, val.acc = 0.6448\n","Epoch 66, loss = 0.6133, val.acc = 0.6554\n","Epoch 67, loss = 0.6092, val.acc = 0.6504\n","Epoch 68, loss = 0.5965, val.acc = 0.6506\n","Epoch 69, loss = 0.6029, val.acc = 0.6488\n","Epoch 70, loss = 0.5936, val.acc = 0.6554\n","Epoch 71, loss = 0.5843, val.acc = 0.6514\n","Epoch 72, loss = 0.5815, val.acc = 0.6532\n","Epoch 73, loss = 0.5882, val.acc = 0.6492\n","Epoch 74, loss = 0.5732, val.acc = 0.6548\n","Epoch 75, loss = 0.5612, val.acc = 0.6552\n","Epoch 76, loss = 0.5702, val.acc = 0.6526\n","Epoch 77, loss = 0.5660, val.acc = 0.6438\n","Epoch 78, loss = 0.5513, val.acc = 0.6548\n","Epoch 79, loss = 0.5604, val.acc = 0.6510\n","Epoch 80, loss = 0.5567, val.acc = 0.6542\n","Epoch 81, loss = 0.5386, val.acc = 0.6536\n","Epoch 82, loss = 0.5376, val.acc = 0.6526\n","Epoch 83, loss = 0.5439, val.acc = 0.6494\n","Epoch 84, loss = 0.5294, val.acc = 0.6550\n","Epoch 85, loss = 0.5254, val.acc = 0.6528\n","Epoch 86, loss = 0.5295, val.acc = 0.6492\n","Epoch 87, loss = 0.5226, val.acc = 0.6532\n","Epoch 88, loss = 0.5198, val.acc = 0.6550\n","Epoch 89, loss = 0.5201, val.acc = 0.6564\n","Epoch 90, loss = 0.5044, val.acc = 0.6492\n","Epoch 91, loss = 0.5167, val.acc = 0.6484\n","Epoch 92, loss = 0.4999, val.acc = 0.6560\n","Epoch 93, loss = 0.4937, val.acc = 0.6520\n","Epoch 94, loss = 0.5101, val.acc = 0.6484\n","Epoch 95, loss = 0.4925, val.acc = 0.6538\n","Epoch 96, loss = 0.4821, val.acc = 0.6526\n","Epoch 97, loss = 0.4986, val.acc = 0.6454\n","Epoch 98, loss = 0.4824, val.acc = 0.6528\n","Epoch 99, loss = 0.4766, val.acc = 0.6494\n","Rep: 3, Layer: 0, te.acc = 0.6373\n","\n","LAYER:1\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.4624, val.acc = 0.6006\n","Epoch 1, loss = 1.1105, val.acc = 0.6474\n","Epoch 2, loss = 1.0022, val.acc = 0.6676\n","Epoch 3, loss = 0.9434, val.acc = 0.6834\n","Epoch 4, loss = 0.9044, val.acc = 0.6890\n","Epoch 5, loss = 0.8741, val.acc = 0.6928\n","Epoch 6, loss = 0.8484, val.acc = 0.6978\n","Epoch 7, loss = 0.8257, val.acc = 0.7000\n","Epoch 8, loss = 0.8051, val.acc = 0.7032\n","Epoch 9, loss = 0.7859, val.acc = 0.7056\n","Epoch 10, loss = 0.7678, val.acc = 0.7082\n","Epoch 11, loss = 0.7507, val.acc = 0.7120\n","Epoch 12, loss = 0.7343, val.acc = 0.7130\n","Epoch 13, loss = 0.7185, val.acc = 0.7150\n","Epoch 14, loss = 0.7032, val.acc = 0.7160\n","Epoch 15, loss = 0.6883, val.acc = 0.7176\n","Epoch 16, loss = 0.6738, val.acc = 0.7194\n","Epoch 17, loss = 0.6597, val.acc = 0.7210\n","Epoch 18, loss = 0.6459, val.acc = 0.7230\n","Epoch 19, loss = 0.6325, val.acc = 0.7236\n","Epoch 20, loss = 0.6194, val.acc = 0.7242\n","Epoch 21, loss = 0.6067, val.acc = 0.7240\n","Epoch 22, loss = 0.5942, val.acc = 0.7232\n","Epoch 23, loss = 0.5820, val.acc = 0.7246\n","Epoch 24, loss = 0.5701, val.acc = 0.7266\n","Epoch 25, loss = 0.5584, val.acc = 0.7270\n","Epoch 26, loss = 0.5470, val.acc = 0.7274\n","Epoch 27, loss = 0.5358, val.acc = 0.7274\n","Epoch 28, loss = 0.5248, val.acc = 0.7270\n","Epoch 29, loss = 0.5141, val.acc = 0.7284\n","Epoch 30, loss = 0.5037, val.acc = 0.7278\n","Epoch 31, loss = 0.4935, val.acc = 0.7272\n","Epoch 32, loss = 0.4835, val.acc = 0.7266\n","Epoch 33, loss = 0.4737, val.acc = 0.7266\n","Epoch 34, loss = 0.4641, val.acc = 0.7270\n","Epoch 35, loss = 0.4548, val.acc = 0.7264\n","Epoch 36, loss = 0.4456, val.acc = 0.7262\n","Epoch 37, loss = 0.4366, val.acc = 0.7260\n","Epoch 38, loss = 0.4278, val.acc = 0.7244\n","Epoch 39, loss = 0.4192, val.acc = 0.7244\n","Epoch 40, loss = 0.4108, val.acc = 0.7238\n","Epoch 41, loss = 0.4025, val.acc = 0.7238\n","Epoch 42, loss = 0.3945, val.acc = 0.7230\n","Epoch 43, loss = 0.3867, val.acc = 0.7234\n","Epoch 44, loss = 0.3790, val.acc = 0.7228\n","Epoch 45, loss = 0.3714, val.acc = 0.7226\n","Epoch 46, loss = 0.3640, val.acc = 0.7212\n","Epoch 47, loss = 0.3567, val.acc = 0.7204\n","Epoch 48, loss = 0.3496, val.acc = 0.7212\n","Epoch 49, loss = 0.3427, val.acc = 0.7206\n","Epoch 50, loss = 0.3360, val.acc = 0.7194\n","Epoch 51, loss = 0.3293, val.acc = 0.7188\n","Epoch 52, loss = 0.3228, val.acc = 0.7176\n","Epoch 53, loss = 0.3164, val.acc = 0.7178\n","Epoch 54, loss = 0.3102, val.acc = 0.7168\n","Epoch 55, loss = 0.3041, val.acc = 0.7174\n","Epoch 56, loss = 0.2981, val.acc = 0.7166\n","Epoch 57, loss = 0.2922, val.acc = 0.7158\n","Epoch 58, loss = 0.2864, val.acc = 0.7170\n","Epoch 59, loss = 0.2808, val.acc = 0.7162\n","Epoch 60, loss = 0.2752, val.acc = 0.7158\n","Epoch 61, loss = 0.2698, val.acc = 0.7164\n","Epoch 62, loss = 0.2646, val.acc = 0.7164\n","Epoch 63, loss = 0.2594, val.acc = 0.7166\n","Epoch 64, loss = 0.2543, val.acc = 0.7160\n","Epoch 65, loss = 0.2493, val.acc = 0.7162\n","Epoch 66, loss = 0.2445, val.acc = 0.7156\n","Epoch 67, loss = 0.2397, val.acc = 0.7154\n","Epoch 68, loss = 0.2350, val.acc = 0.7158\n","Epoch 69, loss = 0.2305, val.acc = 0.7136\n","Epoch 70, loss = 0.2260, val.acc = 0.7128\n","Epoch 71, loss = 0.2216, val.acc = 0.7136\n","Epoch 72, loss = 0.2174, val.acc = 0.7130\n","Epoch 73, loss = 0.2132, val.acc = 0.7120\n","Epoch 74, loss = 0.2091, val.acc = 0.7128\n","Epoch 75, loss = 0.2051, val.acc = 0.7122\n","Epoch 76, loss = 0.2012, val.acc = 0.7114\n","Epoch 77, loss = 0.1973, val.acc = 0.7106\n","Epoch 78, loss = 0.1936, val.acc = 0.7098\n","Epoch 79, loss = 0.1899, val.acc = 0.7092\n","Epoch 80, loss = 0.1864, val.acc = 0.7090\n","Epoch 81, loss = 0.1829, val.acc = 0.7092\n","Epoch 82, loss = 0.1795, val.acc = 0.7092\n","Epoch 83, loss = 0.1761, val.acc = 0.7098\n","Epoch 84, loss = 0.1729, val.acc = 0.7094\n","Epoch 85, loss = 0.1697, val.acc = 0.7094\n","Epoch 86, loss = 0.1666, val.acc = 0.7094\n","Epoch 87, loss = 0.1635, val.acc = 0.7104\n","Epoch 88, loss = 0.1605, val.acc = 0.7104\n","Epoch 89, loss = 0.1576, val.acc = 0.7100\n","Epoch 90, loss = 0.1548, val.acc = 0.7092\n","Epoch 91, loss = 0.1520, val.acc = 0.7094\n","Epoch 92, loss = 0.1493, val.acc = 0.7100\n","Epoch 93, loss = 0.1466, val.acc = 0.7108\n","Epoch 94, loss = 0.1440, val.acc = 0.7116\n","Epoch 95, loss = 0.1414, val.acc = 0.7116\n","Epoch 96, loss = 0.1389, val.acc = 0.7110\n","Epoch 97, loss = 0.1365, val.acc = 0.7118\n","Epoch 98, loss = 0.1341, val.acc = 0.7114\n","Epoch 99, loss = 0.1317, val.acc = 0.7108\n","Rep: 3, Layer: 1, te.acc = 0.7018\n","\n","LAYER:2\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.2961, val.acc = 0.6520\n","Epoch 1, loss = 0.9397, val.acc = 0.6916\n","Epoch 2, loss = 0.8263, val.acc = 0.7146\n","Epoch 3, loss = 0.7540, val.acc = 0.7240\n","Epoch 4, loss = 0.7004, val.acc = 0.7318\n","Epoch 5, loss = 0.6568, val.acc = 0.7362\n","Epoch 6, loss = 0.6192, val.acc = 0.7396\n","Epoch 7, loss = 0.5858, val.acc = 0.7434\n","Epoch 8, loss = 0.5553, val.acc = 0.7442\n","Epoch 9, loss = 0.5271, val.acc = 0.7470\n","Epoch 10, loss = 0.5008, val.acc = 0.7482\n","Epoch 11, loss = 0.4761, val.acc = 0.7486\n","Epoch 12, loss = 0.4526, val.acc = 0.7506\n","Epoch 13, loss = 0.4303, val.acc = 0.7494\n","Epoch 14, loss = 0.4090, val.acc = 0.7512\n","Epoch 15, loss = 0.3887, val.acc = 0.7526\n","Epoch 16, loss = 0.3692, val.acc = 0.7534\n","Epoch 17, loss = 0.3507, val.acc = 0.7536\n","Epoch 18, loss = 0.3329, val.acc = 0.7536\n","Epoch 19, loss = 0.3159, val.acc = 0.7526\n","Epoch 20, loss = 0.2996, val.acc = 0.7528\n","Epoch 21, loss = 0.2841, val.acc = 0.7532\n","Epoch 22, loss = 0.2694, val.acc = 0.7546\n","Epoch 23, loss = 0.2553, val.acc = 0.7540\n","Epoch 24, loss = 0.2419, val.acc = 0.7538\n","Epoch 25, loss = 0.2292, val.acc = 0.7546\n","Epoch 26, loss = 0.2171, val.acc = 0.7550\n","Epoch 27, loss = 0.2056, val.acc = 0.7556\n","Epoch 28, loss = 0.1948, val.acc = 0.7534\n","Epoch 29, loss = 0.1846, val.acc = 0.7536\n","Epoch 30, loss = 0.1749, val.acc = 0.7536\n","Epoch 31, loss = 0.1657, val.acc = 0.7538\n","Epoch 32, loss = 0.1571, val.acc = 0.7526\n","Epoch 33, loss = 0.1489, val.acc = 0.7510\n","Epoch 34, loss = 0.1413, val.acc = 0.7504\n","Epoch 35, loss = 0.1340, val.acc = 0.7504\n","Epoch 36, loss = 0.1273, val.acc = 0.7506\n","Epoch 37, loss = 0.1209, val.acc = 0.7510\n","Epoch 38, loss = 0.1149, val.acc = 0.7520\n","Epoch 39, loss = 0.1093, val.acc = 0.7518\n","Epoch 40, loss = 0.1040, val.acc = 0.7516\n","Epoch 41, loss = 0.0990, val.acc = 0.7514\n","Epoch 42, loss = 0.0944, val.acc = 0.7514\n","Epoch 43, loss = 0.0900, val.acc = 0.7506\n","Epoch 44, loss = 0.0859, val.acc = 0.7498\n","Epoch 45, loss = 0.0820, val.acc = 0.7500\n","Epoch 46, loss = 0.0784, val.acc = 0.7506\n","Epoch 47, loss = 0.0750, val.acc = 0.7502\n","Epoch 48, loss = 0.0719, val.acc = 0.7500\n","Epoch 49, loss = 0.0688, val.acc = 0.7508\n","Epoch 50, loss = 0.0660, val.acc = 0.7504\n","Epoch 51, loss = 0.0634, val.acc = 0.7508\n","Epoch 52, loss = 0.0609, val.acc = 0.7508\n","Epoch 53, loss = 0.0585, val.acc = 0.7508\n","Epoch 54, loss = 0.0563, val.acc = 0.7504\n","Epoch 55, loss = 0.0542, val.acc = 0.7502\n","Epoch 56, loss = 0.0522, val.acc = 0.7502\n","Epoch 57, loss = 0.0503, val.acc = 0.7504\n","Epoch 58, loss = 0.0486, val.acc = 0.7506\n","Epoch 59, loss = 0.0469, val.acc = 0.7502\n","Epoch 60, loss = 0.0453, val.acc = 0.7504\n","Epoch 61, loss = 0.0438, val.acc = 0.7504\n","Epoch 62, loss = 0.0424, val.acc = 0.7506\n","Epoch 63, loss = 0.0411, val.acc = 0.7508\n","Epoch 64, loss = 0.0398, val.acc = 0.7506\n","Epoch 65, loss = 0.0386, val.acc = 0.7502\n","Epoch 66, loss = 0.0374, val.acc = 0.7508\n","Epoch 67, loss = 0.0363, val.acc = 0.7506\n","Epoch 68, loss = 0.0353, val.acc = 0.7506\n","Epoch 69, loss = 0.0343, val.acc = 0.7506\n","Epoch 70, loss = 0.0334, val.acc = 0.7508\n","Epoch 71, loss = 0.0324, val.acc = 0.7508\n","Epoch 72, loss = 0.0316, val.acc = 0.7510\n","Epoch 73, loss = 0.0308, val.acc = 0.7508\n","Epoch 74, loss = 0.0300, val.acc = 0.7510\n","Epoch 75, loss = 0.0292, val.acc = 0.7512\n","Epoch 76, loss = 0.0285, val.acc = 0.7508\n","Epoch 77, loss = 0.0278, val.acc = 0.7506\n","Epoch 78, loss = 0.0271, val.acc = 0.7504\n","Epoch 79, loss = 0.0265, val.acc = 0.7496\n","Epoch 80, loss = 0.0259, val.acc = 0.7492\n","Epoch 81, loss = 0.0253, val.acc = 0.7494\n","Epoch 82, loss = 0.0247, val.acc = 0.7494\n","Epoch 83, loss = 0.0242, val.acc = 0.7494\n","Epoch 84, loss = 0.0237, val.acc = 0.7490\n","Epoch 85, loss = 0.0231, val.acc = 0.7490\n","Epoch 86, loss = 0.0227, val.acc = 0.7492\n","Epoch 87, loss = 0.0222, val.acc = 0.7492\n","Epoch 88, loss = 0.0217, val.acc = 0.7490\n","Epoch 89, loss = 0.0213, val.acc = 0.7490\n","Epoch 90, loss = 0.0209, val.acc = 0.7490\n","Epoch 91, loss = 0.0205, val.acc = 0.7490\n","Epoch 92, loss = 0.0201, val.acc = 0.7490\n","Epoch 93, loss = 0.0197, val.acc = 0.7498\n","Epoch 94, loss = 0.0193, val.acc = 0.7496\n","Epoch 95, loss = 0.0190, val.acc = 0.7498\n","Epoch 96, loss = 0.0186, val.acc = 0.7500\n","Epoch 97, loss = 0.0183, val.acc = 0.7496\n","Epoch 98, loss = 0.0180, val.acc = 0.7498\n","Epoch 99, loss = 0.0177, val.acc = 0.7494\n","Rep: 3, Layer: 2, te.acc = 0.7391\n","\n","LAYER:3\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.3307, val.acc = 0.6676\n","Epoch 1, loss = 0.8114, val.acc = 0.7060\n","Epoch 2, loss = 0.6487, val.acc = 0.7286\n","Epoch 3, loss = 0.5431, val.acc = 0.7444\n","Epoch 4, loss = 0.4638, val.acc = 0.7516\n","Epoch 5, loss = 0.4001, val.acc = 0.7558\n","Epoch 6, loss = 0.3474, val.acc = 0.7586\n","Epoch 7, loss = 0.3029, val.acc = 0.7590\n","Epoch 8, loss = 0.2651, val.acc = 0.7596\n","Epoch 9, loss = 0.2330, val.acc = 0.7598\n","Epoch 10, loss = 0.2055, val.acc = 0.7596\n","Epoch 11, loss = 0.1821, val.acc = 0.7584\n","Epoch 12, loss = 0.1620, val.acc = 0.7582\n","Epoch 13, loss = 0.1448, val.acc = 0.7592\n","Epoch 14, loss = 0.1300, val.acc = 0.7588\n","Epoch 15, loss = 0.1173, val.acc = 0.7582\n","Epoch 16, loss = 0.1062, val.acc = 0.7588\n","Epoch 17, loss = 0.0966, val.acc = 0.7600\n","Epoch 18, loss = 0.0883, val.acc = 0.7594\n","Epoch 19, loss = 0.0809, val.acc = 0.7586\n","Epoch 20, loss = 0.0745, val.acc = 0.7584\n","Epoch 21, loss = 0.0688, val.acc = 0.7580\n","Epoch 22, loss = 0.0637, val.acc = 0.7572\n","Epoch 23, loss = 0.0592, val.acc = 0.7566\n","Epoch 24, loss = 0.0552, val.acc = 0.7560\n","Epoch 25, loss = 0.0516, val.acc = 0.7564\n","Epoch 26, loss = 0.0484, val.acc = 0.7560\n","Epoch 27, loss = 0.0454, val.acc = 0.7562\n","Epoch 28, loss = 0.0428, val.acc = 0.7552\n","Epoch 29, loss = 0.0404, val.acc = 0.7554\n","Epoch 30, loss = 0.0382, val.acc = 0.7554\n","Epoch 31, loss = 0.0362, val.acc = 0.7552\n","Epoch 32, loss = 0.0344, val.acc = 0.7550\n","Epoch 33, loss = 0.0327, val.acc = 0.7546\n","Epoch 34, loss = 0.0311, val.acc = 0.7546\n","Epoch 35, loss = 0.0297, val.acc = 0.7548\n","Epoch 36, loss = 0.0284, val.acc = 0.7546\n","Epoch 37, loss = 0.0272, val.acc = 0.7546\n","Epoch 38, loss = 0.0260, val.acc = 0.7542\n","Epoch 39, loss = 0.0250, val.acc = 0.7540\n","Epoch 40, loss = 0.0240, val.acc = 0.7538\n","Epoch 41, loss = 0.0231, val.acc = 0.7536\n","Epoch 42, loss = 0.0222, val.acc = 0.7538\n","Epoch 43, loss = 0.0214, val.acc = 0.7540\n","Epoch 44, loss = 0.0207, val.acc = 0.7540\n","Epoch 45, loss = 0.0200, val.acc = 0.7540\n","Epoch 46, loss = 0.0193, val.acc = 0.7538\n","Epoch 47, loss = 0.0187, val.acc = 0.7538\n","Epoch 48, loss = 0.0181, val.acc = 0.7536\n","Epoch 49, loss = 0.0175, val.acc = 0.7538\n","Epoch 50, loss = 0.0170, val.acc = 0.7540\n","Epoch 51, loss = 0.0165, val.acc = 0.7542\n","Epoch 52, loss = 0.0160, val.acc = 0.7544\n","Epoch 53, loss = 0.0155, val.acc = 0.7542\n","Epoch 54, loss = 0.0151, val.acc = 0.7542\n","Epoch 55, loss = 0.0147, val.acc = 0.7540\n","Epoch 56, loss = 0.0143, val.acc = 0.7536\n","Epoch 57, loss = 0.0139, val.acc = 0.7538\n","Epoch 58, loss = 0.0136, val.acc = 0.7536\n","Epoch 59, loss = 0.0132, val.acc = 0.7536\n","Epoch 60, loss = 0.0129, val.acc = 0.7536\n","Epoch 61, loss = 0.0126, val.acc = 0.7536\n","Epoch 62, loss = 0.0123, val.acc = 0.7536\n","Epoch 63, loss = 0.0120, val.acc = 0.7540\n","Epoch 64, loss = 0.0118, val.acc = 0.7536\n","Epoch 65, loss = 0.0115, val.acc = 0.7540\n","Epoch 66, loss = 0.0112, val.acc = 0.7540\n","Epoch 67, loss = 0.0110, val.acc = 0.7540\n","Epoch 68, loss = 0.0108, val.acc = 0.7542\n","Epoch 69, loss = 0.0105, val.acc = 0.7546\n","Epoch 70, loss = 0.0103, val.acc = 0.7546\n","Epoch 71, loss = 0.0101, val.acc = 0.7548\n","Epoch 72, loss = 0.0099, val.acc = 0.7546\n","Epoch 73, loss = 0.0097, val.acc = 0.7546\n","Epoch 74, loss = 0.0095, val.acc = 0.7546\n","Epoch 75, loss = 0.0094, val.acc = 0.7546\n","Epoch 76, loss = 0.0092, val.acc = 0.7548\n","Epoch 77, loss = 0.0090, val.acc = 0.7546\n","Epoch 78, loss = 0.0089, val.acc = 0.7546\n","Epoch 79, loss = 0.0087, val.acc = 0.7546\n","Epoch 80, loss = 0.0085, val.acc = 0.7544\n","Epoch 81, loss = 0.0084, val.acc = 0.7544\n","Epoch 82, loss = 0.0083, val.acc = 0.7544\n","Epoch 83, loss = 0.0081, val.acc = 0.7544\n","Epoch 84, loss = 0.0080, val.acc = 0.7544\n","Epoch 85, loss = 0.0079, val.acc = 0.7544\n","Epoch 86, loss = 0.0077, val.acc = 0.7542\n","Epoch 87, loss = 0.0076, val.acc = 0.7542\n","Epoch 88, loss = 0.0075, val.acc = 0.7544\n","Epoch 89, loss = 0.0074, val.acc = 0.7546\n","Epoch 90, loss = 0.0073, val.acc = 0.7546\n","Epoch 91, loss = 0.0071, val.acc = 0.7548\n","Epoch 92, loss = 0.0070, val.acc = 0.7550\n","Epoch 93, loss = 0.0069, val.acc = 0.7552\n","Epoch 94, loss = 0.0068, val.acc = 0.7552\n","Epoch 95, loss = 0.0067, val.acc = 0.7554\n","Epoch 96, loss = 0.0066, val.acc = 0.7556\n","Epoch 97, loss = 0.0065, val.acc = 0.7556\n","Epoch 98, loss = 0.0065, val.acc = 0.7556\n","Epoch 99, loss = 0.0064, val.acc = 0.7558\n","Rep: 3, Layer: 3, te.acc = 0.7452\n","\n","\n","Rep 4\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","LAYER:0\n","Sequential()\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.7907, val.acc = 0.4340\n","Epoch 1, loss = 1.5953, val.acc = 0.4578\n","Epoch 2, loss = 1.5045, val.acc = 0.4678\n","Epoch 3, loss = 1.4236, val.acc = 0.4988\n","Epoch 4, loss = 1.3575, val.acc = 0.5114\n","Epoch 5, loss = 1.3095, val.acc = 0.5268\n","Epoch 6, loss = 1.2691, val.acc = 0.5374\n","Epoch 7, loss = 1.2332, val.acc = 0.5454\n","Epoch 8, loss = 1.2019, val.acc = 0.5560\n","Epoch 9, loss = 1.1744, val.acc = 0.5600\n","Epoch 10, loss = 1.1487, val.acc = 0.5688\n","Epoch 11, loss = 1.1238, val.acc = 0.5786\n","Epoch 12, loss = 1.1006, val.acc = 0.5866\n","Epoch 13, loss = 1.0792, val.acc = 0.5962\n","Epoch 14, loss = 1.0590, val.acc = 0.5990\n","Epoch 15, loss = 1.0404, val.acc = 0.6062\n","Epoch 16, loss = 1.0226, val.acc = 0.6098\n","Epoch 17, loss = 1.0049, val.acc = 0.6096\n","Epoch 18, loss = 0.9935, val.acc = 0.6008\n","Epoch 19, loss = 0.9774, val.acc = 0.6194\n","Epoch 20, loss = 0.9615, val.acc = 0.6158\n","Epoch 21, loss = 0.9532, val.acc = 0.6078\n","Epoch 22, loss = 0.9380, val.acc = 0.6300\n","Epoch 23, loss = 0.9260, val.acc = 0.6302\n","Epoch 24, loss = 0.9179, val.acc = 0.6190\n","Epoch 25, loss = 0.9026, val.acc = 0.6360\n","Epoch 26, loss = 0.8950, val.acc = 0.6244\n","Epoch 27, loss = 0.8836, val.acc = 0.6360\n","Epoch 28, loss = 0.8649, val.acc = 0.6408\n","Epoch 29, loss = 0.8732, val.acc = 0.6402\n","Epoch 30, loss = 0.8574, val.acc = 0.6262\n","Epoch 31, loss = 0.8444, val.acc = 0.6386\n","Epoch 32, loss = 0.8420, val.acc = 0.6308\n","Epoch 33, loss = 0.8278, val.acc = 0.6394\n","Epoch 34, loss = 0.8209, val.acc = 0.6384\n","Epoch 35, loss = 0.8103, val.acc = 0.6444\n","Epoch 36, loss = 0.8092, val.acc = 0.6288\n","Epoch 37, loss = 0.7966, val.acc = 0.6428\n","Epoch 38, loss = 0.7935, val.acc = 0.6304\n","Epoch 39, loss = 0.7810, val.acc = 0.6446\n","Epoch 40, loss = 0.7766, val.acc = 0.6316\n","Epoch 41, loss = 0.7656, val.acc = 0.6386\n","Epoch 42, loss = 0.7594, val.acc = 0.6540\n","Epoch 43, loss = 0.7574, val.acc = 0.6332\n","Epoch 44, loss = 0.7461, val.acc = 0.6488\n","Epoch 45, loss = 0.7400, val.acc = 0.6336\n","Epoch 46, loss = 0.7358, val.acc = 0.6478\n","Epoch 47, loss = 0.7238, val.acc = 0.6522\n","Epoch 48, loss = 0.7276, val.acc = 0.6408\n","Epoch 49, loss = 0.7138, val.acc = 0.6448\n","Epoch 50, loss = 0.6990, val.acc = 0.6330\n","Epoch 51, loss = 0.7081, val.acc = 0.6536\n","Epoch 52, loss = 0.6974, val.acc = 0.6426\n","Epoch 53, loss = 0.6951, val.acc = 0.6512\n","Epoch 54, loss = 0.6833, val.acc = 0.6492\n","Epoch 55, loss = 0.6765, val.acc = 0.6516\n","Epoch 56, loss = 0.6720, val.acc = 0.6440\n","Epoch 57, loss = 0.6650, val.acc = 0.6464\n","Epoch 58, loss = 0.6621, val.acc = 0.6474\n","Epoch 59, loss = 0.6547, val.acc = 0.6568\n","Epoch 60, loss = 0.6452, val.acc = 0.6504\n","Epoch 61, loss = 0.6558, val.acc = 0.6542\n","Epoch 62, loss = 0.6414, val.acc = 0.6548\n","Epoch 63, loss = 0.6253, val.acc = 0.6548\n","Epoch 64, loss = 0.6362, val.acc = 0.6484\n","Epoch 65, loss = 0.6207, val.acc = 0.6504\n","Epoch 66, loss = 0.6146, val.acc = 0.6504\n","Epoch 67, loss = 0.6257, val.acc = 0.6442\n","Epoch 68, loss = 0.6078, val.acc = 0.6582\n","Epoch 69, loss = 0.5961, val.acc = 0.6560\n","Epoch 70, loss = 0.6108, val.acc = 0.6518\n","Epoch 71, loss = 0.5932, val.acc = 0.6508\n","Epoch 72, loss = 0.5914, val.acc = 0.6394\n","Epoch 73, loss = 0.5901, val.acc = 0.6576\n","Epoch 74, loss = 0.5752, val.acc = 0.6548\n","Epoch 75, loss = 0.5868, val.acc = 0.6540\n","Epoch 76, loss = 0.5694, val.acc = 0.6412\n","Epoch 77, loss = 0.5668, val.acc = 0.6590\n","Epoch 78, loss = 0.5771, val.acc = 0.6518\n","Epoch 79, loss = 0.5562, val.acc = 0.6560\n","Epoch 80, loss = 0.5540, val.acc = 0.6594\n","Epoch 81, loss = 0.5506, val.acc = 0.6482\n","Epoch 82, loss = 0.5534, val.acc = 0.6534\n","Epoch 83, loss = 0.5502, val.acc = 0.6496\n","Epoch 84, loss = 0.5368, val.acc = 0.6476\n","Epoch 85, loss = 0.5379, val.acc = 0.6450\n","Epoch 86, loss = 0.5365, val.acc = 0.6570\n","Epoch 87, loss = 0.5191, val.acc = 0.6558\n","Epoch 88, loss = 0.5365, val.acc = 0.6456\n","Epoch 89, loss = 0.5199, val.acc = 0.6480\n","Epoch 90, loss = 0.5130, val.acc = 0.6510\n","Epoch 91, loss = 0.5304, val.acc = 0.6460\n","Epoch 92, loss = 0.5080, val.acc = 0.6552\n","Epoch 93, loss = 0.4964, val.acc = 0.6540\n","Epoch 94, loss = 0.5057, val.acc = 0.6356\n","Epoch 95, loss = 0.5121, val.acc = 0.6490\n","Epoch 96, loss = 0.4978, val.acc = 0.6522\n","Epoch 97, loss = 0.4852, val.acc = 0.6344\n","Epoch 98, loss = 0.4830, val.acc = 0.6418\n","Epoch 99, loss = 0.4885, val.acc = 0.6436\n","Rep: 4, Layer: 0, te.acc = 0.6361\n","\n","LAYER:1\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.4702, val.acc = 0.5908\n","Epoch 1, loss = 1.1191, val.acc = 0.6458\n","Epoch 2, loss = 1.0059, val.acc = 0.6644\n","Epoch 3, loss = 0.9463, val.acc = 0.6772\n","Epoch 4, loss = 0.9067, val.acc = 0.6836\n","Epoch 5, loss = 0.8763, val.acc = 0.6918\n","Epoch 6, loss = 0.8507, val.acc = 0.6966\n","Epoch 7, loss = 0.8281, val.acc = 0.7028\n","Epoch 8, loss = 0.8076, val.acc = 0.7054\n","Epoch 9, loss = 0.7884, val.acc = 0.7062\n","Epoch 10, loss = 0.7703, val.acc = 0.7082\n","Epoch 11, loss = 0.7531, val.acc = 0.7088\n","Epoch 12, loss = 0.7365, val.acc = 0.7134\n","Epoch 13, loss = 0.7205, val.acc = 0.7154\n","Epoch 14, loss = 0.7051, val.acc = 0.7178\n","Epoch 15, loss = 0.6901, val.acc = 0.7196\n","Epoch 16, loss = 0.6756, val.acc = 0.7196\n","Epoch 17, loss = 0.6615, val.acc = 0.7220\n","Epoch 18, loss = 0.6477, val.acc = 0.7204\n","Epoch 19, loss = 0.6344, val.acc = 0.7210\n","Epoch 20, loss = 0.6214, val.acc = 0.7228\n","Epoch 21, loss = 0.6087, val.acc = 0.7242\n","Epoch 22, loss = 0.5963, val.acc = 0.7254\n","Epoch 23, loss = 0.5842, val.acc = 0.7256\n","Epoch 24, loss = 0.5723, val.acc = 0.7250\n","Epoch 25, loss = 0.5607, val.acc = 0.7262\n","Epoch 26, loss = 0.5494, val.acc = 0.7272\n","Epoch 27, loss = 0.5383, val.acc = 0.7278\n","Epoch 28, loss = 0.5275, val.acc = 0.7284\n","Epoch 29, loss = 0.5169, val.acc = 0.7290\n","Epoch 30, loss = 0.5065, val.acc = 0.7294\n","Epoch 31, loss = 0.4964, val.acc = 0.7290\n","Epoch 32, loss = 0.4864, val.acc = 0.7302\n","Epoch 33, loss = 0.4767, val.acc = 0.7304\n","Epoch 34, loss = 0.4671, val.acc = 0.7300\n","Epoch 35, loss = 0.4578, val.acc = 0.7288\n","Epoch 36, loss = 0.4487, val.acc = 0.7292\n","Epoch 37, loss = 0.4398, val.acc = 0.7288\n","Epoch 38, loss = 0.4310, val.acc = 0.7290\n","Epoch 39, loss = 0.4224, val.acc = 0.7296\n","Epoch 40, loss = 0.4141, val.acc = 0.7298\n","Epoch 41, loss = 0.4059, val.acc = 0.7302\n","Epoch 42, loss = 0.3979, val.acc = 0.7302\n","Epoch 43, loss = 0.3900, val.acc = 0.7294\n","Epoch 44, loss = 0.3824, val.acc = 0.7292\n","Epoch 45, loss = 0.3749, val.acc = 0.7286\n","Epoch 46, loss = 0.3675, val.acc = 0.7286\n","Epoch 47, loss = 0.3603, val.acc = 0.7294\n","Epoch 48, loss = 0.3532, val.acc = 0.7304\n","Epoch 49, loss = 0.3463, val.acc = 0.7306\n","Epoch 50, loss = 0.3395, val.acc = 0.7310\n","Epoch 51, loss = 0.3328, val.acc = 0.7304\n","Epoch 52, loss = 0.3263, val.acc = 0.7292\n","Epoch 53, loss = 0.3199, val.acc = 0.7298\n","Epoch 54, loss = 0.3136, val.acc = 0.7300\n","Epoch 55, loss = 0.3075, val.acc = 0.7288\n","Epoch 56, loss = 0.3015, val.acc = 0.7276\n","Epoch 57, loss = 0.2957, val.acc = 0.7274\n","Epoch 58, loss = 0.2900, val.acc = 0.7268\n","Epoch 59, loss = 0.2843, val.acc = 0.7266\n","Epoch 60, loss = 0.2788, val.acc = 0.7256\n","Epoch 61, loss = 0.2734, val.acc = 0.7260\n","Epoch 62, loss = 0.2681, val.acc = 0.7256\n","Epoch 63, loss = 0.2629, val.acc = 0.7234\n","Epoch 64, loss = 0.2578, val.acc = 0.7228\n","Epoch 65, loss = 0.2528, val.acc = 0.7220\n","Epoch 66, loss = 0.2479, val.acc = 0.7214\n","Epoch 67, loss = 0.2432, val.acc = 0.7216\n","Epoch 68, loss = 0.2386, val.acc = 0.7206\n","Epoch 69, loss = 0.2340, val.acc = 0.7200\n","Epoch 70, loss = 0.2295, val.acc = 0.7190\n","Epoch 71, loss = 0.2251, val.acc = 0.7182\n","Epoch 72, loss = 0.2209, val.acc = 0.7170\n","Epoch 73, loss = 0.2167, val.acc = 0.7162\n","Epoch 74, loss = 0.2126, val.acc = 0.7160\n","Epoch 75, loss = 0.2086, val.acc = 0.7156\n","Epoch 76, loss = 0.2047, val.acc = 0.7152\n","Epoch 77, loss = 0.2008, val.acc = 0.7138\n","Epoch 78, loss = 0.1971, val.acc = 0.7132\n","Epoch 79, loss = 0.1934, val.acc = 0.7124\n","Epoch 80, loss = 0.1898, val.acc = 0.7124\n","Epoch 81, loss = 0.1863, val.acc = 0.7130\n","Epoch 82, loss = 0.1828, val.acc = 0.7122\n","Epoch 83, loss = 0.1794, val.acc = 0.7118\n","Epoch 84, loss = 0.1761, val.acc = 0.7120\n","Epoch 85, loss = 0.1729, val.acc = 0.7114\n","Epoch 86, loss = 0.1697, val.acc = 0.7108\n","Epoch 87, loss = 0.1667, val.acc = 0.7106\n","Epoch 88, loss = 0.1636, val.acc = 0.7104\n","Epoch 89, loss = 0.1607, val.acc = 0.7100\n","Epoch 90, loss = 0.1578, val.acc = 0.7104\n","Epoch 91, loss = 0.1550, val.acc = 0.7092\n","Epoch 92, loss = 0.1522, val.acc = 0.7094\n","Epoch 93, loss = 0.1495, val.acc = 0.7102\n","Epoch 94, loss = 0.1468, val.acc = 0.7098\n","Epoch 95, loss = 0.1443, val.acc = 0.7096\n","Epoch 96, loss = 0.1417, val.acc = 0.7092\n","Epoch 97, loss = 0.1393, val.acc = 0.7084\n","Epoch 98, loss = 0.1368, val.acc = 0.7078\n","Epoch 99, loss = 0.1345, val.acc = 0.7078\n","Rep: 4, Layer: 1, te.acc = 0.6998\n","\n","LAYER:2\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.3002, val.acc = 0.6538\n","Epoch 1, loss = 0.9403, val.acc = 0.6998\n","Epoch 2, loss = 0.8264, val.acc = 0.7210\n","Epoch 3, loss = 0.7523, val.acc = 0.7326\n","Epoch 4, loss = 0.6973, val.acc = 0.7380\n","Epoch 5, loss = 0.6530, val.acc = 0.7434\n","Epoch 6, loss = 0.6154, val.acc = 0.7482\n","Epoch 7, loss = 0.5822, val.acc = 0.7518\n","Epoch 8, loss = 0.5521, val.acc = 0.7536\n","Epoch 9, loss = 0.5244, val.acc = 0.7574\n","Epoch 10, loss = 0.4984, val.acc = 0.7588\n","Epoch 11, loss = 0.4741, val.acc = 0.7604\n","Epoch 12, loss = 0.4510, val.acc = 0.7608\n","Epoch 13, loss = 0.4291, val.acc = 0.7616\n","Epoch 14, loss = 0.4081, val.acc = 0.7610\n","Epoch 15, loss = 0.3882, val.acc = 0.7620\n","Epoch 16, loss = 0.3690, val.acc = 0.7610\n","Epoch 17, loss = 0.3507, val.acc = 0.7610\n","Epoch 18, loss = 0.3332, val.acc = 0.7612\n","Epoch 19, loss = 0.3164, val.acc = 0.7620\n","Epoch 20, loss = 0.3004, val.acc = 0.7616\n","Epoch 21, loss = 0.2850, val.acc = 0.7620\n","Epoch 22, loss = 0.2703, val.acc = 0.7620\n","Epoch 23, loss = 0.2563, val.acc = 0.7628\n","Epoch 24, loss = 0.2429, val.acc = 0.7632\n","Epoch 25, loss = 0.2303, val.acc = 0.7640\n","Epoch 26, loss = 0.2182, val.acc = 0.7644\n","Epoch 27, loss = 0.2068, val.acc = 0.7636\n","Epoch 28, loss = 0.1959, val.acc = 0.7636\n","Epoch 29, loss = 0.1856, val.acc = 0.7626\n","Epoch 30, loss = 0.1759, val.acc = 0.7624\n","Epoch 31, loss = 0.1667, val.acc = 0.7614\n","Epoch 32, loss = 0.1580, val.acc = 0.7614\n","Epoch 33, loss = 0.1499, val.acc = 0.7614\n","Epoch 34, loss = 0.1422, val.acc = 0.7610\n","Epoch 35, loss = 0.1349, val.acc = 0.7610\n","Epoch 36, loss = 0.1281, val.acc = 0.7612\n","Epoch 37, loss = 0.1216, val.acc = 0.7604\n","Epoch 38, loss = 0.1156, val.acc = 0.7612\n","Epoch 39, loss = 0.1099, val.acc = 0.7616\n","Epoch 40, loss = 0.1046, val.acc = 0.7616\n","Epoch 41, loss = 0.0996, val.acc = 0.7620\n","Epoch 42, loss = 0.0949, val.acc = 0.7620\n","Epoch 43, loss = 0.0905, val.acc = 0.7618\n","Epoch 44, loss = 0.0864, val.acc = 0.7610\n","Epoch 45, loss = 0.0825, val.acc = 0.7604\n","Epoch 46, loss = 0.0788, val.acc = 0.7604\n","Epoch 47, loss = 0.0754, val.acc = 0.7594\n","Epoch 48, loss = 0.0722, val.acc = 0.7600\n","Epoch 49, loss = 0.0692, val.acc = 0.7598\n","Epoch 50, loss = 0.0663, val.acc = 0.7588\n","Epoch 51, loss = 0.0636, val.acc = 0.7580\n","Epoch 52, loss = 0.0611, val.acc = 0.7586\n","Epoch 53, loss = 0.0588, val.acc = 0.7584\n","Epoch 54, loss = 0.0565, val.acc = 0.7588\n","Epoch 55, loss = 0.0544, val.acc = 0.7584\n","Epoch 56, loss = 0.0524, val.acc = 0.7584\n","Epoch 57, loss = 0.0505, val.acc = 0.7586\n","Epoch 58, loss = 0.0488, val.acc = 0.7592\n","Epoch 59, loss = 0.0471, val.acc = 0.7586\n","Epoch 60, loss = 0.0455, val.acc = 0.7588\n","Epoch 61, loss = 0.0440, val.acc = 0.7588\n","Epoch 62, loss = 0.0426, val.acc = 0.7586\n","Epoch 63, loss = 0.0412, val.acc = 0.7586\n","Epoch 64, loss = 0.0399, val.acc = 0.7590\n","Epoch 65, loss = 0.0387, val.acc = 0.7590\n","Epoch 66, loss = 0.0375, val.acc = 0.7590\n","Epoch 67, loss = 0.0364, val.acc = 0.7586\n","Epoch 68, loss = 0.0354, val.acc = 0.7582\n","Epoch 69, loss = 0.0344, val.acc = 0.7582\n","Epoch 70, loss = 0.0334, val.acc = 0.7586\n","Epoch 71, loss = 0.0325, val.acc = 0.7584\n","Epoch 72, loss = 0.0316, val.acc = 0.7586\n","Epoch 73, loss = 0.0308, val.acc = 0.7584\n","Epoch 74, loss = 0.0300, val.acc = 0.7588\n","Epoch 75, loss = 0.0292, val.acc = 0.7588\n","Epoch 76, loss = 0.0285, val.acc = 0.7590\n","Epoch 77, loss = 0.0278, val.acc = 0.7592\n","Epoch 78, loss = 0.0272, val.acc = 0.7596\n","Epoch 79, loss = 0.0265, val.acc = 0.7596\n","Epoch 80, loss = 0.0259, val.acc = 0.7598\n","Epoch 81, loss = 0.0253, val.acc = 0.7596\n","Epoch 82, loss = 0.0247, val.acc = 0.7596\n","Epoch 83, loss = 0.0242, val.acc = 0.7596\n","Epoch 84, loss = 0.0237, val.acc = 0.7596\n","Epoch 85, loss = 0.0232, val.acc = 0.7602\n","Epoch 86, loss = 0.0227, val.acc = 0.7608\n","Epoch 87, loss = 0.0222, val.acc = 0.7610\n","Epoch 88, loss = 0.0218, val.acc = 0.7612\n","Epoch 89, loss = 0.0213, val.acc = 0.7606\n","Epoch 90, loss = 0.0209, val.acc = 0.7604\n","Epoch 91, loss = 0.0205, val.acc = 0.7602\n","Epoch 92, loss = 0.0201, val.acc = 0.7600\n","Epoch 93, loss = 0.0197, val.acc = 0.7600\n","Epoch 94, loss = 0.0194, val.acc = 0.7598\n","Epoch 95, loss = 0.0190, val.acc = 0.7600\n","Epoch 96, loss = 0.0187, val.acc = 0.7602\n","Epoch 97, loss = 0.0183, val.acc = 0.7602\n","Epoch 98, loss = 0.0180, val.acc = 0.7600\n","Epoch 99, loss = 0.0177, val.acc = 0.7594\n","Rep: 4, Layer: 2, te.acc = 0.7392\n","\n","LAYER:3\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.3381, val.acc = 0.6680\n","Epoch 1, loss = 0.8110, val.acc = 0.7148\n","Epoch 2, loss = 0.6433, val.acc = 0.7364\n","Epoch 3, loss = 0.5377, val.acc = 0.7436\n","Epoch 4, loss = 0.4600, val.acc = 0.7516\n","Epoch 5, loss = 0.3981, val.acc = 0.7528\n","Epoch 6, loss = 0.3468, val.acc = 0.7588\n","Epoch 7, loss = 0.3033, val.acc = 0.7600\n","Epoch 8, loss = 0.2661, val.acc = 0.7646\n","Epoch 9, loss = 0.2342, val.acc = 0.7680\n","Epoch 10, loss = 0.2068, val.acc = 0.7658\n","Epoch 11, loss = 0.1832, val.acc = 0.7652\n","Epoch 12, loss = 0.1630, val.acc = 0.7634\n","Epoch 13, loss = 0.1455, val.acc = 0.7646\n","Epoch 14, loss = 0.1305, val.acc = 0.7656\n","Epoch 15, loss = 0.1175, val.acc = 0.7662\n","Epoch 16, loss = 0.1063, val.acc = 0.7660\n","Epoch 17, loss = 0.0966, val.acc = 0.7658\n","Epoch 18, loss = 0.0881, val.acc = 0.7664\n","Epoch 19, loss = 0.0807, val.acc = 0.7666\n","Epoch 20, loss = 0.0742, val.acc = 0.7666\n","Epoch 21, loss = 0.0685, val.acc = 0.7658\n","Epoch 22, loss = 0.0634, val.acc = 0.7652\n","Epoch 23, loss = 0.0589, val.acc = 0.7638\n","Epoch 24, loss = 0.0549, val.acc = 0.7634\n","Epoch 25, loss = 0.0513, val.acc = 0.7630\n","Epoch 26, loss = 0.0481, val.acc = 0.7636\n","Epoch 27, loss = 0.0452, val.acc = 0.7630\n","Epoch 28, loss = 0.0425, val.acc = 0.7628\n","Epoch 29, loss = 0.0402, val.acc = 0.7628\n","Epoch 30, loss = 0.0380, val.acc = 0.7624\n","Epoch 31, loss = 0.0360, val.acc = 0.7630\n","Epoch 32, loss = 0.0342, val.acc = 0.7640\n","Epoch 33, loss = 0.0325, val.acc = 0.7644\n","Epoch 34, loss = 0.0310, val.acc = 0.7644\n","Epoch 35, loss = 0.0296, val.acc = 0.7644\n","Epoch 36, loss = 0.0283, val.acc = 0.7644\n","Epoch 37, loss = 0.0270, val.acc = 0.7644\n","Epoch 38, loss = 0.0259, val.acc = 0.7648\n","Epoch 39, loss = 0.0249, val.acc = 0.7650\n","Epoch 40, loss = 0.0239, val.acc = 0.7654\n","Epoch 41, loss = 0.0230, val.acc = 0.7656\n","Epoch 42, loss = 0.0221, val.acc = 0.7652\n","Epoch 43, loss = 0.0213, val.acc = 0.7654\n","Epoch 44, loss = 0.0206, val.acc = 0.7652\n","Epoch 45, loss = 0.0199, val.acc = 0.7652\n","Epoch 46, loss = 0.0192, val.acc = 0.7650\n","Epoch 47, loss = 0.0186, val.acc = 0.7650\n","Epoch 48, loss = 0.0180, val.acc = 0.7654\n","Epoch 49, loss = 0.0174, val.acc = 0.7652\n","Epoch 50, loss = 0.0169, val.acc = 0.7648\n","Epoch 51, loss = 0.0164, val.acc = 0.7646\n","Epoch 52, loss = 0.0159, val.acc = 0.7646\n","Epoch 53, loss = 0.0155, val.acc = 0.7642\n","Epoch 54, loss = 0.0151, val.acc = 0.7644\n","Epoch 55, loss = 0.0147, val.acc = 0.7644\n","Epoch 56, loss = 0.0143, val.acc = 0.7644\n","Epoch 57, loss = 0.0139, val.acc = 0.7646\n","Epoch 58, loss = 0.0135, val.acc = 0.7644\n","Epoch 59, loss = 0.0132, val.acc = 0.7646\n","Epoch 60, loss = 0.0129, val.acc = 0.7644\n","Epoch 61, loss = 0.0126, val.acc = 0.7644\n","Epoch 62, loss = 0.0123, val.acc = 0.7646\n","Epoch 63, loss = 0.0120, val.acc = 0.7646\n","Epoch 64, loss = 0.0117, val.acc = 0.7644\n","Epoch 65, loss = 0.0115, val.acc = 0.7644\n","Epoch 66, loss = 0.0112, val.acc = 0.7646\n","Epoch 67, loss = 0.0110, val.acc = 0.7642\n","Epoch 68, loss = 0.0107, val.acc = 0.7642\n","Epoch 69, loss = 0.0105, val.acc = 0.7638\n","Epoch 70, loss = 0.0103, val.acc = 0.7638\n","Epoch 71, loss = 0.0101, val.acc = 0.7638\n","Epoch 72, loss = 0.0099, val.acc = 0.7638\n","Epoch 73, loss = 0.0097, val.acc = 0.7638\n","Epoch 74, loss = 0.0095, val.acc = 0.7636\n","Epoch 75, loss = 0.0093, val.acc = 0.7636\n","Epoch 76, loss = 0.0092, val.acc = 0.7636\n","Epoch 77, loss = 0.0090, val.acc = 0.7636\n","Epoch 78, loss = 0.0088, val.acc = 0.7636\n","Epoch 79, loss = 0.0087, val.acc = 0.7636\n","Epoch 80, loss = 0.0085, val.acc = 0.7634\n","Epoch 81, loss = 0.0084, val.acc = 0.7634\n","Epoch 82, loss = 0.0082, val.acc = 0.7634\n","Epoch 83, loss = 0.0081, val.acc = 0.7634\n","Epoch 84, loss = 0.0080, val.acc = 0.7634\n","Epoch 85, loss = 0.0078, val.acc = 0.7634\n","Epoch 86, loss = 0.0077, val.acc = 0.7638\n","Epoch 87, loss = 0.0076, val.acc = 0.7636\n","Epoch 88, loss = 0.0075, val.acc = 0.7636\n","Epoch 89, loss = 0.0074, val.acc = 0.7636\n","Epoch 90, loss = 0.0072, val.acc = 0.7636\n","Epoch 91, loss = 0.0071, val.acc = 0.7636\n","Epoch 92, loss = 0.0070, val.acc = 0.7636\n","Epoch 93, loss = 0.0069, val.acc = 0.7636\n","Epoch 94, loss = 0.0068, val.acc = 0.7634\n","Epoch 95, loss = 0.0067, val.acc = 0.7634\n","Epoch 96, loss = 0.0066, val.acc = 0.7634\n","Epoch 97, loss = 0.0065, val.acc = 0.7634\n","Epoch 98, loss = 0.0064, val.acc = 0.7634\n","Epoch 99, loss = 0.0064, val.acc = 0.7636\n","Rep: 4, Layer: 3, te.acc = 0.7402\n","\n","\n","Rep 5\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","LAYER:0\n","Sequential()\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.8032, val.acc = 0.4312\n","Epoch 1, loss = 1.6081, val.acc = 0.4578\n","Epoch 2, loss = 1.5170, val.acc = 0.4738\n","Epoch 3, loss = 1.4383, val.acc = 0.4950\n","Epoch 4, loss = 1.3748, val.acc = 0.5124\n","Epoch 5, loss = 1.3264, val.acc = 0.5262\n","Epoch 6, loss = 1.2860, val.acc = 0.5370\n","Epoch 7, loss = 1.2504, val.acc = 0.5434\n","Epoch 8, loss = 1.2185, val.acc = 0.5498\n","Epoch 9, loss = 1.1898, val.acc = 0.5590\n","Epoch 10, loss = 1.1645, val.acc = 0.5630\n","Epoch 11, loss = 1.1415, val.acc = 0.5722\n","Epoch 12, loss = 1.1187, val.acc = 0.5782\n","Epoch 13, loss = 1.0957, val.acc = 0.5858\n","Epoch 14, loss = 1.0743, val.acc = 0.5944\n","Epoch 15, loss = 1.0523, val.acc = 0.6108\n","Epoch 16, loss = 1.0428, val.acc = 0.6014\n","Epoch 17, loss = 1.0207, val.acc = 0.5944\n","Epoch 18, loss = 1.0041, val.acc = 0.6012\n","Epoch 19, loss = 0.9885, val.acc = 0.6102\n","Epoch 20, loss = 0.9744, val.acc = 0.6170\n","Epoch 21, loss = 0.9625, val.acc = 0.6066\n","Epoch 22, loss = 0.9565, val.acc = 0.6266\n","Epoch 23, loss = 0.9384, val.acc = 0.6308\n","Epoch 24, loss = 0.9145, val.acc = 0.6370\n","Epoch 25, loss = 0.9189, val.acc = 0.6306\n","Epoch 26, loss = 0.9003, val.acc = 0.6364\n","Epoch 27, loss = 0.8958, val.acc = 0.6196\n","Epoch 28, loss = 0.8822, val.acc = 0.6394\n","Epoch 29, loss = 0.8697, val.acc = 0.6346\n","Epoch 30, loss = 0.8645, val.acc = 0.6278\n","Epoch 31, loss = 0.8432, val.acc = 0.6084\n","Epoch 32, loss = 0.8445, val.acc = 0.6276\n","Epoch 33, loss = 0.8341, val.acc = 0.6312\n","Epoch 34, loss = 0.8188, val.acc = 0.6374\n","Epoch 35, loss = 0.8180, val.acc = 0.6386\n","Epoch 36, loss = 0.8123, val.acc = 0.6448\n","Epoch 37, loss = 0.7959, val.acc = 0.6484\n","Epoch 38, loss = 0.7933, val.acc = 0.6276\n","Epoch 39, loss = 0.7837, val.acc = 0.6378\n","Epoch 40, loss = 0.7729, val.acc = 0.6388\n","Epoch 41, loss = 0.7681, val.acc = 0.6486\n","Epoch 42, loss = 0.7628, val.acc = 0.6262\n","Epoch 43, loss = 0.7544, val.acc = 0.6516\n","Epoch 44, loss = 0.7444, val.acc = 0.6352\n","Epoch 45, loss = 0.7390, val.acc = 0.6552\n","Epoch 46, loss = 0.7314, val.acc = 0.6334\n","Epoch 47, loss = 0.7245, val.acc = 0.6540\n","Epoch 48, loss = 0.7174, val.acc = 0.6358\n","Epoch 49, loss = 0.7122, val.acc = 0.6528\n","Epoch 50, loss = 0.7045, val.acc = 0.6336\n","Epoch 51, loss = 0.6997, val.acc = 0.6478\n","Epoch 52, loss = 0.6946, val.acc = 0.6398\n","Epoch 53, loss = 0.6827, val.acc = 0.6534\n","Epoch 54, loss = 0.6907, val.acc = 0.6394\n","Epoch 55, loss = 0.6730, val.acc = 0.6530\n","Epoch 56, loss = 0.6697, val.acc = 0.6368\n","Epoch 57, loss = 0.6635, val.acc = 0.6512\n","Epoch 58, loss = 0.6575, val.acc = 0.6346\n","Epoch 59, loss = 0.6432, val.acc = 0.6554\n","Epoch 60, loss = 0.6552, val.acc = 0.6288\n","Epoch 61, loss = 0.6438, val.acc = 0.6362\n","Epoch 62, loss = 0.6387, val.acc = 0.6562\n","Epoch 63, loss = 0.6271, val.acc = 0.6478\n","Epoch 64, loss = 0.6318, val.acc = 0.6408\n","Epoch 65, loss = 0.6127, val.acc = 0.6542\n","Epoch 66, loss = 0.6114, val.acc = 0.6394\n","Epoch 67, loss = 0.6218, val.acc = 0.6396\n","Epoch 68, loss = 0.6035, val.acc = 0.6530\n","Epoch 69, loss = 0.5971, val.acc = 0.6386\n","Epoch 70, loss = 0.6021, val.acc = 0.6434\n","Epoch 71, loss = 0.5957, val.acc = 0.6430\n","Epoch 72, loss = 0.5823, val.acc = 0.6504\n","Epoch 73, loss = 0.5820, val.acc = 0.6348\n","Epoch 74, loss = 0.5798, val.acc = 0.6426\n","Epoch 75, loss = 0.5759, val.acc = 0.6380\n","Epoch 76, loss = 0.5621, val.acc = 0.6518\n","Epoch 77, loss = 0.5656, val.acc = 0.6488\n","Epoch 78, loss = 0.5741, val.acc = 0.6364\n","Epoch 79, loss = 0.5509, val.acc = 0.6478\n","Epoch 80, loss = 0.5492, val.acc = 0.6516\n","Epoch 81, loss = 0.5535, val.acc = 0.6402\n","Epoch 82, loss = 0.5423, val.acc = 0.6426\n","Epoch 83, loss = 0.5362, val.acc = 0.6530\n","Epoch 84, loss = 0.5455, val.acc = 0.6382\n","Epoch 85, loss = 0.5293, val.acc = 0.6364\n","Epoch 86, loss = 0.5306, val.acc = 0.6508\n","Epoch 87, loss = 0.5239, val.acc = 0.6394\n","Epoch 88, loss = 0.5177, val.acc = 0.6308\n","Epoch 89, loss = 0.5207, val.acc = 0.6464\n","Epoch 90, loss = 0.5187, val.acc = 0.6412\n","Epoch 91, loss = 0.5042, val.acc = 0.6434\n","Epoch 92, loss = 0.5083, val.acc = 0.6486\n","Epoch 93, loss = 0.5055, val.acc = 0.6408\n","Epoch 94, loss = 0.4949, val.acc = 0.6350\n","Epoch 95, loss = 0.4984, val.acc = 0.6502\n","Epoch 96, loss = 0.4961, val.acc = 0.6416\n","Epoch 97, loss = 0.4839, val.acc = 0.6370\n","Epoch 98, loss = 0.4886, val.acc = 0.6510\n","Epoch 99, loss = 0.4843, val.acc = 0.6388\n","Rep: 5, Layer: 0, te.acc = 0.6231\n","\n","LAYER:1\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.4783, val.acc = 0.5834\n","Epoch 1, loss = 1.1264, val.acc = 0.6364\n","Epoch 2, loss = 1.0124, val.acc = 0.6614\n","Epoch 3, loss = 0.9507, val.acc = 0.6718\n","Epoch 4, loss = 0.9095, val.acc = 0.6788\n","Epoch 5, loss = 0.8775, val.acc = 0.6862\n","Epoch 6, loss = 0.8506, val.acc = 0.6930\n","Epoch 7, loss = 0.8270, val.acc = 0.6962\n","Epoch 8, loss = 0.8056, val.acc = 0.7010\n","Epoch 9, loss = 0.7858, val.acc = 0.7060\n","Epoch 10, loss = 0.7672, val.acc = 0.7068\n","Epoch 11, loss = 0.7495, val.acc = 0.7094\n","Epoch 12, loss = 0.7326, val.acc = 0.7120\n","Epoch 13, loss = 0.7164, val.acc = 0.7126\n","Epoch 14, loss = 0.7007, val.acc = 0.7144\n","Epoch 15, loss = 0.6856, val.acc = 0.7170\n","Epoch 16, loss = 0.6709, val.acc = 0.7178\n","Epoch 17, loss = 0.6565, val.acc = 0.7172\n","Epoch 18, loss = 0.6426, val.acc = 0.7172\n","Epoch 19, loss = 0.6289, val.acc = 0.7194\n","Epoch 20, loss = 0.6156, val.acc = 0.7206\n","Epoch 21, loss = 0.6027, val.acc = 0.7214\n","Epoch 22, loss = 0.5900, val.acc = 0.7212\n","Epoch 23, loss = 0.5777, val.acc = 0.7226\n","Epoch 24, loss = 0.5656, val.acc = 0.7240\n","Epoch 25, loss = 0.5539, val.acc = 0.7258\n","Epoch 26, loss = 0.5425, val.acc = 0.7256\n","Epoch 27, loss = 0.5312, val.acc = 0.7246\n","Epoch 28, loss = 0.5202, val.acc = 0.7240\n","Epoch 29, loss = 0.5095, val.acc = 0.7260\n","Epoch 30, loss = 0.4991, val.acc = 0.7262\n","Epoch 31, loss = 0.4889, val.acc = 0.7272\n","Epoch 32, loss = 0.4789, val.acc = 0.7276\n","Epoch 33, loss = 0.4692, val.acc = 0.7272\n","Epoch 34, loss = 0.4596, val.acc = 0.7278\n","Epoch 35, loss = 0.4503, val.acc = 0.7266\n","Epoch 36, loss = 0.4412, val.acc = 0.7284\n","Epoch 37, loss = 0.4323, val.acc = 0.7294\n","Epoch 38, loss = 0.4236, val.acc = 0.7276\n","Epoch 39, loss = 0.4151, val.acc = 0.7270\n","Epoch 40, loss = 0.4067, val.acc = 0.7274\n","Epoch 41, loss = 0.3986, val.acc = 0.7272\n","Epoch 42, loss = 0.3906, val.acc = 0.7264\n","Epoch 43, loss = 0.3827, val.acc = 0.7270\n","Epoch 44, loss = 0.3750, val.acc = 0.7274\n","Epoch 45, loss = 0.3676, val.acc = 0.7276\n","Epoch 46, loss = 0.3601, val.acc = 0.7268\n","Epoch 47, loss = 0.3529, val.acc = 0.7262\n","Epoch 48, loss = 0.3458, val.acc = 0.7266\n","Epoch 49, loss = 0.3389, val.acc = 0.7268\n","Epoch 50, loss = 0.3321, val.acc = 0.7270\n","Epoch 51, loss = 0.3254, val.acc = 0.7280\n","Epoch 52, loss = 0.3190, val.acc = 0.7274\n","Epoch 53, loss = 0.3126, val.acc = 0.7272\n","Epoch 54, loss = 0.3064, val.acc = 0.7254\n","Epoch 55, loss = 0.3003, val.acc = 0.7248\n","Epoch 56, loss = 0.2944, val.acc = 0.7248\n","Epoch 57, loss = 0.2885, val.acc = 0.7240\n","Epoch 58, loss = 0.2830, val.acc = 0.7246\n","Epoch 59, loss = 0.2777, val.acc = 0.7236\n","Epoch 60, loss = 0.2718, val.acc = 0.7228\n","Epoch 61, loss = 0.2665, val.acc = 0.7240\n","Epoch 62, loss = 0.2613, val.acc = 0.7238\n","Epoch 63, loss = 0.2559, val.acc = 0.7242\n","Epoch 64, loss = 0.2510, val.acc = 0.7236\n","Epoch 65, loss = 0.2460, val.acc = 0.7238\n","Epoch 66, loss = 0.2411, val.acc = 0.7238\n","Epoch 67, loss = 0.2364, val.acc = 0.7224\n","Epoch 68, loss = 0.2318, val.acc = 0.7232\n","Epoch 69, loss = 0.2272, val.acc = 0.7220\n","Epoch 70, loss = 0.2229, val.acc = 0.7228\n","Epoch 71, loss = 0.2185, val.acc = 0.7224\n","Epoch 72, loss = 0.2143, val.acc = 0.7218\n","Epoch 73, loss = 0.2102, val.acc = 0.7216\n","Epoch 74, loss = 0.2062, val.acc = 0.7212\n","Epoch 75, loss = 0.2023, val.acc = 0.7206\n","Epoch 76, loss = 0.1984, val.acc = 0.7206\n","Epoch 77, loss = 0.1946, val.acc = 0.7204\n","Epoch 78, loss = 0.1909, val.acc = 0.7194\n","Epoch 79, loss = 0.1873, val.acc = 0.7192\n","Epoch 80, loss = 0.1837, val.acc = 0.7178\n","Epoch 81, loss = 0.1803, val.acc = 0.7188\n","Epoch 82, loss = 0.1769, val.acc = 0.7186\n","Epoch 83, loss = 0.1736, val.acc = 0.7180\n","Epoch 84, loss = 0.1703, val.acc = 0.7178\n","Epoch 85, loss = 0.1672, val.acc = 0.7178\n","Epoch 86, loss = 0.1640, val.acc = 0.7174\n","Epoch 87, loss = 0.1610, val.acc = 0.7178\n","Epoch 88, loss = 0.1580, val.acc = 0.7172\n","Epoch 89, loss = 0.1551, val.acc = 0.7178\n","Epoch 90, loss = 0.1523, val.acc = 0.7176\n","Epoch 91, loss = 0.1495, val.acc = 0.7168\n","Epoch 92, loss = 0.1468, val.acc = 0.7164\n","Epoch 93, loss = 0.1442, val.acc = 0.7164\n","Epoch 94, loss = 0.1416, val.acc = 0.7164\n","Epoch 95, loss = 0.1391, val.acc = 0.7162\n","Epoch 96, loss = 0.1366, val.acc = 0.7156\n","Epoch 97, loss = 0.1341, val.acc = 0.7154\n","Epoch 98, loss = 0.1318, val.acc = 0.7154\n","Epoch 99, loss = 0.1295, val.acc = 0.7162\n","Rep: 5, Layer: 1, te.acc = 0.7038\n","\n","LAYER:2\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.2963, val.acc = 0.6528\n","Epoch 1, loss = 0.9291, val.acc = 0.6940\n","Epoch 2, loss = 0.8139, val.acc = 0.7180\n","Epoch 3, loss = 0.7422, val.acc = 0.7274\n","Epoch 4, loss = 0.6891, val.acc = 0.7314\n","Epoch 5, loss = 0.6459, val.acc = 0.7346\n","Epoch 6, loss = 0.6088, val.acc = 0.7366\n","Epoch 7, loss = 0.5758, val.acc = 0.7428\n","Epoch 8, loss = 0.5457, val.acc = 0.7478\n","Epoch 9, loss = 0.5179, val.acc = 0.7506\n","Epoch 10, loss = 0.4919, val.acc = 0.7538\n","Epoch 11, loss = 0.4674, val.acc = 0.7562\n","Epoch 12, loss = 0.4442, val.acc = 0.7574\n","Epoch 13, loss = 0.4221, val.acc = 0.7572\n","Epoch 14, loss = 0.4011, val.acc = 0.7578\n","Epoch 15, loss = 0.3810, val.acc = 0.7580\n","Epoch 16, loss = 0.3617, val.acc = 0.7598\n","Epoch 17, loss = 0.3433, val.acc = 0.7604\n","Epoch 18, loss = 0.3257, val.acc = 0.7614\n","Epoch 19, loss = 0.3089, val.acc = 0.7626\n","Epoch 20, loss = 0.2929, val.acc = 0.7628\n","Epoch 21, loss = 0.2776, val.acc = 0.7624\n","Epoch 22, loss = 0.2630, val.acc = 0.7632\n","Epoch 23, loss = 0.2491, val.acc = 0.7618\n","Epoch 24, loss = 0.2359, val.acc = 0.7616\n","Epoch 25, loss = 0.2234, val.acc = 0.7618\n","Epoch 26, loss = 0.2115, val.acc = 0.7624\n","Epoch 27, loss = 0.2003, val.acc = 0.7614\n","Epoch 28, loss = 0.1896, val.acc = 0.7612\n","Epoch 29, loss = 0.1796, val.acc = 0.7620\n","Epoch 30, loss = 0.1701, val.acc = 0.7626\n","Epoch 31, loss = 0.1611, val.acc = 0.7626\n","Epoch 32, loss = 0.1526, val.acc = 0.7632\n","Epoch 33, loss = 0.1447, val.acc = 0.7632\n","Epoch 34, loss = 0.1372, val.acc = 0.7628\n","Epoch 35, loss = 0.1302, val.acc = 0.7620\n","Epoch 36, loss = 0.1235, val.acc = 0.7616\n","Epoch 37, loss = 0.1173, val.acc = 0.7610\n","Epoch 38, loss = 0.1115, val.acc = 0.7606\n","Epoch 39, loss = 0.1060, val.acc = 0.7612\n","Epoch 40, loss = 0.1008, val.acc = 0.7610\n","Epoch 41, loss = 0.0960, val.acc = 0.7596\n","Epoch 42, loss = 0.0915, val.acc = 0.7592\n","Epoch 43, loss = 0.0873, val.acc = 0.7590\n","Epoch 44, loss = 0.0833, val.acc = 0.7586\n","Epoch 45, loss = 0.0796, val.acc = 0.7584\n","Epoch 46, loss = 0.0761, val.acc = 0.7580\n","Epoch 47, loss = 0.0728, val.acc = 0.7586\n","Epoch 48, loss = 0.0697, val.acc = 0.7582\n","Epoch 49, loss = 0.0668, val.acc = 0.7592\n","Epoch 50, loss = 0.0640, val.acc = 0.7596\n","Epoch 51, loss = 0.0615, val.acc = 0.7596\n","Epoch 52, loss = 0.0591, val.acc = 0.7592\n","Epoch 53, loss = 0.0568, val.acc = 0.7582\n","Epoch 54, loss = 0.0546, val.acc = 0.7578\n","Epoch 55, loss = 0.0526, val.acc = 0.7574\n","Epoch 56, loss = 0.0507, val.acc = 0.7576\n","Epoch 57, loss = 0.0489, val.acc = 0.7582\n","Epoch 58, loss = 0.0472, val.acc = 0.7580\n","Epoch 59, loss = 0.0456, val.acc = 0.7582\n","Epoch 60, loss = 0.0440, val.acc = 0.7582\n","Epoch 61, loss = 0.0426, val.acc = 0.7582\n","Epoch 62, loss = 0.0412, val.acc = 0.7582\n","Epoch 63, loss = 0.0399, val.acc = 0.7586\n","Epoch 64, loss = 0.0387, val.acc = 0.7582\n","Epoch 65, loss = 0.0375, val.acc = 0.7580\n","Epoch 66, loss = 0.0364, val.acc = 0.7580\n","Epoch 67, loss = 0.0353, val.acc = 0.7586\n","Epoch 68, loss = 0.0343, val.acc = 0.7586\n","Epoch 69, loss = 0.0334, val.acc = 0.7582\n","Epoch 70, loss = 0.0324, val.acc = 0.7576\n","Epoch 71, loss = 0.0316, val.acc = 0.7576\n","Epoch 72, loss = 0.0307, val.acc = 0.7574\n","Epoch 73, loss = 0.0299, val.acc = 0.7574\n","Epoch 74, loss = 0.0292, val.acc = 0.7576\n","Epoch 75, loss = 0.0284, val.acc = 0.7580\n","Epoch 76, loss = 0.0277, val.acc = 0.7582\n","Epoch 77, loss = 0.0271, val.acc = 0.7582\n","Epoch 78, loss = 0.0264, val.acc = 0.7584\n","Epoch 79, loss = 0.0258, val.acc = 0.7582\n","Epoch 80, loss = 0.0252, val.acc = 0.7582\n","Epoch 81, loss = 0.0246, val.acc = 0.7582\n","Epoch 82, loss = 0.0241, val.acc = 0.7584\n","Epoch 83, loss = 0.0236, val.acc = 0.7582\n","Epoch 84, loss = 0.0231, val.acc = 0.7584\n","Epoch 85, loss = 0.0226, val.acc = 0.7582\n","Epoch 86, loss = 0.0221, val.acc = 0.7584\n","Epoch 87, loss = 0.0217, val.acc = 0.7586\n","Epoch 88, loss = 0.0212, val.acc = 0.7584\n","Epoch 89, loss = 0.0208, val.acc = 0.7586\n","Epoch 90, loss = 0.0204, val.acc = 0.7584\n","Epoch 91, loss = 0.0200, val.acc = 0.7586\n","Epoch 92, loss = 0.0196, val.acc = 0.7588\n","Epoch 93, loss = 0.0193, val.acc = 0.7588\n","Epoch 94, loss = 0.0189, val.acc = 0.7588\n","Epoch 95, loss = 0.0186, val.acc = 0.7592\n","Epoch 96, loss = 0.0182, val.acc = 0.7594\n","Epoch 97, loss = 0.0179, val.acc = 0.7596\n","Epoch 98, loss = 0.0176, val.acc = 0.7596\n","Epoch 99, loss = 0.0173, val.acc = 0.7598\n","Rep: 5, Layer: 2, te.acc = 0.7473\n","\n","LAYER:3\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (0): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 1.3154, val.acc = 0.6684\n","Epoch 1, loss = 0.7991, val.acc = 0.7118\n","Epoch 2, loss = 0.6381, val.acc = 0.7314\n","Epoch 3, loss = 0.5361, val.acc = 0.7384\n","Epoch 4, loss = 0.4602, val.acc = 0.7508\n","Epoch 5, loss = 0.3992, val.acc = 0.7552\n","Epoch 6, loss = 0.3483, val.acc = 0.7596\n","Epoch 7, loss = 0.3051, val.acc = 0.7626\n","Epoch 8, loss = 0.2681, val.acc = 0.7616\n","Epoch 9, loss = 0.2364, val.acc = 0.7618\n","Epoch 10, loss = 0.2091, val.acc = 0.7624\n","Epoch 11, loss = 0.1856, val.acc = 0.7624\n","Epoch 12, loss = 0.1653, val.acc = 0.7632\n","Epoch 13, loss = 0.1479, val.acc = 0.7622\n","Epoch 14, loss = 0.1328, val.acc = 0.7626\n","Epoch 15, loss = 0.1198, val.acc = 0.7630\n","Epoch 16, loss = 0.1085, val.acc = 0.7624\n","Epoch 17, loss = 0.0987, val.acc = 0.7614\n","Epoch 18, loss = 0.0901, val.acc = 0.7622\n","Epoch 19, loss = 0.0826, val.acc = 0.7638\n","Epoch 20, loss = 0.0759, val.acc = 0.7632\n","Epoch 21, loss = 0.0701, val.acc = 0.7636\n","Epoch 22, loss = 0.0649, val.acc = 0.7646\n","Epoch 23, loss = 0.0603, val.acc = 0.7650\n","Epoch 24, loss = 0.0562, val.acc = 0.7656\n","Epoch 25, loss = 0.0525, val.acc = 0.7656\n","Epoch 26, loss = 0.0492, val.acc = 0.7658\n","Epoch 27, loss = 0.0462, val.acc = 0.7654\n","Epoch 28, loss = 0.0435, val.acc = 0.7652\n","Epoch 29, loss = 0.0410, val.acc = 0.7650\n","Epoch 30, loss = 0.0388, val.acc = 0.7648\n","Epoch 31, loss = 0.0367, val.acc = 0.7654\n","Epoch 32, loss = 0.0349, val.acc = 0.7654\n","Epoch 33, loss = 0.0331, val.acc = 0.7656\n","Epoch 34, loss = 0.0315, val.acc = 0.7652\n","Epoch 35, loss = 0.0301, val.acc = 0.7648\n","Epoch 36, loss = 0.0287, val.acc = 0.7646\n","Epoch 37, loss = 0.0275, val.acc = 0.7644\n","Epoch 38, loss = 0.0263, val.acc = 0.7640\n","Epoch 39, loss = 0.0253, val.acc = 0.7638\n","Epoch 40, loss = 0.0243, val.acc = 0.7634\n","Epoch 41, loss = 0.0233, val.acc = 0.7634\n","Epoch 42, loss = 0.0224, val.acc = 0.7632\n","Epoch 43, loss = 0.0216, val.acc = 0.7632\n","Epoch 44, loss = 0.0209, val.acc = 0.7632\n","Epoch 45, loss = 0.0201, val.acc = 0.7632\n","Epoch 46, loss = 0.0195, val.acc = 0.7630\n","Epoch 47, loss = 0.0188, val.acc = 0.7634\n","Epoch 48, loss = 0.0182, val.acc = 0.7628\n","Epoch 49, loss = 0.0176, val.acc = 0.7628\n","Epoch 50, loss = 0.0171, val.acc = 0.7628\n","Epoch 51, loss = 0.0166, val.acc = 0.7626\n","Epoch 52, loss = 0.0161, val.acc = 0.7632\n","Epoch 53, loss = 0.0156, val.acc = 0.7632\n","Epoch 54, loss = 0.0152, val.acc = 0.7632\n","Epoch 55, loss = 0.0148, val.acc = 0.7630\n","Epoch 56, loss = 0.0144, val.acc = 0.7630\n","Epoch 57, loss = 0.0140, val.acc = 0.7628\n","Epoch 58, loss = 0.0136, val.acc = 0.7628\n","Epoch 59, loss = 0.0133, val.acc = 0.7630\n","Epoch 60, loss = 0.0130, val.acc = 0.7632\n","Epoch 61, loss = 0.0127, val.acc = 0.7632\n","Epoch 62, loss = 0.0124, val.acc = 0.7636\n","Epoch 63, loss = 0.0121, val.acc = 0.7636\n","Epoch 64, loss = 0.0118, val.acc = 0.7634\n","Epoch 65, loss = 0.0115, val.acc = 0.7636\n","Epoch 66, loss = 0.0113, val.acc = 0.7636\n","Epoch 67, loss = 0.0110, val.acc = 0.7636\n","Epoch 68, loss = 0.0108, val.acc = 0.7632\n","Epoch 69, loss = 0.0106, val.acc = 0.7632\n","Epoch 70, loss = 0.0104, val.acc = 0.7632\n","Epoch 71, loss = 0.0101, val.acc = 0.7630\n","Epoch 72, loss = 0.0099, val.acc = 0.7628\n","Epoch 73, loss = 0.0097, val.acc = 0.7626\n","Epoch 74, loss = 0.0096, val.acc = 0.7626\n","Epoch 75, loss = 0.0094, val.acc = 0.7628\n","Epoch 76, loss = 0.0092, val.acc = 0.7628\n","Epoch 77, loss = 0.0090, val.acc = 0.7630\n","Epoch 78, loss = 0.0089, val.acc = 0.7630\n","Epoch 79, loss = 0.0087, val.acc = 0.7628\n","Epoch 80, loss = 0.0086, val.acc = 0.7628\n","Epoch 81, loss = 0.0084, val.acc = 0.7628\n","Epoch 82, loss = 0.0083, val.acc = 0.7630\n","Epoch 83, loss = 0.0081, val.acc = 0.7632\n","Epoch 84, loss = 0.0080, val.acc = 0.7634\n","Epoch 85, loss = 0.0079, val.acc = 0.7636\n","Epoch 86, loss = 0.0077, val.acc = 0.7634\n","Epoch 87, loss = 0.0076, val.acc = 0.7632\n","Epoch 88, loss = 0.0075, val.acc = 0.7630\n","Epoch 89, loss = 0.0074, val.acc = 0.7630\n","Epoch 90, loss = 0.0072, val.acc = 0.7632\n","Epoch 91, loss = 0.0071, val.acc = 0.7632\n","Epoch 92, loss = 0.0070, val.acc = 0.7634\n","Epoch 93, loss = 0.0069, val.acc = 0.7634\n","Epoch 94, loss = 0.0068, val.acc = 0.7634\n","Epoch 95, loss = 0.0067, val.acc = 0.7638\n","Epoch 96, loss = 0.0066, val.acc = 0.7640\n","Epoch 97, loss = 0.0065, val.acc = 0.7640\n","Epoch 98, loss = 0.0064, val.acc = 0.7640\n","Epoch 99, loss = 0.0064, val.acc = 0.7640\n","Rep: 5, Layer: 3, te.acc = 0.7491\n","\n","\n","All reps test.acc:\n","[0.6375, 0.6963, 0.7406, 0.7417]\n","[0.6415, 0.6945, 0.7416, 0.7421]\n","[0.6373, 0.7018, 0.7391, 0.7452]\n","[0.6361, 0.6998, 0.7392, 0.7402]\n","[0.6231, 0.7038, 0.7473, 0.7491]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fifsYWwy-Xfr"},"source":["# CONV - RLL - BP - LR_0.05"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMe3jD5z-Xfr","executionInfo":{"status":"ok","timestamp":1606895901787,"user_tz":360,"elapsed":1820,"user":{"displayName":"E Yang","photoUrl":"","userId":"00321264058976725553"}},"outputId":"6c816892-1107-4077-cb6d-35bf7f643b7a"},"source":["pars = PARS(device, datapath, savepath)\n","pars.process = 'RLL'\n","pars.LR = 0.05\n","print(pars)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["architecture: CONV\n","process: RLL\n","update: BP\n","OPT: SGD\n","loss: CE\n","nonlinear: hardtanh\n","LR: 0.05\n","epochs: 100\n","batch_size: 500\n","repeat: 5\n","device: cuda:0\n","datapath: /ME/My Drive/Colab Notebooks/LLFA/data/\n","savepath: /ME/My Drive/Colab Notebooks/LLFA/save/\n","cuDNN: False\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98jxaCSt-Xft","executionInfo":{"status":"ok","timestamp":1606898018647,"user_tz":360,"elapsed":2118668,"user":{"displayName":"E Yang","photoUrl":"","userId":"00321264058976725553"}},"outputId":"9fa6f3f9-fd89-484d-aa5d-38d833641d26"},"source":["main(pars)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["architecture: CONV\n","process: RLL\n","update: BP\n","OPT: SGD\n","loss: CE\n","nonlinear: hardtanh\n","LR: 0.05\n","epochs: 100\n","batch_size: 500\n","repeat: 5\n","device: cuda:0\n","datapath: /ME/My Drive/Colab Notebooks/LLFA/data/\n","savepath: /ME/My Drive/Colab Notebooks/LLFA/save/\n","cuDNN: False\n","\n","Files already downloaded and verified\n","Files already downloaded and verified\n","\n","Rep 1\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 2.1039, val.acc = [0.3558, 0.3346, 0.2458, 0.2448]\n","Epoch 1, loss = 1.9430, val.acc = [0.3828, 0.3824, 0.3158, 0.2502]\n","Epoch 2, loss = 1.8325, val.acc = [0.405, 0.4042, 0.3646, 0.3068]\n","Epoch 3, loss = 1.7647, val.acc = [0.4306, 0.4216, 0.395, 0.3392]\n","Epoch 4, loss = 1.7022, val.acc = [0.438, 0.4432, 0.405, 0.3586]\n","Epoch 5, loss = 1.6486, val.acc = [0.4528, 0.4622, 0.4236, 0.3736]\n","Epoch 6, loss = 1.6098, val.acc = [0.4708, 0.4642, 0.4424, 0.3878]\n","Epoch 7, loss = 1.5848, val.acc = [0.4674, 0.4648, 0.4578, 0.4096]\n","Epoch 8, loss = 1.5321, val.acc = [0.4754, 0.475, 0.4566, 0.4164]\n","Epoch 9, loss = 1.5080, val.acc = [0.472, 0.503, 0.4878, 0.433]\n","Epoch 10, loss = 1.4686, val.acc = [0.4886, 0.4936, 0.4854, 0.4344]\n","Epoch 11, loss = 1.4434, val.acc = [0.511, 0.5152, 0.5172, 0.4726]\n","Epoch 12, loss = 1.4166, val.acc = [0.5028, 0.5116, 0.5168, 0.4828]\n","Epoch 13, loss = 1.3966, val.acc = [0.4988, 0.5302, 0.5164, 0.487]\n","Epoch 14, loss = 1.3618, val.acc = [0.5144, 0.5364, 0.5266, 0.4954]\n","Epoch 15, loss = 1.3748, val.acc = [0.5234, 0.5466, 0.528, 0.4964]\n","Epoch 16, loss = 1.3330, val.acc = [0.5298, 0.5564, 0.5402, 0.5152]\n","Epoch 17, loss = 1.3006, val.acc = [0.5322, 0.56, 0.553, 0.5108]\n","Epoch 18, loss = 1.3020, val.acc = [0.5254, 0.5674, 0.5522, 0.527]\n","Epoch 19, loss = 1.2915, val.acc = [0.5288, 0.5646, 0.5612, 0.5336]\n","Epoch 20, loss = 1.2774, val.acc = [0.5308, 0.5714, 0.567, 0.5352]\n","Epoch 21, loss = 1.2659, val.acc = [0.5444, 0.5788, 0.5732, 0.5392]\n","Epoch 22, loss = 1.2480, val.acc = [0.55, 0.577, 0.5814, 0.5524]\n","Epoch 23, loss = 1.2268, val.acc = [0.5498, 0.5828, 0.586, 0.5574]\n","Epoch 24, loss = 1.1995, val.acc = [0.5346, 0.581, 0.5934, 0.5678]\n","Epoch 25, loss = 1.2088, val.acc = [0.5574, 0.5954, 0.6028, 0.5808]\n","Epoch 26, loss = 1.2205, val.acc = [0.5564, 0.5878, 0.6106, 0.5868]\n","Epoch 27, loss = 1.1685, val.acc = [0.5584, 0.593, 0.6002, 0.5878]\n","Epoch 28, loss = 1.1669, val.acc = [0.555, 0.5872, 0.5966, 0.5816]\n","Epoch 29, loss = 1.1458, val.acc = [0.5478, 0.6026, 0.6264, 0.5992]\n","Epoch 30, loss = 1.1366, val.acc = [0.568, 0.6088, 0.6172, 0.6136]\n","Epoch 31, loss = 1.1172, val.acc = [0.561, 0.6172, 0.6252, 0.6084]\n","Epoch 32, loss = 1.1183, val.acc = [0.565, 0.6254, 0.6222, 0.6184]\n","Epoch 33, loss = 1.1220, val.acc = [0.56, 0.6244, 0.6328, 0.6196]\n","Epoch 34, loss = 1.1129, val.acc = [0.5634, 0.6178, 0.6206, 0.6154]\n","Epoch 35, loss = 1.0636, val.acc = [0.571, 0.6198, 0.6398, 0.631]\n","Epoch 36, loss = 1.0908, val.acc = [0.5806, 0.6316, 0.6514, 0.6316]\n","Epoch 37, loss = 1.0789, val.acc = [0.5578, 0.586, 0.6382, 0.6176]\n","Epoch 38, loss = 1.0607, val.acc = [0.581, 0.6108, 0.6266, 0.6362]\n","Epoch 39, loss = 1.0589, val.acc = [0.5828, 0.6374, 0.6502, 0.6364]\n","Epoch 40, loss = 1.0468, val.acc = [0.5828, 0.6394, 0.6586, 0.6452]\n","Epoch 41, loss = 1.0065, val.acc = [0.588, 0.643, 0.6656, 0.6482]\n","Epoch 42, loss = 1.0267, val.acc = [0.5816, 0.6466, 0.6642, 0.656]\n","Epoch 43, loss = 1.0000, val.acc = [0.5952, 0.6158, 0.659, 0.6438]\n","Epoch 44, loss = 1.0215, val.acc = [0.5892, 0.6532, 0.6742, 0.6608]\n","Epoch 45, loss = 0.9693, val.acc = [0.5794, 0.6534, 0.67, 0.6682]\n","Epoch 46, loss = 1.0060, val.acc = [0.6016, 0.6422, 0.6656, 0.6622]\n","Epoch 47, loss = 0.9900, val.acc = [0.5832, 0.6534, 0.6826, 0.6686]\n","Epoch 48, loss = 0.9712, val.acc = [0.583, 0.6336, 0.6854, 0.6674]\n","Epoch 49, loss = 0.9667, val.acc = [0.593, 0.6562, 0.6806, 0.6784]\n","Epoch 50, loss = 0.9666, val.acc = [0.5982, 0.6432, 0.6762, 0.6704]\n","Epoch 51, loss = 0.9443, val.acc = [0.602, 0.668, 0.6872, 0.6844]\n","Epoch 52, loss = 0.9756, val.acc = [0.5628, 0.6528, 0.6782, 0.6814]\n","Epoch 53, loss = 0.9391, val.acc = [0.5748, 0.645, 0.6652, 0.6544]\n","Epoch 54, loss = 0.9256, val.acc = [0.601, 0.6654, 0.6924, 0.6858]\n","Epoch 55, loss = 0.9204, val.acc = [0.5962, 0.644, 0.6818, 0.6706]\n","Epoch 56, loss = 0.9411, val.acc = [0.6156, 0.6644, 0.6858, 0.675]\n","Epoch 57, loss = 0.9105, val.acc = [0.593, 0.651, 0.6946, 0.6902]\n","Epoch 58, loss = 0.9172, val.acc = [0.5946, 0.6604, 0.6988, 0.6872]\n","Epoch 59, loss = 0.8859, val.acc = [0.5972, 0.6642, 0.6962, 0.6968]\n","Epoch 60, loss = 0.9294, val.acc = [0.604, 0.6694, 0.7042, 0.6908]\n","Epoch 61, loss = 0.8891, val.acc = [0.6048, 0.6668, 0.7048, 0.703]\n","Epoch 62, loss = 0.8764, val.acc = [0.6132, 0.6724, 0.7124, 0.7092]\n","Epoch 63, loss = 0.8834, val.acc = [0.616, 0.668, 0.7022, 0.7012]\n","Epoch 64, loss = 0.8913, val.acc = [0.5994, 0.634, 0.678, 0.675]\n","Epoch 65, loss = 0.8612, val.acc = [0.6198, 0.648, 0.7004, 0.7072]\n","Epoch 66, loss = 0.8672, val.acc = [0.6194, 0.676, 0.7124, 0.7112]\n","Epoch 67, loss = 0.8461, val.acc = [0.5926, 0.6576, 0.6982, 0.7014]\n","Epoch 68, loss = 0.8395, val.acc = [0.6262, 0.6842, 0.7128, 0.7176]\n","Epoch 69, loss = 0.8391, val.acc = [0.615, 0.676, 0.7144, 0.7136]\n","Epoch 70, loss = 0.8415, val.acc = [0.5902, 0.6426, 0.6972, 0.7006]\n","Epoch 71, loss = 0.8672, val.acc = [0.6248, 0.6792, 0.7098, 0.7132]\n","Epoch 72, loss = 0.8247, val.acc = [0.605, 0.6686, 0.6812, 0.6866]\n","Epoch 73, loss = 0.8193, val.acc = [0.6102, 0.6804, 0.7188, 0.7122]\n","Epoch 74, loss = 0.8074, val.acc = [0.6178, 0.6812, 0.7146, 0.726]\n","Epoch 75, loss = 0.8197, val.acc = [0.6346, 0.6938, 0.7196, 0.7274]\n","Epoch 76, loss = 0.8121, val.acc = [0.6238, 0.683, 0.7036, 0.697]\n","Epoch 77, loss = 0.8308, val.acc = [0.6164, 0.6816, 0.709, 0.7212]\n","Epoch 78, loss = 0.8082, val.acc = [0.6192, 0.686, 0.7276, 0.7278]\n","Epoch 79, loss = 0.8165, val.acc = [0.6332, 0.6932, 0.7258, 0.7348]\n","Epoch 80, loss = 0.7771, val.acc = [0.6318, 0.6892, 0.7198, 0.7226]\n","Epoch 81, loss = 0.7937, val.acc = [0.6372, 0.6824, 0.727, 0.7312]\n","Epoch 82, loss = 0.7597, val.acc = [0.6174, 0.6878, 0.7078, 0.7132]\n","Epoch 83, loss = 0.7671, val.acc = [0.6372, 0.6896, 0.726, 0.7376]\n","Epoch 84, loss = 0.7881, val.acc = [0.6122, 0.6862, 0.7232, 0.7308]\n","Epoch 85, loss = 0.7776, val.acc = [0.6366, 0.6886, 0.7258, 0.735]\n","Epoch 86, loss = 0.7741, val.acc = [0.6146, 0.661, 0.7168, 0.7308]\n","Epoch 87, loss = 0.7620, val.acc = [0.6306, 0.7008, 0.7296, 0.7396]\n","Epoch 88, loss = 0.7310, val.acc = [0.6328, 0.6984, 0.7324, 0.7354]\n","Epoch 89, loss = 0.7415, val.acc = [0.6236, 0.6894, 0.7322, 0.7428]\n","Epoch 90, loss = 0.7583, val.acc = [0.6312, 0.6904, 0.7312, 0.7372]\n","Epoch 91, loss = 0.7351, val.acc = [0.6372, 0.6956, 0.7346, 0.7444]\n","Epoch 92, loss = 0.7281, val.acc = [0.6256, 0.6904, 0.729, 0.7396]\n","Epoch 93, loss = 0.7277, val.acc = [0.6464, 0.6942, 0.733, 0.7484]\n","Epoch 94, loss = 0.7530, val.acc = [0.6464, 0.7028, 0.7348, 0.7464]\n","Epoch 95, loss = 0.7329, val.acc = [0.6352, 0.6986, 0.7336, 0.7502]\n","Epoch 96, loss = 0.7074, val.acc = [0.6308, 0.6942, 0.7282, 0.7472]\n","Epoch 97, loss = 0.7209, val.acc = [0.6182, 0.673, 0.7262, 0.7392]\n","Epoch 98, loss = 0.7064, val.acc = [0.647, 0.6922, 0.7394, 0.7526]\n","Epoch 99, loss = 0.7155, val.acc = [0.6306, 0.6876, 0.7324, 0.745]\n","Epoch 100, loss = 0.7129, val.acc = [0.6294, 0.6992, 0.7398, 0.7528]\n","Epoch 101, loss = 0.6812, val.acc = [0.6326, 0.6956, 0.7334, 0.752]\n","Epoch 102, loss = 0.7161, val.acc = [0.632, 0.6842, 0.717, 0.7336]\n","Epoch 103, loss = 0.6933, val.acc = [0.6278, 0.691, 0.7324, 0.752]\n","Epoch 104, loss = 0.6862, val.acc = [0.6438, 0.6956, 0.742, 0.7532]\n","Epoch 105, loss = 0.6905, val.acc = [0.631, 0.6606, 0.7308, 0.7436]\n","Epoch 106, loss = 0.7048, val.acc = [0.6312, 0.7066, 0.7374, 0.7506]\n","Epoch 107, loss = 0.6516, val.acc = [0.6366, 0.6922, 0.7396, 0.7472]\n","Epoch 108, loss = 0.6595, val.acc = [0.6302, 0.6948, 0.739, 0.7526]\n","Epoch 109, loss = 0.6710, val.acc = [0.6468, 0.709, 0.7434, 0.7554]\n","Epoch 110, loss = 0.6951, val.acc = [0.6154, 0.6986, 0.733, 0.7556]\n","Epoch 111, loss = 0.6573, val.acc = [0.6352, 0.7048, 0.7446, 0.7594]\n","Epoch 112, loss = 0.6730, val.acc = [0.6302, 0.7028, 0.7388, 0.7514]\n","Epoch 113, loss = 0.6831, val.acc = [0.6416, 0.6878, 0.7372, 0.7468]\n","Epoch 114, loss = 0.6657, val.acc = [0.6478, 0.702, 0.743, 0.756]\n","Epoch 115, loss = 0.6598, val.acc = [0.6314, 0.6958, 0.7342, 0.7548]\n","Epoch 116, loss = 0.6182, val.acc = [0.648, 0.707, 0.7404, 0.7604]\n","Epoch 117, loss = 0.6200, val.acc = [0.642, 0.7022, 0.7404, 0.7578]\n","Epoch 118, loss = 0.6511, val.acc = [0.6396, 0.7058, 0.737, 0.753]\n","Epoch 119, loss = 0.6650, val.acc = [0.6372, 0.6998, 0.742, 0.7544]\n","Epoch 120, loss = 0.6010, val.acc = [0.6528, 0.7084, 0.75, 0.7636]\n","Epoch 121, loss = 0.6212, val.acc = [0.6414, 0.7132, 0.7496, 0.7658]\n","Epoch 122, loss = 0.6548, val.acc = [0.641, 0.706, 0.74, 0.7612]\n","Epoch 123, loss = 0.5924, val.acc = [0.6468, 0.7048, 0.7468, 0.7666]\n","Epoch 124, loss = 0.5823, val.acc = [0.6434, 0.7072, 0.742, 0.7498]\n","Epoch 125, loss = 0.6586, val.acc = [0.6502, 0.7126, 0.745, 0.7606]\n","Epoch 126, loss = 0.6207, val.acc = [0.6528, 0.708, 0.7454, 0.7582]\n","Epoch 127, loss = 0.5893, val.acc = [0.6516, 0.7094, 0.7436, 0.7624]\n","Epoch 128, loss = 0.5535, val.acc = [0.652, 0.7064, 0.7446, 0.7656]\n","Epoch 129, loss = 0.5793, val.acc = [0.6206, 0.7048, 0.741, 0.7584]\n","Epoch 130, loss = 0.6113, val.acc = [0.6484, 0.7032, 0.7448, 0.7646]\n","Epoch 131, loss = 0.6138, val.acc = [0.6354, 0.6916, 0.7474, 0.7596]\n","Epoch 132, loss = 0.6001, val.acc = [0.6516, 0.7068, 0.7474, 0.7662]\n","Epoch 133, loss = 0.5549, val.acc = [0.652, 0.7062, 0.749, 0.7642]\n","Epoch 134, loss = 0.5814, val.acc = [0.6416, 0.7044, 0.7448, 0.76]\n","Epoch 135, loss = 0.5689, val.acc = [0.6536, 0.7058, 0.7492, 0.7628]\n","Epoch 136, loss = 0.5429, val.acc = [0.6558, 0.7152, 0.7462, 0.7608]\n","Epoch 137, loss = 0.5798, val.acc = [0.6546, 0.7128, 0.7512, 0.7632]\n","Epoch 138, loss = 0.5421, val.acc = [0.6438, 0.7072, 0.7502, 0.766]\n","Epoch 139, loss = 0.5673, val.acc = [0.649, 0.7132, 0.7504, 0.7662]\n","Epoch 140, loss = 0.5760, val.acc = [0.6388, 0.682, 0.7368, 0.7586]\n","Epoch 141, loss = 0.5723, val.acc = [0.6456, 0.7138, 0.751, 0.767]\n","Epoch 142, loss = 0.5517, val.acc = [0.6356, 0.7118, 0.7446, 0.7588]\n","Epoch 143, loss = 0.5588, val.acc = [0.6524, 0.7134, 0.741, 0.767]\n","Epoch 144, loss = 0.5264, val.acc = [0.6518, 0.7154, 0.7452, 0.7654]\n","Epoch 145, loss = 0.5458, val.acc = [0.6448, 0.7114, 0.7454, 0.7638]\n","Epoch 146, loss = 0.5521, val.acc = [0.6584, 0.7152, 0.748, 0.7676]\n","Epoch 147, loss = 0.5314, val.acc = [0.659, 0.7208, 0.7498, 0.7622]\n","Epoch 148, loss = 0.5066, val.acc = [0.6558, 0.7206, 0.751, 0.7726]\n","Epoch 149, loss = 0.5135, val.acc = [0.6492, 0.7128, 0.7466, 0.7636]\n","Epoch 150, loss = 0.4987, val.acc = [0.6534, 0.7134, 0.7518, 0.7694]\n","Epoch 151, loss = 0.4732, val.acc = [0.6442, 0.7024, 0.741, 0.7582]\n","Epoch 152, loss = 0.5005, val.acc = [0.6472, 0.7094, 0.7424, 0.7672]\n","Epoch 153, loss = 0.5163, val.acc = [0.6552, 0.7094, 0.7482, 0.767]\n","Epoch 154, loss = 0.5635, val.acc = [0.65, 0.717, 0.7508, 0.7662]\n","Epoch 155, loss = 0.5188, val.acc = [0.6522, 0.717, 0.7426, 0.7642]\n","Epoch 156, loss = 0.5095, val.acc = [0.6576, 0.7186, 0.7516, 0.7694]\n","Epoch 157, loss = 0.5548, val.acc = [0.6536, 0.7152, 0.749, 0.7648]\n","Epoch 158, loss = 0.4983, val.acc = [0.6562, 0.7112, 0.7524, 0.7716]\n","Epoch 159, loss = 0.5341, val.acc = [0.6498, 0.7086, 0.747, 0.7624]\n","Epoch 160, loss = 0.5417, val.acc = [0.6568, 0.7162, 0.7518, 0.7666]\n","Epoch 161, loss = 0.4839, val.acc = [0.655, 0.7178, 0.7516, 0.77]\n","Epoch 162, loss = 0.4879, val.acc = [0.6614, 0.713, 0.7524, 0.7564]\n","Epoch 163, loss = 0.4926, val.acc = [0.6544, 0.7188, 0.7494, 0.768]\n","Epoch 164, loss = 0.4788, val.acc = [0.6576, 0.7208, 0.7564, 0.7732]\n","Epoch 165, loss = 0.4720, val.acc = [0.655, 0.7212, 0.7502, 0.7728]\n","Epoch 166, loss = 0.4679, val.acc = [0.6444, 0.7074, 0.74, 0.7698]\n","Epoch 167, loss = 0.4489, val.acc = [0.6492, 0.712, 0.7516, 0.7666]\n","Epoch 168, loss = 0.4630, val.acc = [0.6568, 0.7182, 0.7452, 0.7708]\n","Epoch 169, loss = 0.4655, val.acc = [0.6616, 0.7114, 0.7508, 0.7674]\n","Epoch 170, loss = 0.4839, val.acc = [0.664, 0.713, 0.7538, 0.7636]\n","Epoch 171, loss = 0.4768, val.acc = [0.6656, 0.719, 0.7526, 0.7702]\n","Epoch 172, loss = 0.4943, val.acc = [0.6484, 0.7126, 0.7484, 0.7658]\n","Epoch 173, loss = 0.4384, val.acc = [0.6584, 0.7152, 0.7524, 0.7706]\n","Epoch 174, loss = 0.4193, val.acc = [0.6376, 0.6936, 0.7468, 0.7632]\n","Epoch 175, loss = 0.4941, val.acc = [0.6624, 0.7106, 0.753, 0.7654]\n","Epoch 176, loss = 0.4309, val.acc = [0.655, 0.7188, 0.7558, 0.7674]\n","Epoch 177, loss = 0.4020, val.acc = [0.6586, 0.7174, 0.7554, 0.7676]\n","Epoch 178, loss = 0.4438, val.acc = [0.6518, 0.7172, 0.7526, 0.7674]\n","Epoch 179, loss = 0.4313, val.acc = [0.6216, 0.684, 0.7342, 0.7576]\n","Epoch 180, loss = 0.4541, val.acc = [0.6582, 0.7188, 0.7476, 0.767]\n","Epoch 181, loss = 0.4343, val.acc = [0.6522, 0.7194, 0.7554, 0.7708]\n","Epoch 182, loss = 0.4117, val.acc = [0.6588, 0.7192, 0.7574, 0.7666]\n","Epoch 183, loss = 0.4181, val.acc = [0.6556, 0.7128, 0.7512, 0.7672]\n","Epoch 184, loss = 0.4512, val.acc = [0.6306, 0.696, 0.7468, 0.766]\n","Epoch 185, loss = 0.4055, val.acc = [0.6356, 0.708, 0.7472, 0.7508]\n","Epoch 186, loss = 0.4593, val.acc = [0.6546, 0.7076, 0.7528, 0.7624]\n","Epoch 187, loss = 0.4158, val.acc = [0.6526, 0.7216, 0.7526, 0.773]\n","Epoch 188, loss = 0.4361, val.acc = [0.6634, 0.72, 0.755, 0.7694]\n","Epoch 189, loss = 0.4660, val.acc = [0.6552, 0.7184, 0.757, 0.768]\n","Epoch 190, loss = 0.3675, val.acc = [0.6566, 0.7144, 0.75, 0.7634]\n","Epoch 191, loss = 0.4088, val.acc = [0.6502, 0.7084, 0.7492, 0.7634]\n","Epoch 192, loss = 0.4138, val.acc = [0.6574, 0.7164, 0.7524, 0.7692]\n","Epoch 193, loss = 0.3824, val.acc = [0.6482, 0.7172, 0.7542, 0.7692]\n","Epoch 194, loss = 0.3866, val.acc = [0.6488, 0.714, 0.754, 0.768]\n","Epoch 195, loss = 0.4213, val.acc = [0.6618, 0.7168, 0.7532, 0.7706]\n","Epoch 196, loss = 0.4030, val.acc = [0.661, 0.7172, 0.7544, 0.7678]\n","Epoch 197, loss = 0.4168, val.acc = [0.638, 0.7094, 0.7552, 0.7662]\n","Epoch 198, loss = 0.4176, val.acc = [0.6484, 0.7106, 0.747, 0.7646]\n","Epoch 199, loss = 0.3935, val.acc = [0.6632, 0.7196, 0.7548, 0.7672]\n","Epoch 200, loss = 0.3859, val.acc = [0.66, 0.7204, 0.7564, 0.7672]\n","Epoch 201, loss = 0.3625, val.acc = [0.6526, 0.7164, 0.7534, 0.767]\n","Epoch 202, loss = 0.3659, val.acc = [0.6676, 0.7188, 0.7526, 0.7662]\n","Epoch 203, loss = 0.3886, val.acc = [0.658, 0.7156, 0.7532, 0.7678]\n","Epoch 204, loss = 0.4012, val.acc = [0.6578, 0.7116, 0.76, 0.7668]\n","Epoch 205, loss = 0.3909, val.acc = [0.6462, 0.7156, 0.7556, 0.764]\n","Epoch 206, loss = 0.4056, val.acc = [0.652, 0.7134, 0.7562, 0.7666]\n","Epoch 207, loss = 0.4012, val.acc = [0.657, 0.7138, 0.7524, 0.7668]\n","Epoch 208, loss = 0.3857, val.acc = [0.657, 0.713, 0.7552, 0.7652]\n","Epoch 209, loss = 0.3770, val.acc = [0.6624, 0.7142, 0.7592, 0.766]\n","Epoch 210, loss = 0.3940, val.acc = [0.6652, 0.7178, 0.7538, 0.764]\n","Epoch 211, loss = 0.3833, val.acc = [0.6612, 0.7148, 0.7572, 0.7664]\n","Epoch 212, loss = 0.3394, val.acc = [0.6632, 0.718, 0.7566, 0.764]\n","Epoch 213, loss = 0.3323, val.acc = [0.6574, 0.706, 0.752, 0.761]\n","Epoch 214, loss = 0.3425, val.acc = [0.653, 0.7076, 0.7474, 0.7614]\n","Epoch 215, loss = 0.3569, val.acc = [0.6642, 0.7158, 0.756, 0.7678]\n","Epoch 216, loss = 0.4266, val.acc = [0.6528, 0.716, 0.7502, 0.7558]\n","Epoch 217, loss = 0.3306, val.acc = [0.6558, 0.7088, 0.7566, 0.765]\n","Epoch 218, loss = 0.3341, val.acc = [0.6472, 0.713, 0.754, 0.7684]\n","Epoch 219, loss = 0.3705, val.acc = [0.659, 0.7158, 0.7562, 0.7628]\n","Epoch 220, loss = 0.3180, val.acc = [0.6622, 0.7168, 0.7542, 0.7706]\n","Epoch 221, loss = 0.3001, val.acc = [0.6564, 0.719, 0.7516, 0.7692]\n","Epoch 222, loss = 0.4073, val.acc = [0.6656, 0.719, 0.7584, 0.767]\n","Epoch 223, loss = 0.3123, val.acc = [0.6552, 0.7196, 0.75, 0.764]\n","Epoch 224, loss = 0.3758, val.acc = [0.6354, 0.7004, 0.7384, 0.7546]\n","Epoch 225, loss = 0.2893, val.acc = [0.6602, 0.7168, 0.7584, 0.7672]\n","Epoch 226, loss = 0.3426, val.acc = [0.6606, 0.7126, 0.7592, 0.7664]\n","Epoch 227, loss = 0.3211, val.acc = [0.6572, 0.712, 0.7492, 0.7588]\n","Epoch 228, loss = 0.3554, val.acc = [0.6526, 0.7172, 0.7502, 0.7596]\n","Epoch 229, loss = 0.3476, val.acc = [0.6434, 0.7062, 0.7418, 0.752]\n","Epoch 230, loss = 0.3694, val.acc = [0.66, 0.7136, 0.7556, 0.7622]\n","Epoch 231, loss = 0.2831, val.acc = [0.6566, 0.7174, 0.7614, 0.7674]\n","Epoch 232, loss = 0.3068, val.acc = [0.657, 0.7144, 0.756, 0.7644]\n","Epoch 233, loss = 0.3577, val.acc = [0.6602, 0.7174, 0.7594, 0.7634]\n","Epoch 234, loss = 0.2906, val.acc = [0.6574, 0.7194, 0.7578, 0.7646]\n","Epoch 235, loss = 0.3142, val.acc = [0.6558, 0.7182, 0.7558, 0.7676]\n","Epoch 236, loss = 0.2968, val.acc = [0.6578, 0.7208, 0.7588, 0.7644]\n","Epoch 237, loss = 0.3070, val.acc = [0.664, 0.7192, 0.757, 0.7664]\n","Epoch 238, loss = 0.3263, val.acc = [0.6394, 0.7158, 0.752, 0.7636]\n","Epoch 239, loss = 0.3142, val.acc = [0.6638, 0.7132, 0.7592, 0.7702]\n","Epoch 240, loss = 0.3421, val.acc = [0.6624, 0.7182, 0.7578, 0.7666]\n","Epoch 241, loss = 0.3413, val.acc = [0.6594, 0.712, 0.7554, 0.7658]\n","Epoch 242, loss = 0.3337, val.acc = [0.652, 0.7194, 0.7512, 0.7652]\n","Epoch 243, loss = 0.2939, val.acc = [0.657, 0.7164, 0.7518, 0.77]\n","Epoch 244, loss = 0.3028, val.acc = [0.6522, 0.7106, 0.7502, 0.7598]\n","Epoch 245, loss = 0.3134, val.acc = [0.6566, 0.7188, 0.757, 0.7656]\n","Epoch 246, loss = 0.2978, val.acc = [0.6546, 0.7158, 0.7568, 0.7654]\n","Epoch 247, loss = 0.3549, val.acc = [0.6582, 0.7114, 0.7554, 0.7632]\n","Epoch 248, loss = 0.2817, val.acc = [0.6586, 0.7126, 0.7562, 0.7676]\n","Epoch 249, loss = 0.2811, val.acc = [0.6384, 0.715, 0.7564, 0.7658]\n","Epoch 250, loss = 0.3011, val.acc = [0.6586, 0.7196, 0.7586, 0.7658]\n","Epoch 251, loss = 0.3276, val.acc = [0.6592, 0.7158, 0.7564, 0.7644]\n","Epoch 252, loss = 0.2802, val.acc = [0.6534, 0.7054, 0.7546, 0.7618]\n","Epoch 253, loss = 0.3144, val.acc = [0.6534, 0.7134, 0.7562, 0.7638]\n","Epoch 254, loss = 0.2903, val.acc = [0.6548, 0.7126, 0.7526, 0.7646]\n","Epoch 255, loss = 0.2754, val.acc = [0.6684, 0.717, 0.7558, 0.7666]\n","Epoch 256, loss = 0.2785, val.acc = [0.648, 0.7132, 0.747, 0.7572]\n","Epoch 257, loss = 0.2958, val.acc = [0.6612, 0.7158, 0.7522, 0.768]\n","Epoch 258, loss = 0.2533, val.acc = [0.6582, 0.7154, 0.7542, 0.7646]\n","Epoch 259, loss = 0.2842, val.acc = [0.6584, 0.7102, 0.752, 0.7658]\n","Epoch 260, loss = 0.2918, val.acc = [0.6484, 0.7138, 0.7548, 0.7648]\n","Epoch 261, loss = 0.2913, val.acc = [0.6566, 0.705, 0.7478, 0.7648]\n","Epoch 262, loss = 0.3020, val.acc = [0.6472, 0.719, 0.7524, 0.7672]\n","Epoch 263, loss = 0.2568, val.acc = [0.6578, 0.7112, 0.7554, 0.7644]\n","Epoch 264, loss = 0.3151, val.acc = [0.6428, 0.712, 0.7512, 0.7628]\n","Epoch 265, loss = 0.2807, val.acc = [0.663, 0.7082, 0.7558, 0.7648]\n","Epoch 266, loss = 0.3077, val.acc = [0.6648, 0.7114, 0.7552, 0.7604]\n","Epoch 267, loss = 0.2375, val.acc = [0.6636, 0.7198, 0.7568, 0.7684]\n","Epoch 268, loss = 0.3059, val.acc = [0.667, 0.7122, 0.7576, 0.7666]\n","Epoch 269, loss = 0.2489, val.acc = [0.647, 0.7114, 0.7538, 0.7584]\n","Epoch 270, loss = 0.2955, val.acc = [0.656, 0.7026, 0.7484, 0.7606]\n","Epoch 271, loss = 0.2542, val.acc = [0.6442, 0.7074, 0.7602, 0.7654]\n","Epoch 272, loss = 0.2875, val.acc = [0.6432, 0.7002, 0.7554, 0.7654]\n","Epoch 273, loss = 0.2641, val.acc = [0.6444, 0.707, 0.752, 0.7626]\n","Epoch 274, loss = 0.2436, val.acc = [0.6548, 0.7138, 0.7556, 0.765]\n","Epoch 275, loss = 0.2771, val.acc = [0.6558, 0.7122, 0.7578, 0.7648]\n","Epoch 276, loss = 0.2558, val.acc = [0.6604, 0.713, 0.7556, 0.7652]\n","Epoch 277, loss = 0.2573, val.acc = [0.6556, 0.7174, 0.7594, 0.766]\n","Epoch 278, loss = 0.2724, val.acc = [0.6552, 0.7156, 0.757, 0.7658]\n","Epoch 279, loss = 0.2152, val.acc = [0.6604, 0.714, 0.759, 0.768]\n","Epoch 280, loss = 0.2578, val.acc = [0.6548, 0.7022, 0.756, 0.7646]\n","Epoch 281, loss = 0.2413, val.acc = [0.6584, 0.7064, 0.755, 0.7696]\n","Epoch 282, loss = 0.2654, val.acc = [0.6634, 0.7054, 0.7528, 0.7676]\n","Epoch 283, loss = 0.2663, val.acc = [0.6584, 0.7106, 0.7592, 0.7714]\n","Epoch 284, loss = 0.2571, val.acc = [0.6494, 0.7096, 0.7574, 0.766]\n","Epoch 285, loss = 0.2450, val.acc = [0.6178, 0.7012, 0.7394, 0.7496]\n","Epoch 286, loss = 0.2560, val.acc = [0.6636, 0.7116, 0.7534, 0.7652]\n","Epoch 287, loss = 0.2307, val.acc = [0.6398, 0.7168, 0.753, 0.7648]\n","Epoch 288, loss = 0.2630, val.acc = [0.6556, 0.7072, 0.7482, 0.7662]\n","Epoch 289, loss = 0.2816, val.acc = [0.6612, 0.7122, 0.7546, 0.7708]\n","Epoch 290, loss = 0.3035, val.acc = [0.657, 0.7152, 0.7564, 0.7668]\n","Epoch 291, loss = 0.2395, val.acc = [0.6528, 0.7124, 0.7586, 0.7684]\n","Epoch 292, loss = 0.2415, val.acc = [0.6614, 0.7018, 0.7576, 0.7668]\n","Epoch 293, loss = 0.2726, val.acc = [0.6436, 0.7076, 0.747, 0.7632]\n","Epoch 294, loss = 0.2368, val.acc = [0.664, 0.7122, 0.7592, 0.7672]\n","Epoch 295, loss = 0.2377, val.acc = [0.6616, 0.7128, 0.7586, 0.7698]\n","Epoch 296, loss = 0.2570, val.acc = [0.6452, 0.7102, 0.754, 0.7658]\n","Epoch 297, loss = 0.2236, val.acc = [0.6538, 0.7108, 0.7536, 0.763]\n","Epoch 298, loss = 0.2539, val.acc = [0.6584, 0.7086, 0.7544, 0.7644]\n","Epoch 299, loss = 0.2399, val.acc = [0.6534, 0.71, 0.7534, 0.7656]\n","Epoch 300, loss = 0.2458, val.acc = [0.6116, 0.7136, 0.753, 0.7638]\n","Epoch 301, loss = 0.2822, val.acc = [0.6604, 0.7082, 0.7544, 0.7654]\n","Epoch 302, loss = 0.2464, val.acc = [0.659, 0.708, 0.7546, 0.7652]\n","Epoch 303, loss = 0.2827, val.acc = [0.6588, 0.7056, 0.7548, 0.7658]\n","Epoch 304, loss = 0.2615, val.acc = [0.6332, 0.704, 0.7536, 0.7622]\n","Epoch 305, loss = 0.2556, val.acc = [0.6542, 0.7116, 0.754, 0.767]\n","Epoch 306, loss = 0.2342, val.acc = [0.6606, 0.712, 0.7552, 0.767]\n","Epoch 307, loss = 0.2446, val.acc = [0.6628, 0.7166, 0.7536, 0.7704]\n","Epoch 308, loss = 0.2791, val.acc = [0.6552, 0.7084, 0.7564, 0.7666]\n","Epoch 309, loss = 0.2611, val.acc = [0.631, 0.706, 0.7534, 0.7668]\n","Epoch 310, loss = 0.2312, val.acc = [0.6664, 0.7158, 0.7542, 0.7656]\n","Epoch 311, loss = 0.2063, val.acc = [0.6368, 0.7146, 0.7516, 0.7648]\n","Epoch 312, loss = 0.3055, val.acc = [0.6614, 0.7154, 0.7554, 0.7642]\n","Epoch 313, loss = 0.2019, val.acc = [0.6536, 0.7086, 0.7526, 0.763]\n","Epoch 314, loss = 0.2280, val.acc = [0.6664, 0.7052, 0.7542, 0.7634]\n","Epoch 315, loss = 0.1851, val.acc = [0.6514, 0.7114, 0.7566, 0.7652]\n","Epoch 316, loss = 0.2459, val.acc = [0.6422, 0.7134, 0.7548, 0.7666]\n","Epoch 317, loss = 0.2278, val.acc = [0.6594, 0.7106, 0.7548, 0.7674]\n","Epoch 318, loss = 0.2275, val.acc = [0.6574, 0.7134, 0.7562, 0.7656]\n","Epoch 319, loss = 0.2426, val.acc = [0.6334, 0.712, 0.751, 0.7614]\n","Epoch 320, loss = 0.2406, val.acc = [0.6558, 0.7148, 0.7552, 0.7654]\n","Epoch 321, loss = 0.2194, val.acc = [0.6572, 0.7156, 0.7534, 0.77]\n","Epoch 322, loss = 0.1912, val.acc = [0.654, 0.7134, 0.7506, 0.7648]\n","Epoch 323, loss = 0.1934, val.acc = [0.64, 0.7036, 0.7512, 0.7642]\n","Epoch 324, loss = 0.2042, val.acc = [0.6652, 0.7064, 0.7556, 0.7666]\n","Epoch 325, loss = 0.2433, val.acc = [0.651, 0.7092, 0.7536, 0.7692]\n","Epoch 326, loss = 0.2270, val.acc = [0.6432, 0.7104, 0.753, 0.7636]\n","Epoch 327, loss = 0.2159, val.acc = [0.6572, 0.7126, 0.7574, 0.7642]\n","Epoch 328, loss = 0.2051, val.acc = [0.647, 0.7064, 0.7554, 0.7652]\n","Epoch 329, loss = 0.1933, val.acc = [0.651, 0.7086, 0.7496, 0.7594]\n","Epoch 330, loss = 0.2101, val.acc = [0.6562, 0.7098, 0.7548, 0.7676]\n","Epoch 331, loss = 0.2240, val.acc = [0.6586, 0.7074, 0.7516, 0.7632]\n","Epoch 332, loss = 0.1758, val.acc = [0.6546, 0.71, 0.7572, 0.7664]\n","Epoch 333, loss = 0.2219, val.acc = [0.6492, 0.7134, 0.7562, 0.7716]\n","Epoch 334, loss = 0.2298, val.acc = [0.6582, 0.705, 0.7566, 0.7688]\n","Epoch 335, loss = 0.2153, val.acc = [0.6512, 0.7132, 0.7558, 0.7696]\n","Epoch 336, loss = 0.1915, val.acc = [0.6478, 0.7084, 0.7552, 0.7624]\n","Epoch 337, loss = 0.2150, val.acc = [0.6316, 0.6934, 0.7448, 0.7592]\n","Epoch 338, loss = 0.2037, val.acc = [0.6596, 0.7092, 0.7568, 0.7638]\n","Epoch 339, loss = 0.2204, val.acc = [0.658, 0.711, 0.7558, 0.763]\n","Epoch 340, loss = 0.2138, val.acc = [0.6544, 0.7092, 0.754, 0.7642]\n","Epoch 341, loss = 0.2057, val.acc = [0.658, 0.708, 0.7576, 0.7642]\n","Epoch 342, loss = 0.2077, val.acc = [0.6554, 0.7086, 0.7532, 0.765]\n","Epoch 343, loss = 0.2037, val.acc = [0.6532, 0.7106, 0.755, 0.7672]\n","Epoch 344, loss = 0.2198, val.acc = [0.658, 0.7116, 0.7546, 0.7652]\n","Epoch 345, loss = 0.2209, val.acc = [0.6244, 0.7118, 0.748, 0.7588]\n","Epoch 346, loss = 0.1928, val.acc = [0.6584, 0.7146, 0.7546, 0.7654]\n","Epoch 347, loss = 0.2120, val.acc = [0.6544, 0.7134, 0.7542, 0.7684]\n","Epoch 348, loss = 0.2446, val.acc = [0.6464, 0.7068, 0.7512, 0.7562]\n","Epoch 349, loss = 0.2142, val.acc = [0.6568, 0.7112, 0.7568, 0.7646]\n","Epoch 350, loss = 0.2041, val.acc = [0.649, 0.7096, 0.757, 0.7654]\n","Epoch 351, loss = 0.2158, val.acc = [0.6538, 0.7134, 0.7552, 0.7618]\n","Epoch 352, loss = 0.2445, val.acc = [0.6432, 0.7054, 0.753, 0.7628]\n","Epoch 353, loss = 0.2270, val.acc = [0.6528, 0.7092, 0.7526, 0.761]\n","Epoch 354, loss = 0.2343, val.acc = [0.6576, 0.7094, 0.7518, 0.7616]\n","Epoch 355, loss = 0.1944, val.acc = [0.6506, 0.7136, 0.755, 0.7654]\n","Epoch 356, loss = 0.2275, val.acc = [0.652, 0.7118, 0.755, 0.7632]\n","Epoch 357, loss = 0.2114, val.acc = [0.6566, 0.7112, 0.7542, 0.765]\n","Epoch 358, loss = 0.1872, val.acc = [0.6384, 0.7104, 0.7526, 0.7618]\n","Epoch 359, loss = 0.2198, val.acc = [0.6574, 0.7122, 0.755, 0.764]\n","Epoch 360, loss = 0.1300, val.acc = [0.6584, 0.7068, 0.7558, 0.7644]\n","Epoch 361, loss = 0.2160, val.acc = [0.6462, 0.7058, 0.757, 0.7626]\n","Epoch 362, loss = 0.2189, val.acc = [0.6482, 0.7082, 0.754, 0.7592]\n","Epoch 363, loss = 0.2087, val.acc = [0.6606, 0.708, 0.7526, 0.7638]\n","Epoch 364, loss = 0.2353, val.acc = [0.6428, 0.7112, 0.7552, 0.7664]\n","Epoch 365, loss = 0.1844, val.acc = [0.6544, 0.7076, 0.754, 0.7644]\n","Epoch 366, loss = 0.1862, val.acc = [0.6564, 0.7102, 0.7586, 0.7664]\n","Epoch 367, loss = 0.2121, val.acc = [0.6394, 0.7056, 0.7476, 0.7624]\n","Epoch 368, loss = 0.1894, val.acc = [0.6586, 0.716, 0.7568, 0.7654]\n","Epoch 369, loss = 0.1867, val.acc = [0.6414, 0.7062, 0.7578, 0.764]\n","Epoch 370, loss = 0.2411, val.acc = [0.6432, 0.7072, 0.7542, 0.7648]\n","Epoch 371, loss = 0.2155, val.acc = [0.6582, 0.71, 0.7548, 0.7664]\n","Epoch 372, loss = 0.1490, val.acc = [0.6616, 0.7072, 0.7578, 0.7668]\n","Epoch 373, loss = 0.1718, val.acc = [0.6536, 0.7138, 0.7522, 0.7632]\n","Epoch 374, loss = 0.2234, val.acc = [0.6512, 0.7094, 0.7552, 0.7662]\n","Epoch 375, loss = 0.1996, val.acc = [0.6562, 0.7066, 0.7546, 0.7598]\n","Epoch 376, loss = 0.2321, val.acc = [0.6442, 0.7052, 0.75, 0.7608]\n","Epoch 377, loss = 0.1884, val.acc = [0.648, 0.7082, 0.7532, 0.762]\n","Epoch 378, loss = 0.1944, val.acc = [0.6488, 0.7066, 0.7556, 0.7664]\n","Epoch 379, loss = 0.1918, val.acc = [0.652, 0.703, 0.7478, 0.7636]\n","Epoch 380, loss = 0.1704, val.acc = [0.6496, 0.7088, 0.754, 0.7644]\n","Epoch 381, loss = 0.1936, val.acc = [0.6394, 0.7012, 0.7528, 0.766]\n","Epoch 382, loss = 0.2214, val.acc = [0.6492, 0.7082, 0.7548, 0.763]\n","Epoch 383, loss = 0.1608, val.acc = [0.6532, 0.7074, 0.7576, 0.7654]\n","Epoch 384, loss = 0.1809, val.acc = [0.6496, 0.709, 0.7542, 0.765]\n","Epoch 385, loss = 0.1988, val.acc = [0.6606, 0.7106, 0.7526, 0.7644]\n","Epoch 386, loss = 0.1918, val.acc = [0.6456, 0.7084, 0.7526, 0.7644]\n","Epoch 387, loss = 0.1469, val.acc = [0.644, 0.6984, 0.7442, 0.7514]\n","Epoch 388, loss = 0.1739, val.acc = [0.654, 0.704, 0.7536, 0.7606]\n","Epoch 389, loss = 0.1480, val.acc = [0.6522, 0.7086, 0.753, 0.7628]\n","Epoch 390, loss = 0.1865, val.acc = [0.656, 0.7094, 0.7564, 0.7666]\n","Epoch 391, loss = 0.2220, val.acc = [0.645, 0.7106, 0.7522, 0.7628]\n","Epoch 392, loss = 0.2226, val.acc = [0.6496, 0.7034, 0.7536, 0.767]\n","Epoch 393, loss = 0.1887, val.acc = [0.659, 0.706, 0.7524, 0.7642]\n","Epoch 394, loss = 0.1962, val.acc = [0.649, 0.7082, 0.7476, 0.7552]\n","Epoch 395, loss = 0.1638, val.acc = [0.6492, 0.7032, 0.7508, 0.7608]\n","Epoch 396, loss = 0.1641, val.acc = [0.651, 0.7114, 0.7572, 0.767]\n","Epoch 397, loss = 0.1704, val.acc = [0.6484, 0.7104, 0.7566, 0.7652]\n","Epoch 398, loss = 0.1759, val.acc = [0.6372, 0.712, 0.7516, 0.7618]\n","Epoch 399, loss = 0.1928, val.acc = [0.6518, 0.7036, 0.7578, 0.761]\n","Rep: 1, te.acc = [0.6347, 0.6957, 0.7417, 0.7521]\n","\n","Rep 2\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 2.1359, val.acc = [0.3324, 0.3236, 0.2746, 0.2182]\n","Epoch 1, loss = 1.9351, val.acc = [0.3806, 0.3514, 0.3202, 0.2718]\n","Epoch 2, loss = 1.8530, val.acc = [0.403, 0.395, 0.3652, 0.3004]\n","Epoch 3, loss = 1.7657, val.acc = [0.4174, 0.418, 0.379, 0.336]\n","Epoch 4, loss = 1.7064, val.acc = [0.435, 0.4286, 0.3938, 0.3582]\n","Epoch 5, loss = 1.6686, val.acc = [0.4522, 0.4414, 0.422, 0.3732]\n","Epoch 6, loss = 1.6160, val.acc = [0.458, 0.4602, 0.4336, 0.3886]\n","Epoch 7, loss = 1.5895, val.acc = [0.4386, 0.4482, 0.4368, 0.3934]\n","Epoch 8, loss = 1.5905, val.acc = [0.4644, 0.4606, 0.4466, 0.4146]\n","Epoch 9, loss = 1.5214, val.acc = [0.4678, 0.4824, 0.4698, 0.4306]\n","Epoch 10, loss = 1.4954, val.acc = [0.4658, 0.4954, 0.4764, 0.4392]\n","Epoch 11, loss = 1.4923, val.acc = [0.447, 0.4514, 0.4426, 0.4026]\n","Epoch 12, loss = 1.4623, val.acc = [0.4856, 0.502, 0.4998, 0.461]\n","Epoch 13, loss = 1.4371, val.acc = [0.4946, 0.5122, 0.5094, 0.4756]\n","Epoch 14, loss = 1.4177, val.acc = [0.4944, 0.5284, 0.5134, 0.4914]\n","Epoch 15, loss = 1.3873, val.acc = [0.5102, 0.531, 0.5318, 0.4956]\n","Epoch 16, loss = 1.3665, val.acc = [0.5072, 0.5354, 0.5306, 0.501]\n","Epoch 17, loss = 1.3657, val.acc = [0.5004, 0.5316, 0.5304, 0.5012]\n","Epoch 18, loss = 1.3378, val.acc = [0.505, 0.5304, 0.535, 0.496]\n","Epoch 19, loss = 1.3191, val.acc = [0.523, 0.5504, 0.5528, 0.5202]\n","Epoch 20, loss = 1.3006, val.acc = [0.5336, 0.5544, 0.559, 0.53]\n","Epoch 21, loss = 1.2861, val.acc = [0.5288, 0.5654, 0.5682, 0.5406]\n","Epoch 22, loss = 1.2719, val.acc = [0.5184, 0.5448, 0.5578, 0.5204]\n","Epoch 23, loss = 1.2659, val.acc = [0.5388, 0.5702, 0.578, 0.5512]\n","Epoch 24, loss = 1.2357, val.acc = [0.5202, 0.582, 0.5764, 0.5494]\n","Epoch 25, loss = 1.2373, val.acc = [0.5478, 0.572, 0.5934, 0.5604]\n","Epoch 26, loss = 1.2095, val.acc = [0.5224, 0.5604, 0.5484, 0.5394]\n","Epoch 27, loss = 1.2126, val.acc = [0.545, 0.5822, 0.596, 0.5682]\n","Epoch 28, loss = 1.1818, val.acc = [0.544, 0.5882, 0.6074, 0.5824]\n","Epoch 29, loss = 1.1857, val.acc = [0.5568, 0.6038, 0.6104, 0.5912]\n","Epoch 30, loss = 1.1398, val.acc = [0.5548, 0.601, 0.6146, 0.5894]\n","Epoch 31, loss = 1.1639, val.acc = [0.5594, 0.618, 0.62, 0.6016]\n","Epoch 32, loss = 1.1288, val.acc = [0.5554, 0.6108, 0.6226, 0.5956]\n","Epoch 33, loss = 1.1276, val.acc = [0.5718, 0.6134, 0.6318, 0.611]\n","Epoch 34, loss = 1.1311, val.acc = [0.5636, 0.6238, 0.6436, 0.6156]\n","Epoch 35, loss = 1.1111, val.acc = [0.554, 0.6132, 0.6422, 0.619]\n","Epoch 36, loss = 1.0972, val.acc = [0.566, 0.6278, 0.6524, 0.6252]\n","Epoch 37, loss = 1.0894, val.acc = [0.5708, 0.6086, 0.6406, 0.6126]\n","Epoch 38, loss = 1.0647, val.acc = [0.5762, 0.623, 0.6558, 0.6324]\n","Epoch 39, loss = 1.1050, val.acc = [0.5606, 0.6226, 0.6542, 0.614]\n","Epoch 40, loss = 1.0279, val.acc = [0.5844, 0.6374, 0.6628, 0.6448]\n","Epoch 41, loss = 1.0203, val.acc = [0.583, 0.6394, 0.6646, 0.651]\n","Epoch 42, loss = 1.0169, val.acc = [0.5736, 0.6266, 0.6612, 0.6482]\n","Epoch 43, loss = 1.0104, val.acc = [0.5718, 0.6434, 0.6692, 0.6512]\n","Epoch 44, loss = 1.0186, val.acc = [0.5778, 0.6502, 0.6696, 0.6528]\n","Epoch 45, loss = 1.0209, val.acc = [0.5818, 0.6448, 0.6652, 0.6534]\n","Epoch 46, loss = 0.9920, val.acc = [0.5716, 0.6478, 0.6644, 0.6608]\n","Epoch 47, loss = 0.9963, val.acc = [0.5462, 0.6104, 0.6284, 0.6164]\n","Epoch 48, loss = 1.0040, val.acc = [0.5936, 0.65, 0.6606, 0.6594]\n","Epoch 49, loss = 0.9938, val.acc = [0.5886, 0.649, 0.6776, 0.6686]\n","Epoch 50, loss = 0.9638, val.acc = [0.6028, 0.6442, 0.6706, 0.6676]\n","Epoch 51, loss = 0.9830, val.acc = [0.5934, 0.662, 0.6872, 0.6758]\n","Epoch 52, loss = 0.9461, val.acc = [0.584, 0.6556, 0.6884, 0.677]\n","Epoch 53, loss = 0.9613, val.acc = [0.577, 0.6582, 0.6828, 0.667]\n","Epoch 54, loss = 0.9743, val.acc = [0.6048, 0.659, 0.6834, 0.6824]\n","Epoch 55, loss = 0.9409, val.acc = [0.5912, 0.66, 0.686, 0.6788]\n","Epoch 56, loss = 0.9229, val.acc = [0.608, 0.67, 0.6958, 0.6854]\n","Epoch 57, loss = 0.9518, val.acc = [0.582, 0.633, 0.6444, 0.6468]\n","Epoch 58, loss = 0.9232, val.acc = [0.6058, 0.6628, 0.6908, 0.6886]\n","Epoch 59, loss = 0.8935, val.acc = [0.612, 0.6758, 0.699, 0.6966]\n","Epoch 60, loss = 0.8882, val.acc = [0.5784, 0.6712, 0.6968, 0.6926]\n","Epoch 61, loss = 0.9050, val.acc = [0.6034, 0.6554, 0.6934, 0.6866]\n","Epoch 62, loss = 0.8845, val.acc = [0.6094, 0.6758, 0.7012, 0.6932]\n","Epoch 63, loss = 0.8647, val.acc = [0.6112, 0.6708, 0.7076, 0.7002]\n","Epoch 64, loss = 0.8726, val.acc = [0.6076, 0.674, 0.705, 0.7016]\n","Epoch 65, loss = 0.8848, val.acc = [0.5798, 0.6192, 0.6984, 0.689]\n","Epoch 66, loss = 0.8886, val.acc = [0.6138, 0.6718, 0.7074, 0.701]\n","Epoch 67, loss = 0.8516, val.acc = [0.6126, 0.6776, 0.708, 0.702]\n","Epoch 68, loss = 0.8358, val.acc = [0.614, 0.676, 0.7122, 0.7076]\n","Epoch 69, loss = 0.8652, val.acc = [0.6134, 0.6664, 0.702, 0.6884]\n","Epoch 70, loss = 0.8535, val.acc = [0.6166, 0.6688, 0.7138, 0.7116]\n","Epoch 71, loss = 0.8377, val.acc = [0.5902, 0.679, 0.7088, 0.7094]\n","Epoch 72, loss = 0.8481, val.acc = [0.6164, 0.6734, 0.7072, 0.7088]\n","Epoch 73, loss = 0.8381, val.acc = [0.6188, 0.6874, 0.7066, 0.7126]\n","Epoch 74, loss = 0.8458, val.acc = [0.59, 0.6888, 0.7138, 0.7116]\n","Epoch 75, loss = 0.8405, val.acc = [0.6178, 0.682, 0.7218, 0.721]\n","Epoch 76, loss = 0.8393, val.acc = [0.6014, 0.6804, 0.7154, 0.7168]\n","Epoch 77, loss = 0.8234, val.acc = [0.6094, 0.6762, 0.7102, 0.711]\n","Epoch 78, loss = 0.8096, val.acc = [0.627, 0.6806, 0.7202, 0.7208]\n","Epoch 79, loss = 0.7824, val.acc = [0.6306, 0.6918, 0.7252, 0.7284]\n","Epoch 80, loss = 0.7911, val.acc = [0.6296, 0.6908, 0.7242, 0.7286]\n","Epoch 81, loss = 0.7699, val.acc = [0.6234, 0.6876, 0.7302, 0.7294]\n","Epoch 82, loss = 0.7935, val.acc = [0.6094, 0.6654, 0.7098, 0.709]\n","Epoch 83, loss = 0.7931, val.acc = [0.6116, 0.6864, 0.7276, 0.7248]\n","Epoch 84, loss = 0.7733, val.acc = [0.6314, 0.6922, 0.7302, 0.7304]\n","Epoch 85, loss = 0.7645, val.acc = [0.6336, 0.692, 0.7308, 0.7358]\n","Epoch 86, loss = 0.7801, val.acc = [0.638, 0.6918, 0.7262, 0.732]\n","Epoch 87, loss = 0.7549, val.acc = [0.6328, 0.6932, 0.7274, 0.7288]\n","Epoch 88, loss = 0.7537, val.acc = [0.6106, 0.6956, 0.7312, 0.7238]\n","Epoch 89, loss = 0.7549, val.acc = [0.6368, 0.6896, 0.7316, 0.74]\n","Epoch 90, loss = 0.7364, val.acc = [0.6052, 0.6616, 0.7096, 0.7124]\n","Epoch 91, loss = 0.7326, val.acc = [0.6246, 0.6874, 0.7202, 0.7348]\n","Epoch 92, loss = 0.7121, val.acc = [0.6256, 0.6842, 0.7304, 0.7376]\n","Epoch 93, loss = 0.7088, val.acc = [0.6248, 0.6794, 0.7132, 0.7362]\n","Epoch 94, loss = 0.7399, val.acc = [0.6418, 0.6936, 0.7336, 0.7346]\n","Epoch 95, loss = 0.6947, val.acc = [0.6372, 0.6974, 0.7354, 0.7402]\n","Epoch 96, loss = 0.7203, val.acc = [0.642, 0.6972, 0.7368, 0.7424]\n","Epoch 97, loss = 0.7387, val.acc = [0.6468, 0.7034, 0.737, 0.7446]\n","Epoch 98, loss = 0.7365, val.acc = [0.6394, 0.6972, 0.7426, 0.737]\n","Epoch 99, loss = 0.7086, val.acc = [0.6304, 0.7046, 0.7334, 0.7502]\n","Epoch 100, loss = 0.7197, val.acc = [0.6224, 0.7004, 0.7292, 0.7476]\n","Epoch 101, loss = 0.6954, val.acc = [0.6304, 0.6962, 0.7366, 0.7428]\n","Epoch 102, loss = 0.7091, val.acc = [0.6342, 0.688, 0.7318, 0.7406]\n","Epoch 103, loss = 0.6724, val.acc = [0.6364, 0.7044, 0.7408, 0.7476]\n","Epoch 104, loss = 0.6653, val.acc = [0.633, 0.7002, 0.7408, 0.748]\n","Epoch 105, loss = 0.6706, val.acc = [0.6352, 0.7064, 0.7336, 0.7504]\n","Epoch 106, loss = 0.6700, val.acc = [0.6364, 0.7014, 0.7386, 0.7436]\n","Epoch 107, loss = 0.7073, val.acc = [0.6338, 0.6972, 0.7414, 0.7476]\n","Epoch 108, loss = 0.6534, val.acc = [0.6476, 0.6994, 0.7472, 0.7576]\n","Epoch 109, loss = 0.6764, val.acc = [0.6278, 0.6792, 0.7294, 0.732]\n","Epoch 110, loss = 0.6734, val.acc = [0.6372, 0.7098, 0.7408, 0.7524]\n","Epoch 111, loss = 0.6652, val.acc = [0.6392, 0.7042, 0.74, 0.7516]\n","Epoch 112, loss = 0.6849, val.acc = [0.642, 0.7032, 0.7408, 0.7538]\n","Epoch 113, loss = 0.6640, val.acc = [0.6464, 0.7118, 0.743, 0.7584]\n","Epoch 114, loss = 0.6544, val.acc = [0.6354, 0.6998, 0.7328, 0.7476]\n","Epoch 115, loss = 0.6328, val.acc = [0.6446, 0.7082, 0.74, 0.758]\n","Epoch 116, loss = 0.6613, val.acc = [0.636, 0.7128, 0.7474, 0.759]\n","Epoch 117, loss = 0.6514, val.acc = [0.624, 0.7146, 0.7446, 0.756]\n","Epoch 118, loss = 0.6284, val.acc = [0.6426, 0.6984, 0.7414, 0.749]\n","Epoch 119, loss = 0.6115, val.acc = [0.6412, 0.7068, 0.7414, 0.7572]\n","Epoch 120, loss = 0.6545, val.acc = [0.6482, 0.7014, 0.7404, 0.7496]\n","Epoch 121, loss = 0.6332, val.acc = [0.6414, 0.7162, 0.7466, 0.7586]\n","Epoch 122, loss = 0.6179, val.acc = [0.6224, 0.7144, 0.7318, 0.7504]\n","Epoch 123, loss = 0.6213, val.acc = [0.6352, 0.708, 0.7372, 0.7472]\n","Epoch 124, loss = 0.6151, val.acc = [0.6494, 0.7122, 0.7454, 0.7512]\n","Epoch 125, loss = 0.5842, val.acc = [0.613, 0.7106, 0.7318, 0.7576]\n","Epoch 126, loss = 0.6258, val.acc = [0.6338, 0.7092, 0.7418, 0.756]\n","Epoch 127, loss = 0.6011, val.acc = [0.6348, 0.708, 0.736, 0.7582]\n","Epoch 128, loss = 0.5960, val.acc = [0.6348, 0.7124, 0.7426, 0.7498]\n","Epoch 129, loss = 0.6053, val.acc = [0.642, 0.7098, 0.7418, 0.7574]\n","Epoch 130, loss = 0.6004, val.acc = [0.642, 0.711, 0.7406, 0.7608]\n","Epoch 131, loss = 0.5375, val.acc = [0.6508, 0.7128, 0.7494, 0.7606]\n","Epoch 132, loss = 0.6007, val.acc = [0.6444, 0.7128, 0.7544, 0.7656]\n","Epoch 133, loss = 0.6126, val.acc = [0.6272, 0.707, 0.7394, 0.7562]\n","Epoch 134, loss = 0.5442, val.acc = [0.6432, 0.7074, 0.751, 0.7582]\n","Epoch 135, loss = 0.5932, val.acc = [0.632, 0.7102, 0.7454, 0.758]\n","Epoch 136, loss = 0.5760, val.acc = [0.651, 0.7206, 0.7486, 0.7618]\n","Epoch 137, loss = 0.5581, val.acc = [0.6472, 0.7154, 0.7524, 0.7616]\n","Epoch 138, loss = 0.5645, val.acc = [0.6508, 0.7184, 0.747, 0.7552]\n","Epoch 139, loss = 0.5568, val.acc = [0.6502, 0.7148, 0.7498, 0.7644]\n","Epoch 140, loss = 0.5568, val.acc = [0.6454, 0.7104, 0.7448, 0.7594]\n","Epoch 141, loss = 0.5663, val.acc = [0.6388, 0.7154, 0.748, 0.759]\n","Epoch 142, loss = 0.5386, val.acc = [0.6508, 0.7134, 0.748, 0.759]\n","Epoch 143, loss = 0.5400, val.acc = [0.6486, 0.715, 0.7398, 0.7554]\n","Epoch 144, loss = 0.5563, val.acc = [0.649, 0.7142, 0.747, 0.7586]\n","Epoch 145, loss = 0.5514, val.acc = [0.6478, 0.7102, 0.7548, 0.7588]\n","Epoch 146, loss = 0.5227, val.acc = [0.6454, 0.6988, 0.738, 0.7462]\n","Epoch 147, loss = 0.5000, val.acc = [0.6552, 0.7148, 0.7546, 0.7616]\n","Epoch 148, loss = 0.5252, val.acc = [0.6558, 0.7174, 0.7538, 0.7616]\n","Epoch 149, loss = 0.5911, val.acc = [0.6416, 0.719, 0.7518, 0.7616]\n","Epoch 150, loss = 0.5085, val.acc = [0.637, 0.7126, 0.7544, 0.7596]\n","Epoch 151, loss = 0.5193, val.acc = [0.6208, 0.6998, 0.7288, 0.7392]\n","Epoch 152, loss = 0.5157, val.acc = [0.6512, 0.7218, 0.754, 0.7638]\n","Epoch 153, loss = 0.5224, val.acc = [0.6476, 0.7224, 0.753, 0.7634]\n","Epoch 154, loss = 0.5725, val.acc = [0.6544, 0.714, 0.7552, 0.763]\n","Epoch 155, loss = 0.5120, val.acc = [0.6522, 0.7142, 0.7548, 0.7674]\n","Epoch 156, loss = 0.5463, val.acc = [0.6324, 0.719, 0.7562, 0.7638]\n","Epoch 157, loss = 0.5365, val.acc = [0.6538, 0.7162, 0.7534, 0.7632]\n","Epoch 158, loss = 0.4917, val.acc = [0.644, 0.7228, 0.7572, 0.7696]\n","Epoch 159, loss = 0.5292, val.acc = [0.641, 0.7094, 0.7422, 0.76]\n","Epoch 160, loss = 0.4630, val.acc = [0.6404, 0.718, 0.751, 0.7634]\n","Epoch 161, loss = 0.5058, val.acc = [0.6434, 0.7126, 0.7522, 0.768]\n","Epoch 162, loss = 0.4793, val.acc = [0.6534, 0.715, 0.7558, 0.7634]\n","Epoch 163, loss = 0.4929, val.acc = [0.6466, 0.7174, 0.7504, 0.7582]\n","Epoch 164, loss = 0.5043, val.acc = [0.6434, 0.7074, 0.7434, 0.7624]\n","Epoch 165, loss = 0.4991, val.acc = [0.6326, 0.7064, 0.7348, 0.758]\n","Epoch 166, loss = 0.4896, val.acc = [0.6482, 0.7174, 0.7448, 0.7656]\n","Epoch 167, loss = 0.4499, val.acc = [0.6464, 0.7196, 0.7576, 0.7682]\n","Epoch 168, loss = 0.4595, val.acc = [0.6336, 0.7184, 0.7536, 0.7622]\n","Epoch 169, loss = 0.4747, val.acc = [0.6502, 0.72, 0.7548, 0.7656]\n","Epoch 170, loss = 0.4616, val.acc = [0.6242, 0.7208, 0.757, 0.764]\n","Epoch 171, loss = 0.4445, val.acc = [0.6536, 0.7132, 0.7524, 0.7628]\n","Epoch 172, loss = 0.4525, val.acc = [0.646, 0.7076, 0.756, 0.7636]\n","Epoch 173, loss = 0.4580, val.acc = [0.6574, 0.7202, 0.7564, 0.7678]\n","Epoch 174, loss = 0.4618, val.acc = [0.6448, 0.7086, 0.7512, 0.7678]\n","Epoch 175, loss = 0.4310, val.acc = [0.649, 0.7208, 0.7566, 0.7682]\n","Epoch 176, loss = 0.4387, val.acc = [0.6546, 0.7114, 0.7464, 0.7576]\n","Epoch 177, loss = 0.4460, val.acc = [0.6468, 0.7134, 0.7574, 0.7676]\n","Epoch 178, loss = 0.4735, val.acc = [0.6516, 0.7164, 0.7564, 0.7686]\n","Epoch 179, loss = 0.4729, val.acc = [0.6488, 0.713, 0.7526, 0.771]\n","Epoch 180, loss = 0.4208, val.acc = [0.6436, 0.714, 0.7534, 0.7656]\n","Epoch 181, loss = 0.4505, val.acc = [0.6354, 0.7012, 0.74, 0.7592]\n","Epoch 182, loss = 0.4344, val.acc = [0.631, 0.719, 0.7542, 0.7662]\n","Epoch 183, loss = 0.4242, val.acc = [0.6552, 0.7198, 0.7586, 0.7662]\n","Epoch 184, loss = 0.4115, val.acc = [0.6522, 0.717, 0.7568, 0.7624]\n","Epoch 185, loss = 0.4410, val.acc = [0.6486, 0.7226, 0.7556, 0.765]\n","Epoch 186, loss = 0.4498, val.acc = [0.6214, 0.7158, 0.7598, 0.765]\n","Epoch 187, loss = 0.4575, val.acc = [0.6552, 0.7204, 0.7592, 0.7638]\n","Epoch 188, loss = 0.4296, val.acc = [0.6484, 0.7186, 0.7564, 0.7584]\n","Epoch 189, loss = 0.4085, val.acc = [0.6424, 0.7188, 0.7572, 0.7622]\n","Epoch 190, loss = 0.4435, val.acc = [0.6488, 0.7184, 0.755, 0.7658]\n","Epoch 191, loss = 0.3783, val.acc = [0.6524, 0.7206, 0.7602, 0.7684]\n","Epoch 192, loss = 0.4536, val.acc = [0.6464, 0.72, 0.7568, 0.7664]\n","Epoch 193, loss = 0.4005, val.acc = [0.6536, 0.7212, 0.7578, 0.7676]\n","Epoch 194, loss = 0.3783, val.acc = [0.6542, 0.7116, 0.7598, 0.7668]\n","Epoch 195, loss = 0.4469, val.acc = [0.6546, 0.7172, 0.7566, 0.7666]\n","Epoch 196, loss = 0.3963, val.acc = [0.6508, 0.7206, 0.7594, 0.7686]\n","Epoch 197, loss = 0.4131, val.acc = [0.6596, 0.715, 0.7588, 0.7678]\n","Epoch 198, loss = 0.3938, val.acc = [0.6402, 0.7038, 0.7586, 0.7642]\n","Epoch 199, loss = 0.3839, val.acc = [0.6488, 0.7186, 0.7552, 0.767]\n","Epoch 200, loss = 0.4142, val.acc = [0.636, 0.7056, 0.7582, 0.768]\n","Epoch 201, loss = 0.3992, val.acc = [0.6418, 0.713, 0.7502, 0.7612]\n","Epoch 202, loss = 0.4073, val.acc = [0.6502, 0.7248, 0.7562, 0.7658]\n","Epoch 203, loss = 0.3641, val.acc = [0.6482, 0.7226, 0.7594, 0.769]\n","Epoch 204, loss = 0.3774, val.acc = [0.6562, 0.7206, 0.758, 0.7638]\n","Epoch 205, loss = 0.3887, val.acc = [0.6532, 0.716, 0.7588, 0.7674]\n","Epoch 206, loss = 0.3922, val.acc = [0.6454, 0.7214, 0.7592, 0.7688]\n","Epoch 207, loss = 0.3460, val.acc = [0.656, 0.723, 0.7616, 0.7716]\n","Epoch 208, loss = 0.3470, val.acc = [0.6464, 0.72, 0.7492, 0.7706]\n","Epoch 209, loss = 0.3965, val.acc = [0.658, 0.7192, 0.7604, 0.7582]\n","Epoch 210, loss = 0.4268, val.acc = [0.6598, 0.7198, 0.763, 0.7682]\n","Epoch 211, loss = 0.3731, val.acc = [0.658, 0.7232, 0.7606, 0.7668]\n","Epoch 212, loss = 0.3573, val.acc = [0.6376, 0.7026, 0.7442, 0.7582]\n","Epoch 213, loss = 0.3970, val.acc = [0.649, 0.721, 0.7564, 0.7608]\n","Epoch 214, loss = 0.3646, val.acc = [0.6434, 0.7152, 0.7604, 0.7668]\n","Epoch 215, loss = 0.3426, val.acc = [0.648, 0.72, 0.7584, 0.772]\n","Epoch 216, loss = 0.3421, val.acc = [0.6526, 0.7258, 0.7554, 0.7692]\n","Epoch 217, loss = 0.4039, val.acc = [0.6408, 0.7174, 0.756, 0.765]\n","Epoch 218, loss = 0.3434, val.acc = [0.6506, 0.7192, 0.754, 0.7682]\n","Epoch 219, loss = 0.3503, val.acc = [0.6534, 0.7196, 0.757, 0.767]\n","Epoch 220, loss = 0.3956, val.acc = [0.6536, 0.7202, 0.7594, 0.7708]\n","Epoch 221, loss = 0.3504, val.acc = [0.6494, 0.7104, 0.7618, 0.7706]\n","Epoch 222, loss = 0.3475, val.acc = [0.6478, 0.7176, 0.7594, 0.7684]\n","Epoch 223, loss = 0.3473, val.acc = [0.6562, 0.718, 0.7566, 0.7672]\n","Epoch 224, loss = 0.3227, val.acc = [0.6596, 0.7198, 0.761, 0.7672]\n","Epoch 225, loss = 0.3326, val.acc = [0.6592, 0.7202, 0.7582, 0.7662]\n","Epoch 226, loss = 0.3649, val.acc = [0.6458, 0.7158, 0.7608, 0.7668]\n","Epoch 227, loss = 0.4009, val.acc = [0.6536, 0.7186, 0.7568, 0.766]\n","Epoch 228, loss = 0.3085, val.acc = [0.6468, 0.7212, 0.761, 0.7672]\n","Epoch 229, loss = 0.3475, val.acc = [0.6556, 0.7222, 0.76, 0.7702]\n","Epoch 230, loss = 0.3579, val.acc = [0.6484, 0.7204, 0.7622, 0.7704]\n","Epoch 231, loss = 0.3384, val.acc = [0.6506, 0.722, 0.7634, 0.768]\n","Epoch 232, loss = 0.3214, val.acc = [0.6404, 0.7154, 0.7588, 0.7684]\n","Epoch 233, loss = 0.3053, val.acc = [0.6354, 0.7196, 0.755, 0.765]\n","Epoch 234, loss = 0.3518, val.acc = [0.6492, 0.7216, 0.7614, 0.7678]\n","Epoch 235, loss = 0.3226, val.acc = [0.6392, 0.7224, 0.758, 0.7702]\n","Epoch 236, loss = 0.3481, val.acc = [0.654, 0.7152, 0.754, 0.7622]\n","Epoch 237, loss = 0.3267, val.acc = [0.6498, 0.7148, 0.762, 0.7704]\n","Epoch 238, loss = 0.3251, val.acc = [0.6396, 0.7138, 0.751, 0.7622]\n","Epoch 239, loss = 0.3305, val.acc = [0.6486, 0.7242, 0.753, 0.7646]\n","Epoch 240, loss = 0.3104, val.acc = [0.656, 0.7196, 0.7574, 0.7712]\n","Epoch 241, loss = 0.3314, val.acc = [0.6476, 0.7162, 0.7538, 0.7682]\n","Epoch 242, loss = 0.3601, val.acc = [0.6584, 0.7214, 0.7564, 0.7646]\n","Epoch 243, loss = 0.2390, val.acc = [0.658, 0.7214, 0.761, 0.771]\n","Epoch 244, loss = 0.3098, val.acc = [0.6582, 0.7238, 0.7606, 0.7716]\n","Epoch 245, loss = 0.3008, val.acc = [0.6442, 0.7186, 0.76, 0.7662]\n","Epoch 246, loss = 0.2834, val.acc = [0.6508, 0.718, 0.7582, 0.7682]\n","Epoch 247, loss = 0.3009, val.acc = [0.6466, 0.7238, 0.7504, 0.7678]\n","Epoch 248, loss = 0.3115, val.acc = [0.6464, 0.7198, 0.7596, 0.763]\n","Epoch 249, loss = 0.3427, val.acc = [0.6416, 0.7152, 0.7584, 0.773]\n","Epoch 250, loss = 0.2820, val.acc = [0.6512, 0.7186, 0.759, 0.7694]\n","Epoch 251, loss = 0.3034, val.acc = [0.6524, 0.7206, 0.7604, 0.7634]\n","Epoch 252, loss = 0.3056, val.acc = [0.6464, 0.7194, 0.76, 0.7664]\n","Epoch 253, loss = 0.3148, val.acc = [0.6292, 0.709, 0.7572, 0.765]\n","Epoch 254, loss = 0.2832, val.acc = [0.6284, 0.7022, 0.7528, 0.7618]\n","Epoch 255, loss = 0.3023, val.acc = [0.6428, 0.7184, 0.7586, 0.768]\n","Epoch 256, loss = 0.2863, val.acc = [0.6456, 0.7074, 0.7572, 0.7658]\n","Epoch 257, loss = 0.2857, val.acc = [0.6444, 0.7206, 0.7584, 0.7666]\n","Epoch 258, loss = 0.3102, val.acc = [0.653, 0.7168, 0.7552, 0.7666]\n","Epoch 259, loss = 0.3003, val.acc = [0.6362, 0.719, 0.7522, 0.7648]\n","Epoch 260, loss = 0.3085, val.acc = [0.6508, 0.7136, 0.7568, 0.7652]\n","Epoch 261, loss = 0.2611, val.acc = [0.6544, 0.7178, 0.7584, 0.7698]\n","Epoch 262, loss = 0.2522, val.acc = [0.6492, 0.712, 0.7612, 0.7654]\n","Epoch 263, loss = 0.2867, val.acc = [0.6558, 0.7198, 0.7592, 0.7688]\n","Epoch 264, loss = 0.2913, val.acc = [0.6342, 0.718, 0.7556, 0.7662]\n","Epoch 265, loss = 0.3054, val.acc = [0.627, 0.7088, 0.745, 0.7542]\n","Epoch 266, loss = 0.2311, val.acc = [0.6532, 0.717, 0.754, 0.7652]\n","Epoch 267, loss = 0.2730, val.acc = [0.6496, 0.7232, 0.7634, 0.77]\n","Epoch 268, loss = 0.2546, val.acc = [0.6374, 0.7206, 0.7582, 0.7658]\n","Epoch 269, loss = 0.2652, val.acc = [0.6344, 0.7196, 0.7572, 0.7676]\n","Epoch 270, loss = 0.2813, val.acc = [0.6502, 0.7234, 0.7604, 0.7714]\n","Epoch 271, loss = 0.2389, val.acc = [0.6472, 0.7234, 0.76, 0.7686]\n","Epoch 272, loss = 0.2435, val.acc = [0.6546, 0.7176, 0.7612, 0.7648]\n","Epoch 273, loss = 0.2386, val.acc = [0.6468, 0.7144, 0.7596, 0.768]\n","Epoch 274, loss = 0.2217, val.acc = [0.645, 0.7146, 0.7592, 0.7702]\n","Epoch 275, loss = 0.2279, val.acc = [0.6338, 0.7184, 0.755, 0.7642]\n","Epoch 276, loss = 0.2754, val.acc = [0.6474, 0.7198, 0.7544, 0.766]\n","Epoch 277, loss = 0.2700, val.acc = [0.6514, 0.7202, 0.7602, 0.769]\n","Epoch 278, loss = 0.3201, val.acc = [0.6484, 0.7194, 0.7528, 0.765]\n","Epoch 279, loss = 0.2887, val.acc = [0.6508, 0.723, 0.7606, 0.7686]\n","Epoch 280, loss = 0.2659, val.acc = [0.6308, 0.7176, 0.7498, 0.765]\n","Epoch 281, loss = 0.2486, val.acc = [0.6312, 0.7182, 0.7546, 0.7608]\n","Epoch 282, loss = 0.2717, val.acc = [0.6534, 0.7204, 0.755, 0.7658]\n","Epoch 283, loss = 0.2436, val.acc = [0.6468, 0.723, 0.7556, 0.7634]\n","Epoch 284, loss = 0.2749, val.acc = [0.6496, 0.719, 0.7542, 0.7696]\n","Epoch 285, loss = 0.2407, val.acc = [0.6394, 0.7142, 0.7556, 0.7688]\n","Epoch 286, loss = 0.2628, val.acc = [0.6336, 0.7218, 0.7558, 0.764]\n","Epoch 287, loss = 0.2598, val.acc = [0.64, 0.718, 0.7576, 0.769]\n","Epoch 288, loss = 0.2630, val.acc = [0.6504, 0.7172, 0.7626, 0.7682]\n","Epoch 289, loss = 0.2902, val.acc = [0.6526, 0.7216, 0.7628, 0.7674]\n","Epoch 290, loss = 0.2563, val.acc = [0.6484, 0.7132, 0.761, 0.7676]\n","Epoch 291, loss = 0.2768, val.acc = [0.654, 0.7222, 0.756, 0.7692]\n","Epoch 292, loss = 0.2546, val.acc = [0.6486, 0.7176, 0.7616, 0.7694]\n","Epoch 293, loss = 0.2329, val.acc = [0.6516, 0.7222, 0.7608, 0.7658]\n","Epoch 294, loss = 0.2072, val.acc = [0.6496, 0.7248, 0.7588, 0.772]\n","Epoch 295, loss = 0.2531, val.acc = [0.6474, 0.7238, 0.7652, 0.7678]\n","Epoch 296, loss = 0.3109, val.acc = [0.6546, 0.7204, 0.7602, 0.77]\n","Epoch 297, loss = 0.2547, val.acc = [0.643, 0.7206, 0.758, 0.7646]\n","Epoch 298, loss = 0.2660, val.acc = [0.647, 0.7202, 0.7606, 0.769]\n","Epoch 299, loss = 0.2539, val.acc = [0.6426, 0.711, 0.7548, 0.7662]\n","Epoch 300, loss = 0.2402, val.acc = [0.6496, 0.7204, 0.763, 0.7716]\n","Epoch 301, loss = 0.2213, val.acc = [0.6466, 0.715, 0.7584, 0.7696]\n","Epoch 302, loss = 0.2181, val.acc = [0.6442, 0.7114, 0.75, 0.7594]\n","Epoch 303, loss = 0.2760, val.acc = [0.6404, 0.714, 0.7568, 0.7708]\n","Epoch 304, loss = 0.2250, val.acc = [0.644, 0.7196, 0.7586, 0.7688]\n","Epoch 305, loss = 0.2247, val.acc = [0.6438, 0.7144, 0.7572, 0.7648]\n","Epoch 306, loss = 0.2290, val.acc = [0.6312, 0.7128, 0.759, 0.7684]\n","Epoch 307, loss = 0.2292, val.acc = [0.6488, 0.712, 0.7584, 0.7648]\n","Epoch 308, loss = 0.2273, val.acc = [0.6312, 0.717, 0.7528, 0.767]\n","Epoch 309, loss = 0.2624, val.acc = [0.6478, 0.719, 0.7548, 0.768]\n","Epoch 310, loss = 0.2244, val.acc = [0.6422, 0.7158, 0.756, 0.77]\n","Epoch 311, loss = 0.2289, val.acc = [0.6512, 0.7212, 0.76, 0.7738]\n","Epoch 312, loss = 0.2221, val.acc = [0.651, 0.725, 0.7576, 0.766]\n","Epoch 313, loss = 0.2465, val.acc = [0.6498, 0.7206, 0.7636, 0.771]\n","Epoch 314, loss = 0.2555, val.acc = [0.6458, 0.7176, 0.7618, 0.7688]\n","Epoch 315, loss = 0.2100, val.acc = [0.652, 0.7218, 0.7622, 0.7712]\n","Epoch 316, loss = 0.2355, val.acc = [0.6408, 0.7206, 0.759, 0.7724]\n","Epoch 317, loss = 0.2329, val.acc = [0.645, 0.7154, 0.7604, 0.7714]\n","Epoch 318, loss = 0.2153, val.acc = [0.6492, 0.7196, 0.7622, 0.7722]\n","Epoch 319, loss = 0.2553, val.acc = [0.6402, 0.7154, 0.7622, 0.768]\n","Epoch 320, loss = 0.2048, val.acc = [0.6418, 0.7178, 0.7574, 0.7682]\n","Epoch 321, loss = 0.2665, val.acc = [0.6456, 0.7152, 0.7572, 0.7668]\n","Epoch 322, loss = 0.2127, val.acc = [0.6424, 0.7054, 0.7592, 0.7676]\n","Epoch 323, loss = 0.2369, val.acc = [0.6334, 0.7188, 0.76, 0.7662]\n","Epoch 324, loss = 0.2040, val.acc = [0.6402, 0.7098, 0.7538, 0.7692]\n","Epoch 325, loss = 0.2102, val.acc = [0.6378, 0.72, 0.7538, 0.767]\n","Epoch 326, loss = 0.2144, val.acc = [0.6472, 0.7152, 0.7606, 0.7656]\n","Epoch 327, loss = 0.2577, val.acc = [0.6398, 0.709, 0.7542, 0.768]\n","Epoch 328, loss = 0.2412, val.acc = [0.6396, 0.7162, 0.7612, 0.77]\n","Epoch 329, loss = 0.2403, val.acc = [0.6322, 0.7126, 0.7568, 0.7684]\n","Epoch 330, loss = 0.1867, val.acc = [0.6498, 0.7158, 0.7544, 0.7646]\n","Epoch 331, loss = 0.2391, val.acc = [0.647, 0.7224, 0.7548, 0.7682]\n","Epoch 332, loss = 0.2168, val.acc = [0.6392, 0.7156, 0.757, 0.768]\n","Epoch 333, loss = 0.2210, val.acc = [0.6362, 0.7198, 0.7554, 0.7668]\n","Epoch 334, loss = 0.2619, val.acc = [0.6492, 0.7116, 0.7556, 0.7674]\n","Epoch 335, loss = 0.2008, val.acc = [0.6392, 0.7174, 0.759, 0.7702]\n","Epoch 336, loss = 0.2068, val.acc = [0.634, 0.7116, 0.7528, 0.7674]\n","Epoch 337, loss = 0.1659, val.acc = [0.6416, 0.7168, 0.762, 0.7672]\n","Epoch 338, loss = 0.2046, val.acc = [0.6418, 0.715, 0.7578, 0.7692]\n","Epoch 339, loss = 0.1937, val.acc = [0.6476, 0.7172, 0.7612, 0.7706]\n","Epoch 340, loss = 0.2286, val.acc = [0.6326, 0.718, 0.7566, 0.7664]\n","Epoch 341, loss = 0.2045, val.acc = [0.6442, 0.7168, 0.7598, 0.7696]\n","Epoch 342, loss = 0.2123, val.acc = [0.6378, 0.7152, 0.7546, 0.7686]\n","Epoch 343, loss = 0.2215, val.acc = [0.6492, 0.7186, 0.759, 0.7674]\n","Epoch 344, loss = 0.1910, val.acc = [0.6432, 0.7064, 0.7544, 0.7662]\n","Epoch 345, loss = 0.1664, val.acc = [0.6492, 0.7112, 0.7562, 0.7682]\n","Epoch 346, loss = 0.1960, val.acc = [0.6372, 0.7094, 0.753, 0.7612]\n","Epoch 347, loss = 0.1990, val.acc = [0.646, 0.7162, 0.758, 0.7742]\n","Epoch 348, loss = 0.2191, val.acc = [0.6434, 0.7192, 0.7602, 0.774]\n","Epoch 349, loss = 0.1901, val.acc = [0.6208, 0.704, 0.7536, 0.764]\n","Epoch 350, loss = 0.2387, val.acc = [0.6426, 0.72, 0.7598, 0.767]\n","Epoch 351, loss = 0.2093, val.acc = [0.6448, 0.7144, 0.7552, 0.7702]\n","Epoch 352, loss = 0.1923, val.acc = [0.6488, 0.7192, 0.7588, 0.77]\n","Epoch 353, loss = 0.1935, val.acc = [0.6484, 0.7092, 0.7556, 0.7678]\n","Epoch 354, loss = 0.1950, val.acc = [0.6468, 0.7128, 0.7568, 0.7682]\n","Epoch 355, loss = 0.1940, val.acc = [0.6384, 0.7202, 0.758, 0.7718]\n","Epoch 356, loss = 0.1815, val.acc = [0.6422, 0.7144, 0.7604, 0.7708]\n","Epoch 357, loss = 0.1572, val.acc = [0.631, 0.713, 0.7628, 0.7734]\n","Epoch 358, loss = 0.2113, val.acc = [0.6386, 0.717, 0.7566, 0.768]\n","Epoch 359, loss = 0.1912, val.acc = [0.63, 0.7162, 0.7542, 0.7644]\n","Epoch 360, loss = 0.1936, val.acc = [0.6466, 0.7142, 0.7584, 0.7702]\n","Epoch 361, loss = 0.1657, val.acc = [0.643, 0.7094, 0.7568, 0.7676]\n","Epoch 362, loss = 0.2256, val.acc = [0.6478, 0.71, 0.758, 0.7664]\n","Epoch 363, loss = 0.2178, val.acc = [0.6448, 0.7122, 0.7572, 0.7686]\n","Epoch 364, loss = 0.2162, val.acc = [0.641, 0.716, 0.7602, 0.7704]\n","Epoch 365, loss = 0.1720, val.acc = [0.62, 0.7102, 0.754, 0.7656]\n","Epoch 366, loss = 0.2373, val.acc = [0.6422, 0.718, 0.7588, 0.7672]\n","Epoch 367, loss = 0.1770, val.acc = [0.6434, 0.7126, 0.7588, 0.769]\n","Epoch 368, loss = 0.1759, val.acc = [0.6448, 0.7148, 0.7606, 0.7686]\n","Epoch 369, loss = 0.1725, val.acc = [0.6334, 0.7118, 0.7558, 0.7696]\n","Epoch 370, loss = 0.1835, val.acc = [0.639, 0.7066, 0.7558, 0.768]\n","Epoch 371, loss = 0.1747, val.acc = [0.6408, 0.7154, 0.7582, 0.7726]\n","Epoch 372, loss = 0.1750, val.acc = [0.6156, 0.7064, 0.7454, 0.7648]\n","Epoch 373, loss = 0.2178, val.acc = [0.637, 0.7142, 0.7538, 0.7648]\n","Epoch 374, loss = 0.1747, val.acc = [0.6464, 0.7162, 0.7572, 0.7734]\n","Epoch 375, loss = 0.1567, val.acc = [0.6414, 0.7102, 0.7536, 0.7674]\n","Epoch 376, loss = 0.1375, val.acc = [0.6454, 0.7142, 0.7602, 0.77]\n","Epoch 377, loss = 0.2083, val.acc = [0.6372, 0.7122, 0.7584, 0.7662]\n","Epoch 378, loss = 0.2030, val.acc = [0.6448, 0.7142, 0.7568, 0.769]\n","Epoch 379, loss = 0.2055, val.acc = [0.642, 0.715, 0.7576, 0.7696]\n","Epoch 380, loss = 0.1571, val.acc = [0.6364, 0.7152, 0.7576, 0.768]\n","Epoch 381, loss = 0.1983, val.acc = [0.644, 0.7128, 0.7576, 0.7708]\n","Epoch 382, loss = 0.1728, val.acc = [0.6374, 0.7108, 0.7582, 0.7686]\n","Epoch 383, loss = 0.1811, val.acc = [0.6428, 0.7186, 0.756, 0.7674]\n","Epoch 384, loss = 0.1747, val.acc = [0.6428, 0.718, 0.755, 0.7684]\n","Epoch 385, loss = 0.1772, val.acc = [0.6414, 0.7174, 0.7622, 0.7702]\n","Epoch 386, loss = 0.1864, val.acc = [0.6384, 0.712, 0.7592, 0.7674]\n","Epoch 387, loss = 0.1782, val.acc = [0.6406, 0.716, 0.757, 0.7704]\n","Epoch 388, loss = 0.1527, val.acc = [0.646, 0.7144, 0.7606, 0.7702]\n","Epoch 389, loss = 0.1750, val.acc = [0.6368, 0.7194, 0.7622, 0.7674]\n","Epoch 390, loss = 0.1898, val.acc = [0.6402, 0.7136, 0.7554, 0.7688]\n","Epoch 391, loss = 0.1624, val.acc = [0.6458, 0.7152, 0.7618, 0.7664]\n","Epoch 392, loss = 0.1876, val.acc = [0.6418, 0.7148, 0.7594, 0.7684]\n","Epoch 393, loss = 0.2033, val.acc = [0.6434, 0.7146, 0.7538, 0.7636]\n","Epoch 394, loss = 0.1728, val.acc = [0.6342, 0.7112, 0.7548, 0.7654]\n","Epoch 395, loss = 0.1836, val.acc = [0.6374, 0.7148, 0.7578, 0.7672]\n","Epoch 396, loss = 0.1592, val.acc = [0.6394, 0.7112, 0.7548, 0.7632]\n","Epoch 397, loss = 0.1846, val.acc = [0.6416, 0.716, 0.7604, 0.7688]\n","Epoch 398, loss = 0.1733, val.acc = [0.6372, 0.7104, 0.7564, 0.7698]\n","Epoch 399, loss = 0.2016, val.acc = [0.6336, 0.7078, 0.756, 0.7682]\n","Rep: 2, te.acc = [0.6279, 0.6932, 0.7397, 0.754]\n","\n","Rep 3\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 2.1600, val.acc = [0.3556, 0.2992, 0.2714, 0.2242]\n","Epoch 1, loss = 1.9390, val.acc = [0.398, 0.3558, 0.3154, 0.2708]\n","Epoch 2, loss = 1.8508, val.acc = [0.418, 0.3928, 0.348, 0.3096]\n","Epoch 3, loss = 1.7645, val.acc = [0.4434, 0.408, 0.3832, 0.3346]\n","Epoch 4, loss = 1.7186, val.acc = [0.443, 0.4344, 0.4058, 0.3592]\n","Epoch 5, loss = 1.6562, val.acc = [0.4538, 0.4464, 0.4264, 0.3766]\n","Epoch 6, loss = 1.6413, val.acc = [0.447, 0.4572, 0.4346, 0.3908]\n","Epoch 7, loss = 1.5817, val.acc = [0.4718, 0.467, 0.4548, 0.4046]\n","Epoch 8, loss = 1.5779, val.acc = [0.4816, 0.485, 0.467, 0.4138]\n","Epoch 9, loss = 1.5150, val.acc = [0.4704, 0.4932, 0.4784, 0.4288]\n","Epoch 10, loss = 1.5006, val.acc = [0.4774, 0.4926, 0.4822, 0.4426]\n","Epoch 11, loss = 1.4587, val.acc = [0.4968, 0.503, 0.501, 0.4704]\n","Epoch 12, loss = 1.4328, val.acc = [0.5066, 0.5286, 0.5146, 0.4818]\n","Epoch 13, loss = 1.4120, val.acc = [0.4976, 0.526, 0.5216, 0.4842]\n","Epoch 14, loss = 1.3935, val.acc = [0.512, 0.5356, 0.5306, 0.4976]\n","Epoch 15, loss = 1.3562, val.acc = [0.5148, 0.5424, 0.5368, 0.4948]\n","Epoch 16, loss = 1.3621, val.acc = [0.5238, 0.5454, 0.5478, 0.5146]\n","Epoch 17, loss = 1.3245, val.acc = [0.5212, 0.5468, 0.5454, 0.5116]\n","Epoch 18, loss = 1.3075, val.acc = [0.5124, 0.5516, 0.5502, 0.5132]\n","Epoch 19, loss = 1.3276, val.acc = [0.5234, 0.558, 0.564, 0.538]\n","Epoch 20, loss = 1.2922, val.acc = [0.5204, 0.5772, 0.57, 0.541]\n","Epoch 21, loss = 1.2730, val.acc = [0.548, 0.578, 0.5754, 0.5482]\n","Epoch 22, loss = 1.2405, val.acc = [0.5402, 0.5712, 0.562, 0.5438]\n","Epoch 23, loss = 1.2535, val.acc = [0.5084, 0.5712, 0.556, 0.5278]\n","Epoch 24, loss = 1.2207, val.acc = [0.5574, 0.5846, 0.5876, 0.5694]\n","Epoch 25, loss = 1.2074, val.acc = [0.56, 0.5902, 0.596, 0.5692]\n","Epoch 26, loss = 1.1899, val.acc = [0.5588, 0.5992, 0.6032, 0.5782]\n","Epoch 27, loss = 1.1953, val.acc = [0.5512, 0.602, 0.5972, 0.5744]\n","Epoch 28, loss = 1.1647, val.acc = [0.5494, 0.6058, 0.6146, 0.5912]\n","Epoch 29, loss = 1.1557, val.acc = [0.5528, 0.595, 0.6206, 0.5998]\n","Epoch 30, loss = 1.1261, val.acc = [0.5684, 0.6074, 0.6172, 0.6008]\n","Epoch 31, loss = 1.1108, val.acc = [0.56, 0.6038, 0.6186, 0.6046]\n","Epoch 32, loss = 1.1127, val.acc = [0.5572, 0.6172, 0.6368, 0.6188]\n","Epoch 33, loss = 1.1341, val.acc = [0.5754, 0.6244, 0.6378, 0.6244]\n","Epoch 34, loss = 1.0833, val.acc = [0.5756, 0.6262, 0.6338, 0.6256]\n","Epoch 35, loss = 1.0767, val.acc = [0.5714, 0.62, 0.6426, 0.636]\n","Epoch 36, loss = 1.0835, val.acc = [0.568, 0.5834, 0.6136, 0.6064]\n","Epoch 37, loss = 1.0742, val.acc = [0.5772, 0.6214, 0.6402, 0.6306]\n","Epoch 38, loss = 1.0393, val.acc = [0.5316, 0.566, 0.6302, 0.6186]\n","Epoch 39, loss = 1.0391, val.acc = [0.5756, 0.6332, 0.6592, 0.6248]\n","Epoch 40, loss = 1.0427, val.acc = [0.5854, 0.628, 0.645, 0.643]\n","Epoch 41, loss = 1.0213, val.acc = [0.5778, 0.6442, 0.6664, 0.6552]\n","Epoch 42, loss = 1.0285, val.acc = [0.5928, 0.641, 0.6656, 0.6566]\n","Epoch 43, loss = 1.0364, val.acc = [0.5722, 0.6388, 0.6542, 0.6484]\n","Epoch 44, loss = 0.9954, val.acc = [0.5744, 0.6452, 0.6696, 0.6588]\n","Epoch 45, loss = 0.9851, val.acc = [0.5888, 0.6538, 0.6848, 0.6718]\n","Epoch 46, loss = 0.9849, val.acc = [0.6034, 0.6556, 0.6822, 0.673]\n","Epoch 47, loss = 0.9735, val.acc = [0.5976, 0.6584, 0.6864, 0.6768]\n","Epoch 48, loss = 0.9785, val.acc = [0.5896, 0.6572, 0.6758, 0.6762]\n","Epoch 49, loss = 0.9753, val.acc = [0.6046, 0.662, 0.674, 0.6808]\n","Epoch 50, loss = 0.9409, val.acc = [0.598, 0.6548, 0.688, 0.6866]\n","Epoch 51, loss = 0.9365, val.acc = [0.5916, 0.661, 0.6928, 0.6896]\n","Epoch 52, loss = 0.9439, val.acc = [0.6006, 0.6544, 0.6842, 0.686]\n","Epoch 53, loss = 0.9505, val.acc = [0.5688, 0.6546, 0.6852, 0.6798]\n","Epoch 54, loss = 0.9389, val.acc = [0.5924, 0.6406, 0.6778, 0.6756]\n","Epoch 55, loss = 0.9116, val.acc = [0.6002, 0.6452, 0.6938, 0.6842]\n","Epoch 56, loss = 0.8940, val.acc = [0.6024, 0.6682, 0.7036, 0.695]\n","Epoch 57, loss = 0.8820, val.acc = [0.6214, 0.6626, 0.7032, 0.6958]\n","Epoch 58, loss = 0.8839, val.acc = [0.5912, 0.632, 0.673, 0.6662]\n","Epoch 59, loss = 0.9210, val.acc = [0.586, 0.6426, 0.6606, 0.6714]\n","Epoch 60, loss = 0.9248, val.acc = [0.6022, 0.6756, 0.6938, 0.6974]\n","Epoch 61, loss = 0.8568, val.acc = [0.6138, 0.6748, 0.7018, 0.711]\n","Epoch 62, loss = 0.8638, val.acc = [0.6148, 0.6712, 0.705, 0.7096]\n","Epoch 63, loss = 0.8708, val.acc = [0.598, 0.653, 0.6912, 0.7004]\n","Epoch 64, loss = 0.8701, val.acc = [0.6006, 0.667, 0.7062, 0.7072]\n","Epoch 65, loss = 0.8600, val.acc = [0.603, 0.6602, 0.7052, 0.7066]\n","Epoch 66, loss = 0.8349, val.acc = [0.6238, 0.6826, 0.7138, 0.7222]\n","Epoch 67, loss = 0.8261, val.acc = [0.6162, 0.684, 0.715, 0.7186]\n","Epoch 68, loss = 0.8466, val.acc = [0.6174, 0.6612, 0.7086, 0.7078]\n","Epoch 69, loss = 0.8163, val.acc = [0.625, 0.6868, 0.7084, 0.7224]\n","Epoch 70, loss = 0.8228, val.acc = [0.6184, 0.6864, 0.7168, 0.7198]\n","Epoch 71, loss = 0.8370, val.acc = [0.6282, 0.6824, 0.7182, 0.7134]\n","Epoch 72, loss = 0.8088, val.acc = [0.6324, 0.674, 0.7062, 0.7138]\n","Epoch 73, loss = 0.8519, val.acc = [0.5896, 0.6442, 0.6846, 0.6948]\n","Epoch 74, loss = 0.7928, val.acc = [0.6114, 0.6818, 0.714, 0.7222]\n","Epoch 75, loss = 0.7812, val.acc = [0.6256, 0.6836, 0.7202, 0.7292]\n","Epoch 76, loss = 0.8221, val.acc = [0.6254, 0.6818, 0.718, 0.726]\n","Epoch 77, loss = 0.7965, val.acc = [0.6164, 0.6806, 0.7162, 0.7332]\n","Epoch 78, loss = 0.8053, val.acc = [0.6278, 0.685, 0.7256, 0.7244]\n","Epoch 79, loss = 0.7887, val.acc = [0.6246, 0.6846, 0.727, 0.7338]\n","Epoch 80, loss = 0.8002, val.acc = [0.6246, 0.69, 0.7238, 0.74]\n","Epoch 81, loss = 0.7794, val.acc = [0.6174, 0.6816, 0.7122, 0.7302]\n","Epoch 82, loss = 0.7705, val.acc = [0.6026, 0.6758, 0.7162, 0.7266]\n","Epoch 83, loss = 0.7927, val.acc = [0.6168, 0.6874, 0.7214, 0.738]\n","Epoch 84, loss = 0.7793, val.acc = [0.6212, 0.6856, 0.7116, 0.7364]\n","Epoch 85, loss = 0.7691, val.acc = [0.5968, 0.6524, 0.7054, 0.724]\n","Epoch 86, loss = 0.7326, val.acc = [0.6262, 0.684, 0.7224, 0.7422]\n","Epoch 87, loss = 0.7305, val.acc = [0.6282, 0.6962, 0.7284, 0.7424]\n","Epoch 88, loss = 0.7272, val.acc = [0.62, 0.693, 0.7324, 0.7394]\n","Epoch 89, loss = 0.7295, val.acc = [0.6182, 0.6966, 0.7248, 0.7402]\n","Epoch 90, loss = 0.7642, val.acc = [0.6104, 0.6724, 0.6942, 0.707]\n","Epoch 91, loss = 0.7347, val.acc = [0.638, 0.6896, 0.7262, 0.7458]\n","Epoch 92, loss = 0.7235, val.acc = [0.6206, 0.689, 0.732, 0.7422]\n","Epoch 93, loss = 0.7457, val.acc = [0.6194, 0.6932, 0.726, 0.7446]\n","Epoch 94, loss = 0.7190, val.acc = [0.619, 0.6856, 0.7218, 0.7428]\n","Epoch 95, loss = 0.7064, val.acc = [0.6354, 0.7036, 0.7354, 0.7492]\n","Epoch 96, loss = 0.7081, val.acc = [0.6314, 0.7018, 0.7312, 0.7508]\n","Epoch 97, loss = 0.7144, val.acc = [0.6292, 0.6962, 0.7314, 0.7438]\n","Epoch 98, loss = 0.6989, val.acc = [0.6382, 0.6932, 0.7362, 0.7492]\n","Epoch 99, loss = 0.7367, val.acc = [0.6374, 0.7014, 0.7338, 0.7468]\n","Epoch 100, loss = 0.6788, val.acc = [0.6404, 0.6992, 0.7332, 0.7516]\n","Epoch 101, loss = 0.7032, val.acc = [0.6256, 0.7042, 0.7368, 0.7494]\n","Epoch 102, loss = 0.6873, val.acc = [0.627, 0.6978, 0.7288, 0.7458]\n","Epoch 103, loss = 0.6691, val.acc = [0.6274, 0.699, 0.736, 0.7536]\n","Epoch 104, loss = 0.6724, val.acc = [0.644, 0.7038, 0.739, 0.754]\n","Epoch 105, loss = 0.6947, val.acc = [0.6248, 0.6926, 0.7232, 0.747]\n","Epoch 106, loss = 0.6794, val.acc = [0.6202, 0.6998, 0.7264, 0.7426]\n","Epoch 107, loss = 0.6900, val.acc = [0.6298, 0.6886, 0.7326, 0.7456]\n","Epoch 108, loss = 0.6405, val.acc = [0.6392, 0.701, 0.7342, 0.756]\n","Epoch 109, loss = 0.6651, val.acc = [0.6302, 0.6928, 0.7338, 0.7474]\n","Epoch 110, loss = 0.6829, val.acc = [0.6434, 0.695, 0.7446, 0.7562]\n","Epoch 111, loss = 0.6652, val.acc = [0.6384, 0.6998, 0.738, 0.7532]\n","Epoch 112, loss = 0.6418, val.acc = [0.625, 0.7028, 0.7352, 0.7544]\n","Epoch 113, loss = 0.6352, val.acc = [0.6444, 0.7116, 0.734, 0.7576]\n","Epoch 114, loss = 0.6530, val.acc = [0.6304, 0.6988, 0.7382, 0.7434]\n","Epoch 115, loss = 0.6289, val.acc = [0.646, 0.6996, 0.7452, 0.7546]\n","Epoch 116, loss = 0.6530, val.acc = [0.6422, 0.7028, 0.7332, 0.7556]\n","Epoch 117, loss = 0.6633, val.acc = [0.6536, 0.7118, 0.7388, 0.7586]\n","Epoch 118, loss = 0.6192, val.acc = [0.6378, 0.6936, 0.7202, 0.7448]\n","Epoch 119, loss = 0.6306, val.acc = [0.6452, 0.7018, 0.7428, 0.7616]\n","Epoch 120, loss = 0.6227, val.acc = [0.636, 0.7018, 0.7406, 0.7634]\n","Epoch 121, loss = 0.6178, val.acc = [0.6506, 0.7094, 0.7424, 0.7596]\n","Epoch 122, loss = 0.6107, val.acc = [0.64, 0.702, 0.7428, 0.7606]\n","Epoch 123, loss = 0.5647, val.acc = [0.6364, 0.7102, 0.744, 0.7628]\n","Epoch 124, loss = 0.6227, val.acc = [0.6344, 0.7108, 0.7362, 0.7576]\n","Epoch 125, loss = 0.5960, val.acc = [0.6404, 0.7062, 0.742, 0.7644]\n","Epoch 126, loss = 0.5693, val.acc = [0.6372, 0.7114, 0.738, 0.7574]\n","Epoch 127, loss = 0.6015, val.acc = [0.6374, 0.7082, 0.7356, 0.7544]\n","Epoch 128, loss = 0.6047, val.acc = [0.618, 0.7004, 0.7386, 0.7582]\n","Epoch 129, loss = 0.5915, val.acc = [0.6424, 0.7064, 0.7448, 0.7668]\n","Epoch 130, loss = 0.6265, val.acc = [0.651, 0.6992, 0.7382, 0.7576]\n","Epoch 131, loss = 0.5507, val.acc = [0.6348, 0.7064, 0.7462, 0.7576]\n","Epoch 132, loss = 0.5786, val.acc = [0.642, 0.697, 0.7458, 0.7662]\n","Epoch 133, loss = 0.5981, val.acc = [0.6442, 0.7048, 0.7358, 0.7588]\n","Epoch 134, loss = 0.5627, val.acc = [0.6346, 0.703, 0.7398, 0.7722]\n","Epoch 135, loss = 0.5416, val.acc = [0.6232, 0.7002, 0.7474, 0.7618]\n","Epoch 136, loss = 0.5452, val.acc = [0.6528, 0.7056, 0.7524, 0.765]\n","Epoch 137, loss = 0.5193, val.acc = [0.6556, 0.7152, 0.7488, 0.7644]\n","Epoch 138, loss = 0.5695, val.acc = [0.6498, 0.703, 0.7464, 0.7484]\n","Epoch 139, loss = 0.5581, val.acc = [0.639, 0.7006, 0.741, 0.7566]\n","Epoch 140, loss = 0.5408, val.acc = [0.649, 0.7124, 0.744, 0.7658]\n","Epoch 141, loss = 0.5723, val.acc = [0.6414, 0.7074, 0.7408, 0.7586]\n","Epoch 142, loss = 0.5256, val.acc = [0.6486, 0.713, 0.7486, 0.7672]\n","Epoch 143, loss = 0.5494, val.acc = [0.644, 0.6944, 0.7368, 0.759]\n","Epoch 144, loss = 0.5419, val.acc = [0.645, 0.7132, 0.7496, 0.7598]\n","Epoch 145, loss = 0.5278, val.acc = [0.6486, 0.7114, 0.749, 0.7624]\n","Epoch 146, loss = 0.5272, val.acc = [0.6468, 0.705, 0.7454, 0.7642]\n","Epoch 147, loss = 0.5172, val.acc = [0.6592, 0.714, 0.7468, 0.7634]\n","Epoch 148, loss = 0.5022, val.acc = [0.6596, 0.7122, 0.7488, 0.7602]\n","Epoch 149, loss = 0.5079, val.acc = [0.636, 0.7126, 0.7538, 0.7644]\n","Epoch 150, loss = 0.4811, val.acc = [0.6574, 0.7046, 0.7528, 0.766]\n","Epoch 151, loss = 0.4908, val.acc = [0.649, 0.7048, 0.7436, 0.7588]\n","Epoch 152, loss = 0.5109, val.acc = [0.6446, 0.7102, 0.7452, 0.766]\n","Epoch 153, loss = 0.4781, val.acc = [0.6346, 0.7178, 0.7492, 0.7718]\n","Epoch 154, loss = 0.4963, val.acc = [0.6318, 0.7078, 0.7416, 0.7646]\n","Epoch 155, loss = 0.4822, val.acc = [0.6378, 0.712, 0.739, 0.7612]\n","Epoch 156, loss = 0.5331, val.acc = [0.6508, 0.6954, 0.7488, 0.7656]\n","Epoch 157, loss = 0.5117, val.acc = [0.6584, 0.713, 0.749, 0.7678]\n","Epoch 158, loss = 0.5228, val.acc = [0.6526, 0.7118, 0.7476, 0.7674]\n","Epoch 159, loss = 0.4558, val.acc = [0.6334, 0.6998, 0.7382, 0.7616]\n","Epoch 160, loss = 0.4701, val.acc = [0.6464, 0.7082, 0.7474, 0.7636]\n","Epoch 161, loss = 0.5368, val.acc = [0.6554, 0.706, 0.7506, 0.7666]\n","Epoch 162, loss = 0.4969, val.acc = [0.6464, 0.716, 0.751, 0.7646]\n","Epoch 163, loss = 0.4284, val.acc = [0.6296, 0.713, 0.7472, 0.7698]\n","Epoch 164, loss = 0.4567, val.acc = [0.6526, 0.7192, 0.7532, 0.771]\n","Epoch 165, loss = 0.4580, val.acc = [0.6422, 0.7092, 0.7482, 0.764]\n","Epoch 166, loss = 0.4200, val.acc = [0.6518, 0.7126, 0.7514, 0.7636]\n","Epoch 167, loss = 0.4723, val.acc = [0.6558, 0.7132, 0.7544, 0.7742]\n","Epoch 168, loss = 0.4785, val.acc = [0.6562, 0.715, 0.754, 0.7618]\n","Epoch 169, loss = 0.4365, val.acc = [0.6478, 0.7018, 0.7494, 0.7608]\n","Epoch 170, loss = 0.5012, val.acc = [0.6532, 0.7226, 0.7502, 0.7634]\n","Epoch 171, loss = 0.4341, val.acc = [0.6432, 0.709, 0.7458, 0.7638]\n","Epoch 172, loss = 0.4960, val.acc = [0.6548, 0.7168, 0.7524, 0.7716]\n","Epoch 173, loss = 0.4455, val.acc = [0.629, 0.7102, 0.7498, 0.7692]\n","Epoch 174, loss = 0.4421, val.acc = [0.6512, 0.7176, 0.7556, 0.7694]\n","Epoch 175, loss = 0.4475, val.acc = [0.6432, 0.7166, 0.7456, 0.762]\n","Epoch 176, loss = 0.4661, val.acc = [0.6516, 0.7154, 0.7514, 0.7664]\n","Epoch 177, loss = 0.4387, val.acc = [0.6486, 0.712, 0.7504, 0.7628]\n","Epoch 178, loss = 0.4442, val.acc = [0.6562, 0.7098, 0.7546, 0.7632]\n","Epoch 179, loss = 0.4242, val.acc = [0.6452, 0.7072, 0.7488, 0.7664]\n","Epoch 180, loss = 0.4540, val.acc = [0.6296, 0.7066, 0.7458, 0.7704]\n","Epoch 181, loss = 0.4383, val.acc = [0.6548, 0.7158, 0.7514, 0.7732]\n","Epoch 182, loss = 0.4372, val.acc = [0.647, 0.7172, 0.7548, 0.7694]\n","Epoch 183, loss = 0.4559, val.acc = [0.643, 0.7098, 0.7532, 0.768]\n","Epoch 184, loss = 0.4310, val.acc = [0.6542, 0.7138, 0.7558, 0.7662]\n","Epoch 185, loss = 0.4138, val.acc = [0.6512, 0.7126, 0.7568, 0.7728]\n","Epoch 186, loss = 0.3864, val.acc = [0.6502, 0.714, 0.7432, 0.7674]\n","Epoch 187, loss = 0.4200, val.acc = [0.6546, 0.711, 0.75, 0.7666]\n","Epoch 188, loss = 0.4188, val.acc = [0.6474, 0.72, 0.756, 0.77]\n","Epoch 189, loss = 0.4269, val.acc = [0.656, 0.7116, 0.7428, 0.7634]\n","Epoch 190, loss = 0.4393, val.acc = [0.629, 0.7034, 0.7508, 0.7622]\n","Epoch 191, loss = 0.4291, val.acc = [0.6468, 0.7124, 0.7524, 0.7654]\n","Epoch 192, loss = 0.4090, val.acc = [0.6628, 0.7118, 0.7502, 0.7478]\n","Epoch 193, loss = 0.3371, val.acc = [0.6544, 0.713, 0.7504, 0.7658]\n","Epoch 194, loss = 0.4079, val.acc = [0.6558, 0.718, 0.755, 0.7742]\n","Epoch 195, loss = 0.3817, val.acc = [0.639, 0.715, 0.7476, 0.7634]\n","Epoch 196, loss = 0.3908, val.acc = [0.654, 0.7216, 0.7518, 0.7724]\n","Epoch 197, loss = 0.3958, val.acc = [0.6566, 0.7198, 0.7544, 0.7724]\n","Epoch 198, loss = 0.4105, val.acc = [0.6474, 0.712, 0.7502, 0.765]\n","Epoch 199, loss = 0.4011, val.acc = [0.6594, 0.7118, 0.7554, 0.7664]\n","Epoch 200, loss = 0.3072, val.acc = [0.6574, 0.7116, 0.7484, 0.766]\n","Epoch 201, loss = 0.3878, val.acc = [0.645, 0.712, 0.7546, 0.769]\n","Epoch 202, loss = 0.3541, val.acc = [0.6368, 0.7154, 0.7532, 0.7618]\n","Epoch 203, loss = 0.3863, val.acc = [0.6492, 0.7134, 0.755, 0.7696]\n","Epoch 204, loss = 0.3618, val.acc = [0.653, 0.7134, 0.76, 0.7776]\n","Epoch 205, loss = 0.3362, val.acc = [0.6532, 0.7108, 0.7532, 0.7746]\n","Epoch 206, loss = 0.3482, val.acc = [0.642, 0.714, 0.746, 0.771]\n","Epoch 207, loss = 0.4034, val.acc = [0.6616, 0.7102, 0.7548, 0.7686]\n","Epoch 208, loss = 0.3628, val.acc = [0.656, 0.7158, 0.7516, 0.7682]\n","Epoch 209, loss = 0.3442, val.acc = [0.6344, 0.705, 0.7408, 0.7558]\n","Epoch 210, loss = 0.3483, val.acc = [0.656, 0.7192, 0.7544, 0.7674]\n","Epoch 211, loss = 0.3696, val.acc = [0.6446, 0.7152, 0.7538, 0.7674]\n","Epoch 212, loss = 0.3502, val.acc = [0.6514, 0.713, 0.7504, 0.7714]\n","Epoch 213, loss = 0.3290, val.acc = [0.6522, 0.7124, 0.7512, 0.768]\n","Epoch 214, loss = 0.3603, val.acc = [0.6478, 0.7158, 0.7526, 0.7634]\n","Epoch 215, loss = 0.3365, val.acc = [0.6482, 0.7148, 0.7566, 0.767]\n","Epoch 216, loss = 0.3161, val.acc = [0.6486, 0.7068, 0.7584, 0.7754]\n","Epoch 217, loss = 0.3839, val.acc = [0.6432, 0.7132, 0.7504, 0.7692]\n","Epoch 218, loss = 0.3445, val.acc = [0.6494, 0.714, 0.7534, 0.7686]\n","Epoch 219, loss = 0.3294, val.acc = [0.6506, 0.7106, 0.7512, 0.769]\n","Epoch 220, loss = 0.3231, val.acc = [0.6548, 0.7168, 0.7536, 0.7704]\n","Epoch 221, loss = 0.3333, val.acc = [0.6562, 0.7178, 0.7566, 0.773]\n","Epoch 222, loss = 0.3492, val.acc = [0.6448, 0.7132, 0.7552, 0.7748]\n","Epoch 223, loss = 0.3356, val.acc = [0.6572, 0.7134, 0.7554, 0.7744]\n","Epoch 224, loss = 0.3190, val.acc = [0.6478, 0.7088, 0.7566, 0.7732]\n","Epoch 225, loss = 0.3534, val.acc = [0.654, 0.715, 0.7566, 0.7716]\n","Epoch 226, loss = 0.3826, val.acc = [0.6526, 0.7194, 0.7552, 0.7702]\n","Epoch 227, loss = 0.3558, val.acc = [0.6518, 0.7098, 0.7562, 0.7728]\n","Epoch 228, loss = 0.3347, val.acc = [0.6544, 0.7154, 0.7584, 0.7714]\n","Epoch 229, loss = 0.3172, val.acc = [0.6536, 0.7104, 0.7558, 0.7672]\n","Epoch 230, loss = 0.3326, val.acc = [0.655, 0.7158, 0.7584, 0.7728]\n","Epoch 231, loss = 0.3425, val.acc = [0.6532, 0.713, 0.7556, 0.7698]\n","Epoch 232, loss = 0.2973, val.acc = [0.6556, 0.7158, 0.7592, 0.7722]\n","Epoch 233, loss = 0.2915, val.acc = [0.6494, 0.7166, 0.7612, 0.7736]\n","Epoch 234, loss = 0.2705, val.acc = [0.6574, 0.7114, 0.7524, 0.7696]\n","Epoch 235, loss = 0.3346, val.acc = [0.6558, 0.7116, 0.7584, 0.7674]\n","Epoch 236, loss = 0.3150, val.acc = [0.655, 0.7152, 0.756, 0.7696]\n","Epoch 237, loss = 0.3210, val.acc = [0.6436, 0.714, 0.7524, 0.7706]\n","Epoch 238, loss = 0.3256, val.acc = [0.6556, 0.717, 0.757, 0.7742]\n","Epoch 239, loss = 0.2872, val.acc = [0.6534, 0.717, 0.7564, 0.7724]\n","Epoch 240, loss = 0.3368, val.acc = [0.6416, 0.7068, 0.7536, 0.7638]\n","Epoch 241, loss = 0.2818, val.acc = [0.6582, 0.7178, 0.7578, 0.7716]\n","Epoch 242, loss = 0.2670, val.acc = [0.6502, 0.714, 0.7554, 0.7732]\n","Epoch 243, loss = 0.3100, val.acc = [0.6558, 0.7228, 0.751, 0.766]\n","Epoch 244, loss = 0.2924, val.acc = [0.6502, 0.7106, 0.758, 0.7712]\n","Epoch 245, loss = 0.3233, val.acc = [0.6476, 0.7138, 0.7564, 0.7672]\n","Epoch 246, loss = 0.3320, val.acc = [0.6544, 0.7136, 0.7574, 0.7708]\n","Epoch 247, loss = 0.3084, val.acc = [0.6516, 0.7102, 0.7536, 0.768]\n","Epoch 248, loss = 0.3145, val.acc = [0.6558, 0.716, 0.7524, 0.773]\n","Epoch 249, loss = 0.3199, val.acc = [0.6566, 0.7176, 0.7546, 0.7716]\n","Epoch 250, loss = 0.2648, val.acc = [0.6498, 0.718, 0.756, 0.77]\n","Epoch 251, loss = 0.2713, val.acc = [0.6562, 0.7136, 0.7542, 0.7718]\n","Epoch 252, loss = 0.2686, val.acc = [0.651, 0.7084, 0.7474, 0.7628]\n","Epoch 253, loss = 0.3100, val.acc = [0.6582, 0.712, 0.76, 0.7716]\n","Epoch 254, loss = 0.2812, val.acc = [0.6518, 0.7142, 0.7544, 0.772]\n","Epoch 255, loss = 0.2703, val.acc = [0.6584, 0.7138, 0.7568, 0.7762]\n","Epoch 256, loss = 0.2737, val.acc = [0.6584, 0.7188, 0.757, 0.7746]\n","Epoch 257, loss = 0.2793, val.acc = [0.6524, 0.7158, 0.7548, 0.7752]\n","Epoch 258, loss = 0.3012, val.acc = [0.6512, 0.7124, 0.7554, 0.7704]\n","Epoch 259, loss = 0.3032, val.acc = [0.6512, 0.7148, 0.7566, 0.7736]\n","Epoch 260, loss = 0.2832, val.acc = [0.6536, 0.7146, 0.7554, 0.7682]\n","Epoch 261, loss = 0.2507, val.acc = [0.6512, 0.7164, 0.7574, 0.7706]\n","Epoch 262, loss = 0.2776, val.acc = [0.6434, 0.7104, 0.7566, 0.7676]\n","Epoch 263, loss = 0.2639, val.acc = [0.6498, 0.7146, 0.7554, 0.7734]\n","Epoch 264, loss = 0.2881, val.acc = [0.6542, 0.714, 0.7562, 0.7708]\n","Epoch 265, loss = 0.3504, val.acc = [0.6576, 0.7182, 0.7546, 0.7672]\n","Epoch 266, loss = 0.3021, val.acc = [0.6466, 0.7194, 0.7496, 0.7658]\n","Epoch 267, loss = 0.2482, val.acc = [0.6404, 0.7044, 0.7536, 0.7656]\n","Epoch 268, loss = 0.2164, val.acc = [0.6468, 0.7074, 0.748, 0.7644]\n","Epoch 269, loss = 0.2617, val.acc = [0.6476, 0.7126, 0.7562, 0.7704]\n","Epoch 270, loss = 0.2809, val.acc = [0.6536, 0.7108, 0.7562, 0.7698]\n","Epoch 271, loss = 0.2608, val.acc = [0.6552, 0.7178, 0.7562, 0.7652]\n","Epoch 272, loss = 0.2181, val.acc = [0.6504, 0.713, 0.7574, 0.7714]\n","Epoch 273, loss = 0.2654, val.acc = [0.6578, 0.716, 0.7598, 0.7668]\n","Epoch 274, loss = 0.2712, val.acc = [0.6558, 0.7172, 0.7528, 0.767]\n","Epoch 275, loss = 0.2273, val.acc = [0.656, 0.7094, 0.7542, 0.773]\n","Epoch 276, loss = 0.2598, val.acc = [0.6568, 0.7118, 0.7568, 0.7714]\n","Epoch 277, loss = 0.3112, val.acc = [0.6522, 0.7146, 0.7554, 0.769]\n","Epoch 278, loss = 0.2656, val.acc = [0.647, 0.715, 0.7526, 0.7692]\n","Epoch 279, loss = 0.2840, val.acc = [0.659, 0.7168, 0.7596, 0.7706]\n","Epoch 280, loss = 0.2452, val.acc = [0.6478, 0.7172, 0.7528, 0.7654]\n","Epoch 281, loss = 0.2626, val.acc = [0.6534, 0.7156, 0.7566, 0.7694]\n","Epoch 282, loss = 0.2441, val.acc = [0.646, 0.7138, 0.759, 0.7694]\n","Epoch 283, loss = 0.2560, val.acc = [0.6544, 0.7164, 0.7558, 0.7712]\n","Epoch 284, loss = 0.2471, val.acc = [0.6566, 0.719, 0.76, 0.7692]\n","Epoch 285, loss = 0.2488, val.acc = [0.644, 0.7132, 0.7592, 0.7696]\n","Epoch 286, loss = 0.2811, val.acc = [0.6516, 0.7124, 0.7574, 0.7684]\n","Epoch 287, loss = 0.2931, val.acc = [0.6436, 0.7142, 0.7572, 0.7664]\n","Epoch 288, loss = 0.2788, val.acc = [0.6512, 0.708, 0.753, 0.7648]\n","Epoch 289, loss = 0.2868, val.acc = [0.6512, 0.7096, 0.7572, 0.7706]\n","Epoch 290, loss = 0.2218, val.acc = [0.6556, 0.7074, 0.7614, 0.7706]\n","Epoch 291, loss = 0.2207, val.acc = [0.6562, 0.7144, 0.7548, 0.766]\n","Epoch 292, loss = 0.2231, val.acc = [0.655, 0.7128, 0.7522, 0.7636]\n","Epoch 293, loss = 0.2844, val.acc = [0.6544, 0.7106, 0.7552, 0.7692]\n","Epoch 294, loss = 0.2120, val.acc = [0.6496, 0.7106, 0.751, 0.767]\n","Epoch 295, loss = 0.2452, val.acc = [0.66, 0.7098, 0.7562, 0.7652]\n","Epoch 296, loss = 0.2298, val.acc = [0.654, 0.7126, 0.7614, 0.7712]\n","Epoch 297, loss = 0.2537, val.acc = [0.6508, 0.715, 0.757, 0.7672]\n","Epoch 298, loss = 0.2097, val.acc = [0.6498, 0.717, 0.7584, 0.7708]\n","Epoch 299, loss = 0.2240, val.acc = [0.6576, 0.7148, 0.7552, 0.7668]\n","Epoch 300, loss = 0.2154, val.acc = [0.6576, 0.7128, 0.7612, 0.7708]\n","Epoch 301, loss = 0.2438, val.acc = [0.6486, 0.7132, 0.7562, 0.7662]\n","Epoch 302, loss = 0.2379, val.acc = [0.6494, 0.7038, 0.7534, 0.766]\n","Epoch 303, loss = 0.2890, val.acc = [0.6534, 0.705, 0.754, 0.7624]\n","Epoch 304, loss = 0.2314, val.acc = [0.6586, 0.7144, 0.7548, 0.7658]\n","Epoch 305, loss = 0.2375, val.acc = [0.6608, 0.7112, 0.7604, 0.77]\n","Epoch 306, loss = 0.2435, val.acc = [0.6508, 0.7168, 0.752, 0.769]\n","Epoch 307, loss = 0.2554, val.acc = [0.6558, 0.7126, 0.758, 0.7664]\n","Epoch 308, loss = 0.2654, val.acc = [0.6418, 0.7042, 0.747, 0.7562]\n","Epoch 309, loss = 0.2144, val.acc = [0.6448, 0.7128, 0.76, 0.7674]\n","Epoch 310, loss = 0.2443, val.acc = [0.657, 0.7104, 0.7548, 0.7642]\n","Epoch 311, loss = 0.2382, val.acc = [0.6558, 0.7124, 0.7582, 0.7664]\n","Epoch 312, loss = 0.2351, val.acc = [0.6572, 0.711, 0.7604, 0.768]\n","Epoch 313, loss = 0.2368, val.acc = [0.6552, 0.712, 0.755, 0.7682]\n","Epoch 314, loss = 0.2533, val.acc = [0.652, 0.7106, 0.7572, 0.7694]\n","Epoch 315, loss = 0.1880, val.acc = [0.6486, 0.7114, 0.7544, 0.7668]\n","Epoch 316, loss = 0.1981, val.acc = [0.6548, 0.7138, 0.761, 0.7706]\n","Epoch 317, loss = 0.2558, val.acc = [0.6476, 0.719, 0.7564, 0.7692]\n","Epoch 318, loss = 0.2417, val.acc = [0.6518, 0.7138, 0.7568, 0.769]\n","Epoch 319, loss = 0.2477, val.acc = [0.6322, 0.6976, 0.7398, 0.754]\n","Epoch 320, loss = 0.2440, val.acc = [0.646, 0.7048, 0.7528, 0.7684]\n","Epoch 321, loss = 0.2162, val.acc = [0.6518, 0.7108, 0.753, 0.7644]\n","Epoch 322, loss = 0.2498, val.acc = [0.6388, 0.7032, 0.7512, 0.7624]\n","Epoch 323, loss = 0.2112, val.acc = [0.6402, 0.7076, 0.759, 0.7682]\n","Epoch 324, loss = 0.2290, val.acc = [0.649, 0.7142, 0.7578, 0.7664]\n","Epoch 325, loss = 0.2192, val.acc = [0.6484, 0.7088, 0.7532, 0.7662]\n","Epoch 326, loss = 0.2442, val.acc = [0.6492, 0.708, 0.755, 0.7668]\n","Epoch 327, loss = 0.2410, val.acc = [0.654, 0.7114, 0.7522, 0.7654]\n","Epoch 328, loss = 0.2393, val.acc = [0.6468, 0.7128, 0.75, 0.765]\n","Epoch 329, loss = 0.2098, val.acc = [0.6542, 0.7114, 0.7558, 0.7654]\n","Epoch 330, loss = 0.1986, val.acc = [0.6444, 0.7104, 0.7508, 0.7656]\n","Epoch 331, loss = 0.2487, val.acc = [0.6592, 0.7112, 0.755, 0.763]\n","Epoch 332, loss = 0.2381, val.acc = [0.641, 0.7072, 0.7574, 0.7672]\n","Epoch 333, loss = 0.1714, val.acc = [0.6532, 0.7126, 0.7568, 0.7664]\n","Epoch 334, loss = 0.2571, val.acc = [0.6504, 0.7154, 0.754, 0.764]\n","Epoch 335, loss = 0.2028, val.acc = [0.644, 0.706, 0.7528, 0.7636]\n","Epoch 336, loss = 0.2018, val.acc = [0.6466, 0.7022, 0.753, 0.7626]\n","Epoch 337, loss = 0.2063, val.acc = [0.655, 0.7086, 0.7556, 0.7646]\n","Epoch 338, loss = 0.1974, val.acc = [0.6536, 0.7058, 0.7552, 0.7644]\n","Epoch 339, loss = 0.2289, val.acc = [0.6546, 0.7068, 0.7536, 0.769]\n","Epoch 340, loss = 0.2095, val.acc = [0.6538, 0.711, 0.7596, 0.766]\n","Epoch 341, loss = 0.2076, val.acc = [0.6512, 0.7132, 0.7566, 0.7656]\n","Epoch 342, loss = 0.2189, val.acc = [0.651, 0.7096, 0.7564, 0.7674]\n","Epoch 343, loss = 0.1871, val.acc = [0.6508, 0.7098, 0.7592, 0.7692]\n","Epoch 344, loss = 0.1991, val.acc = [0.6492, 0.71, 0.7542, 0.7618]\n","Epoch 345, loss = 0.1987, val.acc = [0.6542, 0.7036, 0.7572, 0.7654]\n","Epoch 346, loss = 0.1775, val.acc = [0.6546, 0.711, 0.7572, 0.7678]\n","Epoch 347, loss = 0.1723, val.acc = [0.654, 0.713, 0.7574, 0.7664]\n","Epoch 348, loss = 0.2033, val.acc = [0.6526, 0.7096, 0.7572, 0.7664]\n","Epoch 349, loss = 0.2070, val.acc = [0.6368, 0.7024, 0.7532, 0.763]\n","Epoch 350, loss = 0.2118, val.acc = [0.6438, 0.7124, 0.7556, 0.7652]\n","Epoch 351, loss = 0.2192, val.acc = [0.6526, 0.7054, 0.759, 0.7682]\n","Epoch 352, loss = 0.1896, val.acc = [0.6426, 0.7018, 0.755, 0.7628]\n","Epoch 353, loss = 0.2029, val.acc = [0.6458, 0.7066, 0.76, 0.7704]\n","Epoch 354, loss = 0.2028, val.acc = [0.6504, 0.705, 0.7602, 0.7676]\n","Epoch 355, loss = 0.2121, val.acc = [0.6438, 0.709, 0.7592, 0.7672]\n","Epoch 356, loss = 0.1790, val.acc = [0.6528, 0.7078, 0.7554, 0.7676]\n","Epoch 357, loss = 0.2164, val.acc = [0.6472, 0.7086, 0.7558, 0.7648]\n","Epoch 358, loss = 0.2386, val.acc = [0.652, 0.7062, 0.7542, 0.7602]\n","Epoch 359, loss = 0.2188, val.acc = [0.6466, 0.709, 0.7548, 0.7618]\n","Epoch 360, loss = 0.2564, val.acc = [0.645, 0.7036, 0.7574, 0.7658]\n","Epoch 361, loss = 0.1849, val.acc = [0.6372, 0.7066, 0.7556, 0.7664]\n","Epoch 362, loss = 0.1982, val.acc = [0.6452, 0.7116, 0.7582, 0.77]\n","Epoch 363, loss = 0.2067, val.acc = [0.6488, 0.7076, 0.7584, 0.7676]\n","Epoch 364, loss = 0.2017, val.acc = [0.6538, 0.7128, 0.7584, 0.7656]\n","Epoch 365, loss = 0.1531, val.acc = [0.6488, 0.7134, 0.758, 0.7676]\n","Epoch 366, loss = 0.1847, val.acc = [0.6536, 0.7104, 0.7526, 0.7676]\n","Epoch 367, loss = 0.2086, val.acc = [0.6496, 0.7018, 0.7536, 0.7664]\n","Epoch 368, loss = 0.2158, val.acc = [0.6466, 0.7108, 0.7556, 0.7656]\n","Epoch 369, loss = 0.1940, val.acc = [0.6384, 0.703, 0.752, 0.7612]\n","Epoch 370, loss = 0.1833, val.acc = [0.6508, 0.708, 0.755, 0.7644]\n","Epoch 371, loss = 0.1704, val.acc = [0.6536, 0.711, 0.755, 0.763]\n","Epoch 372, loss = 0.1776, val.acc = [0.655, 0.7128, 0.7562, 0.7654]\n","Epoch 373, loss = 0.1972, val.acc = [0.6454, 0.7076, 0.7592, 0.7648]\n","Epoch 374, loss = 0.2095, val.acc = [0.6458, 0.7116, 0.7522, 0.7636]\n","Epoch 375, loss = 0.2050, val.acc = [0.645, 0.7008, 0.755, 0.7634]\n","Epoch 376, loss = 0.2132, val.acc = [0.6476, 0.7038, 0.7534, 0.7608]\n","Epoch 377, loss = 0.1779, val.acc = [0.6538, 0.7092, 0.7582, 0.7668]\n","Epoch 378, loss = 0.1576, val.acc = [0.6538, 0.706, 0.7548, 0.7652]\n","Epoch 379, loss = 0.1941, val.acc = [0.6414, 0.7018, 0.754, 0.7624]\n","Epoch 380, loss = 0.1943, val.acc = [0.642, 0.6986, 0.7538, 0.7646]\n","Epoch 381, loss = 0.1407, val.acc = [0.65, 0.7102, 0.7594, 0.766]\n","Epoch 382, loss = 0.1717, val.acc = [0.6542, 0.7058, 0.757, 0.7624]\n","Epoch 383, loss = 0.1595, val.acc = [0.6384, 0.6998, 0.758, 0.7654]\n","Epoch 384, loss = 0.2124, val.acc = [0.6476, 0.7072, 0.7552, 0.7674]\n","Epoch 385, loss = 0.1680, val.acc = [0.638, 0.7084, 0.76, 0.7624]\n","Epoch 386, loss = 0.1959, val.acc = [0.6524, 0.7028, 0.7588, 0.7636]\n","Epoch 387, loss = 0.1818, val.acc = [0.6516, 0.707, 0.7552, 0.7654]\n","Epoch 388, loss = 0.1847, val.acc = [0.6468, 0.7026, 0.7568, 0.7618]\n","Epoch 389, loss = 0.1815, val.acc = [0.6556, 0.7056, 0.7612, 0.7668]\n","Epoch 390, loss = 0.1768, val.acc = [0.622, 0.7056, 0.7544, 0.764]\n","Epoch 391, loss = 0.1895, val.acc = [0.6452, 0.7058, 0.7558, 0.7634]\n","Epoch 392, loss = 0.1624, val.acc = [0.6456, 0.7122, 0.7516, 0.7624]\n","Epoch 393, loss = 0.1892, val.acc = [0.6496, 0.7086, 0.7602, 0.762]\n","Epoch 394, loss = 0.1851, val.acc = [0.6538, 0.7062, 0.7566, 0.7636]\n","Epoch 395, loss = 0.1657, val.acc = [0.6398, 0.704, 0.7542, 0.764]\n","Epoch 396, loss = 0.1867, val.acc = [0.6362, 0.705, 0.7534, 0.7616]\n","Epoch 397, loss = 0.1761, val.acc = [0.6526, 0.7074, 0.7568, 0.7664]\n","Epoch 398, loss = 0.1714, val.acc = [0.6496, 0.7022, 0.7574, 0.7656]\n","Epoch 399, loss = 0.1626, val.acc = [0.653, 0.7072, 0.7546, 0.7624]\n","Rep: 3, te.acc = [0.6355, 0.6965, 0.7354, 0.746]\n","\n","Rep 4\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 2.1331, val.acc = [0.3508, 0.33, 0.269, 0.2228]\n","Epoch 1, loss = 1.9109, val.acc = [0.384, 0.3826, 0.322, 0.2674]\n","Epoch 2, loss = 1.8200, val.acc = [0.4182, 0.4068, 0.3608, 0.2988]\n","Epoch 3, loss = 1.7582, val.acc = [0.4212, 0.4198, 0.3868, 0.3362]\n","Epoch 4, loss = 1.7024, val.acc = [0.4304, 0.4396, 0.4092, 0.3622]\n","Epoch 5, loss = 1.6662, val.acc = [0.4394, 0.4512, 0.428, 0.377]\n","Epoch 6, loss = 1.6460, val.acc = [0.4546, 0.4608, 0.4346, 0.3938]\n","Epoch 7, loss = 1.5864, val.acc = [0.4414, 0.4652, 0.4398, 0.398]\n","Epoch 8, loss = 1.5472, val.acc = [0.4582, 0.4806, 0.4576, 0.4116]\n","Epoch 9, loss = 1.5353, val.acc = [0.4704, 0.482, 0.4742, 0.4372]\n","Epoch 10, loss = 1.5022, val.acc = [0.4854, 0.4966, 0.4836, 0.4424]\n","Epoch 11, loss = 1.4781, val.acc = [0.4866, 0.502, 0.495, 0.4462]\n","Epoch 12, loss = 1.4417, val.acc = [0.4914, 0.5156, 0.5058, 0.4734]\n","Epoch 13, loss = 1.4104, val.acc = [0.494, 0.5316, 0.5176, 0.4802]\n","Epoch 14, loss = 1.3859, val.acc = [0.493, 0.5344, 0.5046, 0.4826]\n","Epoch 15, loss = 1.3687, val.acc = [0.5054, 0.5418, 0.535, 0.4936]\n","Epoch 16, loss = 1.3705, val.acc = [0.4908, 0.5444, 0.5328, 0.51]\n","Epoch 17, loss = 1.3474, val.acc = [0.5106, 0.5534, 0.5516, 0.5162]\n","Epoch 18, loss = 1.3130, val.acc = [0.5068, 0.553, 0.556, 0.5286]\n","Epoch 19, loss = 1.3237, val.acc = [0.5232, 0.5632, 0.5546, 0.5302]\n","Epoch 20, loss = 1.2841, val.acc = [0.5048, 0.5586, 0.5592, 0.5354]\n","Epoch 21, loss = 1.2808, val.acc = [0.4756, 0.4818, 0.466, 0.4468]\n","Epoch 22, loss = 1.2830, val.acc = [0.5344, 0.5846, 0.585, 0.557]\n","Epoch 23, loss = 1.2284, val.acc = [0.5344, 0.5824, 0.589, 0.5576]\n","Epoch 24, loss = 1.2282, val.acc = [0.5366, 0.5922, 0.5884, 0.5716]\n","Epoch 25, loss = 1.2093, val.acc = [0.5274, 0.5934, 0.5948, 0.568]\n","Epoch 26, loss = 1.2173, val.acc = [0.54, 0.5956, 0.601, 0.5848]\n","Epoch 27, loss = 1.2059, val.acc = [0.5436, 0.6054, 0.5848, 0.5874]\n","Epoch 28, loss = 1.1709, val.acc = [0.5318, 0.6066, 0.6084, 0.5898]\n","Epoch 29, loss = 1.1590, val.acc = [0.556, 0.6096, 0.6152, 0.6]\n","Epoch 30, loss = 1.1289, val.acc = [0.5668, 0.6052, 0.621, 0.6078]\n","Epoch 31, loss = 1.1526, val.acc = [0.5518, 0.6108, 0.6226, 0.6058]\n","Epoch 32, loss = 1.1344, val.acc = [0.542, 0.5898, 0.5872, 0.5544]\n","Epoch 33, loss = 1.1292, val.acc = [0.5558, 0.6234, 0.6382, 0.6228]\n","Epoch 34, loss = 1.0976, val.acc = [0.557, 0.5884, 0.6268, 0.6192]\n","Epoch 35, loss = 1.0946, val.acc = [0.5504, 0.6166, 0.629, 0.6222]\n","Epoch 36, loss = 1.0648, val.acc = [0.5722, 0.6278, 0.6456, 0.6324]\n","Epoch 37, loss = 1.0890, val.acc = [0.5596, 0.5694, 0.5836, 0.589]\n","Epoch 38, loss = 1.0663, val.acc = [0.551, 0.5834, 0.5856, 0.5882]\n","Epoch 39, loss = 1.0596, val.acc = [0.5618, 0.6112, 0.648, 0.6394]\n","Epoch 40, loss = 1.0154, val.acc = [0.5752, 0.6198, 0.6524, 0.6468]\n","Epoch 41, loss = 1.0388, val.acc = [0.5846, 0.6464, 0.6612, 0.6606]\n","Epoch 42, loss = 1.0172, val.acc = [0.5492, 0.6106, 0.5658, 0.5916]\n","Epoch 43, loss = 1.0183, val.acc = [0.5554, 0.6272, 0.6224, 0.623]\n","Epoch 44, loss = 1.0087, val.acc = [0.578, 0.6508, 0.6684, 0.6642]\n","Epoch 45, loss = 0.9982, val.acc = [0.5686, 0.6516, 0.6608, 0.6544]\n","Epoch 46, loss = 0.9951, val.acc = [0.588, 0.601, 0.6652, 0.6622]\n","Epoch 47, loss = 0.9976, val.acc = [0.5916, 0.6414, 0.6588, 0.6586]\n","Epoch 48, loss = 0.9582, val.acc = [0.5864, 0.6526, 0.6778, 0.6784]\n","Epoch 49, loss = 0.9556, val.acc = [0.594, 0.6574, 0.6732, 0.6708]\n","Epoch 50, loss = 0.9682, val.acc = [0.5968, 0.6548, 0.6808, 0.6798]\n","Epoch 51, loss = 0.9372, val.acc = [0.592, 0.6454, 0.6594, 0.6746]\n","Epoch 52, loss = 0.9501, val.acc = [0.5804, 0.6562, 0.684, 0.6834]\n","Epoch 53, loss = 0.9292, val.acc = [0.6054, 0.661, 0.6902, 0.6924]\n","Epoch 54, loss = 0.9587, val.acc = [0.5978, 0.6574, 0.6918, 0.6906]\n","Epoch 55, loss = 0.9133, val.acc = [0.6044, 0.6656, 0.6886, 0.6858]\n","Epoch 56, loss = 0.9273, val.acc = [0.6052, 0.6652, 0.6926, 0.6978]\n","Epoch 57, loss = 0.8932, val.acc = [0.5866, 0.6672, 0.6834, 0.6956]\n","Epoch 58, loss = 0.9306, val.acc = [0.6136, 0.6724, 0.7012, 0.7038]\n","Epoch 59, loss = 0.8914, val.acc = [0.6182, 0.6674, 0.694, 0.6996]\n","Epoch 60, loss = 0.8960, val.acc = [0.5942, 0.666, 0.693, 0.6992]\n","Epoch 61, loss = 0.8825, val.acc = [0.6012, 0.6684, 0.6966, 0.7006]\n","Epoch 62, loss = 0.8898, val.acc = [0.6078, 0.6484, 0.6686, 0.6802]\n","Epoch 63, loss = 0.8762, val.acc = [0.6224, 0.6742, 0.704, 0.7104]\n","Epoch 64, loss = 0.8812, val.acc = [0.6154, 0.6566, 0.692, 0.6996]\n","Epoch 65, loss = 0.8537, val.acc = [0.6116, 0.6568, 0.693, 0.69]\n","Epoch 66, loss = 0.8574, val.acc = [0.6098, 0.6796, 0.7076, 0.7142]\n","Epoch 67, loss = 0.8528, val.acc = [0.6198, 0.6798, 0.7138, 0.7158]\n","Epoch 68, loss = 0.8151, val.acc = [0.5966, 0.6816, 0.7122, 0.7162]\n","Epoch 69, loss = 0.8662, val.acc = [0.6112, 0.6832, 0.7156, 0.7162]\n","Epoch 70, loss = 0.8333, val.acc = [0.609, 0.6856, 0.7132, 0.721]\n","Epoch 71, loss = 0.8641, val.acc = [0.6028, 0.674, 0.7072, 0.7134]\n","Epoch 72, loss = 0.8281, val.acc = [0.6222, 0.6834, 0.7128, 0.7244]\n","Epoch 73, loss = 0.8360, val.acc = [0.6034, 0.6822, 0.6932, 0.723]\n","Epoch 74, loss = 0.8125, val.acc = [0.6234, 0.691, 0.7176, 0.7248]\n","Epoch 75, loss = 0.8010, val.acc = [0.6146, 0.6868, 0.7068, 0.7224]\n","Epoch 76, loss = 0.8097, val.acc = [0.5912, 0.6868, 0.7112, 0.7238]\n","Epoch 77, loss = 0.7903, val.acc = [0.6184, 0.6882, 0.719, 0.7268]\n","Epoch 78, loss = 0.7980, val.acc = [0.6236, 0.677, 0.717, 0.7236]\n","Epoch 79, loss = 0.7827, val.acc = [0.6024, 0.681, 0.7074, 0.722]\n","Epoch 80, loss = 0.7942, val.acc = [0.6254, 0.6936, 0.7248, 0.736]\n","Epoch 81, loss = 0.8042, val.acc = [0.625, 0.6746, 0.7136, 0.7246]\n","Epoch 82, loss = 0.7832, val.acc = [0.6194, 0.6918, 0.721, 0.7224]\n","Epoch 83, loss = 0.7855, val.acc = [0.6338, 0.6916, 0.7196, 0.733]\n","Epoch 84, loss = 0.7736, val.acc = [0.6224, 0.6944, 0.7256, 0.7368]\n","Epoch 85, loss = 0.7924, val.acc = [0.5946, 0.6434, 0.7066, 0.7024]\n","Epoch 86, loss = 0.7768, val.acc = [0.6336, 0.6876, 0.7254, 0.7348]\n","Epoch 87, loss = 0.7429, val.acc = [0.6268, 0.6928, 0.7294, 0.7404]\n","Epoch 88, loss = 0.7582, val.acc = [0.6276, 0.6906, 0.717, 0.7288]\n","Epoch 89, loss = 0.7670, val.acc = [0.6328, 0.693, 0.7272, 0.7392]\n","Epoch 90, loss = 0.7437, val.acc = [0.6316, 0.6934, 0.7252, 0.7412]\n","Epoch 91, loss = 0.7372, val.acc = [0.6416, 0.701, 0.7362, 0.741]\n","Epoch 92, loss = 0.7214, val.acc = [0.6376, 0.6984, 0.729, 0.735]\n","Epoch 93, loss = 0.7203, val.acc = [0.632, 0.7, 0.732, 0.74]\n","Epoch 94, loss = 0.7515, val.acc = [0.5974, 0.6214, 0.7008, 0.7056]\n","Epoch 95, loss = 0.7515, val.acc = [0.6384, 0.6998, 0.7324, 0.745]\n","Epoch 96, loss = 0.7008, val.acc = [0.6368, 0.6974, 0.731, 0.7444]\n","Epoch 97, loss = 0.7255, val.acc = [0.632, 0.707, 0.7322, 0.746]\n","Epoch 98, loss = 0.6930, val.acc = [0.627, 0.6966, 0.7188, 0.7332]\n","Epoch 99, loss = 0.6879, val.acc = [0.6398, 0.6996, 0.7324, 0.7428]\n","Epoch 100, loss = 0.6814, val.acc = [0.6388, 0.6992, 0.726, 0.7392]\n","Epoch 101, loss = 0.7054, val.acc = [0.6346, 0.6848, 0.7252, 0.7432]\n","Epoch 102, loss = 0.7114, val.acc = [0.6362, 0.6882, 0.731, 0.743]\n","Epoch 103, loss = 0.6645, val.acc = [0.6464, 0.7022, 0.7402, 0.7464]\n","Epoch 104, loss = 0.7047, val.acc = [0.6448, 0.7022, 0.7394, 0.75]\n","Epoch 105, loss = 0.7256, val.acc = [0.6078, 0.7036, 0.7374, 0.743]\n","Epoch 106, loss = 0.6620, val.acc = [0.6216, 0.689, 0.7264, 0.7408]\n","Epoch 107, loss = 0.6747, val.acc = [0.6124, 0.683, 0.719, 0.723]\n","Epoch 108, loss = 0.6675, val.acc = [0.6328, 0.7058, 0.738, 0.737]\n","Epoch 109, loss = 0.6545, val.acc = [0.6458, 0.6976, 0.7418, 0.7508]\n","Epoch 110, loss = 0.6332, val.acc = [0.636, 0.6962, 0.7404, 0.7468]\n","Epoch 111, loss = 0.6475, val.acc = [0.6504, 0.708, 0.7472, 0.7568]\n","Epoch 112, loss = 0.6611, val.acc = [0.6502, 0.7088, 0.737, 0.7558]\n","Epoch 113, loss = 0.6618, val.acc = [0.6556, 0.7102, 0.7408, 0.7542]\n","Epoch 114, loss = 0.6299, val.acc = [0.648, 0.7038, 0.7402, 0.7558]\n","Epoch 115, loss = 0.6285, val.acc = [0.6212, 0.6794, 0.7322, 0.7498]\n","Epoch 116, loss = 0.6315, val.acc = [0.6508, 0.7038, 0.7468, 0.7598]\n","Epoch 117, loss = 0.6583, val.acc = [0.6482, 0.7018, 0.744, 0.7532]\n","Epoch 118, loss = 0.6483, val.acc = [0.6162, 0.7006, 0.7346, 0.7414]\n","Epoch 119, loss = 0.6494, val.acc = [0.649, 0.7128, 0.745, 0.757]\n","Epoch 120, loss = 0.6149, val.acc = [0.6392, 0.7056, 0.7416, 0.7524]\n","Epoch 121, loss = 0.6078, val.acc = [0.6422, 0.7102, 0.7544, 0.7596]\n","Epoch 122, loss = 0.5829, val.acc = [0.644, 0.7036, 0.7384, 0.7484]\n","Epoch 123, loss = 0.6336, val.acc = [0.6524, 0.7022, 0.7466, 0.7584]\n","Epoch 124, loss = 0.6189, val.acc = [0.646, 0.7088, 0.7436, 0.758]\n","Epoch 125, loss = 0.6178, val.acc = [0.629, 0.7028, 0.74, 0.755]\n","Epoch 126, loss = 0.5656, val.acc = [0.6542, 0.7124, 0.7464, 0.7544]\n","Epoch 127, loss = 0.5923, val.acc = [0.6524, 0.713, 0.7456, 0.7558]\n","Epoch 128, loss = 0.5850, val.acc = [0.6378, 0.7058, 0.7418, 0.7612]\n","Epoch 129, loss = 0.5972, val.acc = [0.6322, 0.7036, 0.7444, 0.7568]\n","Epoch 130, loss = 0.5924, val.acc = [0.6506, 0.709, 0.7504, 0.764]\n","Epoch 131, loss = 0.5775, val.acc = [0.6574, 0.7074, 0.7442, 0.7568]\n","Epoch 132, loss = 0.5841, val.acc = [0.655, 0.7136, 0.7478, 0.7666]\n","Epoch 133, loss = 0.5976, val.acc = [0.6508, 0.7124, 0.752, 0.766]\n","Epoch 134, loss = 0.5520, val.acc = [0.657, 0.7122, 0.7504, 0.7694]\n","Epoch 135, loss = 0.5439, val.acc = [0.6482, 0.7138, 0.7568, 0.7652]\n","Epoch 136, loss = 0.5828, val.acc = [0.6108, 0.712, 0.7392, 0.7526]\n","Epoch 137, loss = 0.5474, val.acc = [0.6322, 0.693, 0.7426, 0.7552]\n","Epoch 138, loss = 0.5555, val.acc = [0.6278, 0.6584, 0.7356, 0.7536]\n","Epoch 139, loss = 0.5090, val.acc = [0.6318, 0.71, 0.7454, 0.7524]\n","Epoch 140, loss = 0.5724, val.acc = [0.6302, 0.7122, 0.7392, 0.754]\n","Epoch 141, loss = 0.5460, val.acc = [0.653, 0.7168, 0.7494, 0.7594]\n","Epoch 142, loss = 0.5291, val.acc = [0.6138, 0.7072, 0.7482, 0.7562]\n","Epoch 143, loss = 0.5580, val.acc = [0.6544, 0.716, 0.7508, 0.7632]\n","Epoch 144, loss = 0.5774, val.acc = [0.6566, 0.7096, 0.7552, 0.7636]\n","Epoch 145, loss = 0.5364, val.acc = [0.6458, 0.7076, 0.7412, 0.758]\n","Epoch 146, loss = 0.5075, val.acc = [0.663, 0.719, 0.7526, 0.7662]\n","Epoch 147, loss = 0.4862, val.acc = [0.6358, 0.7048, 0.746, 0.761]\n","Epoch 148, loss = 0.5547, val.acc = [0.6192, 0.712, 0.7518, 0.767]\n","Epoch 149, loss = 0.5453, val.acc = [0.6554, 0.7136, 0.7582, 0.77]\n","Epoch 150, loss = 0.5046, val.acc = [0.6554, 0.7146, 0.7518, 0.7702]\n","Epoch 151, loss = 0.4914, val.acc = [0.6574, 0.7144, 0.7512, 0.7656]\n","Epoch 152, loss = 0.5455, val.acc = [0.642, 0.7164, 0.7466, 0.7636]\n","Epoch 153, loss = 0.5138, val.acc = [0.6582, 0.7172, 0.756, 0.7706]\n","Epoch 154, loss = 0.5012, val.acc = [0.6546, 0.7136, 0.7392, 0.7606]\n","Epoch 155, loss = 0.4986, val.acc = [0.6402, 0.7088, 0.7344, 0.7604]\n","Epoch 156, loss = 0.5040, val.acc = [0.6328, 0.7192, 0.751, 0.7666]\n","Epoch 157, loss = 0.5124, val.acc = [0.6544, 0.7178, 0.7482, 0.7668]\n","Epoch 158, loss = 0.4938, val.acc = [0.6494, 0.7218, 0.751, 0.7694]\n","Epoch 159, loss = 0.5434, val.acc = [0.6454, 0.7198, 0.751, 0.7674]\n","Epoch 160, loss = 0.4770, val.acc = [0.6394, 0.7216, 0.7542, 0.7696]\n","Epoch 161, loss = 0.4762, val.acc = [0.6272, 0.7062, 0.7406, 0.7602]\n","Epoch 162, loss = 0.4615, val.acc = [0.6562, 0.7196, 0.7514, 0.7724]\n","Epoch 163, loss = 0.4988, val.acc = [0.6566, 0.718, 0.7562, 0.7716]\n","Epoch 164, loss = 0.4863, val.acc = [0.6588, 0.715, 0.7484, 0.767]\n","Epoch 165, loss = 0.4685, val.acc = [0.6532, 0.7146, 0.7534, 0.7696]\n","Epoch 166, loss = 0.4389, val.acc = [0.6502, 0.7226, 0.7538, 0.7716]\n","Epoch 167, loss = 0.4613, val.acc = [0.6528, 0.7166, 0.7454, 0.7644]\n","Epoch 168, loss = 0.4338, val.acc = [0.6516, 0.7118, 0.756, 0.772]\n","Epoch 169, loss = 0.4460, val.acc = [0.6602, 0.7212, 0.7516, 0.7702]\n","Epoch 170, loss = 0.4891, val.acc = [0.6424, 0.6918, 0.7388, 0.7548]\n","Epoch 171, loss = 0.4508, val.acc = [0.6414, 0.7154, 0.7518, 0.766]\n","Epoch 172, loss = 0.4206, val.acc = [0.6548, 0.7178, 0.752, 0.7692]\n","Epoch 173, loss = 0.4747, val.acc = [0.655, 0.717, 0.7552, 0.771]\n","Epoch 174, loss = 0.4667, val.acc = [0.654, 0.722, 0.754, 0.7698]\n","Epoch 175, loss = 0.4632, val.acc = [0.651, 0.706, 0.7458, 0.7556]\n","Epoch 176, loss = 0.4796, val.acc = [0.6578, 0.7172, 0.7534, 0.7708]\n","Epoch 177, loss = 0.4417, val.acc = [0.645, 0.7164, 0.7488, 0.765]\n","Epoch 178, loss = 0.4522, val.acc = [0.6554, 0.718, 0.7326, 0.7638]\n","Epoch 179, loss = 0.4609, val.acc = [0.654, 0.7148, 0.749, 0.7654]\n","Epoch 180, loss = 0.4197, val.acc = [0.6568, 0.7228, 0.7494, 0.768]\n","Epoch 181, loss = 0.4579, val.acc = [0.6588, 0.7048, 0.738, 0.768]\n","Epoch 182, loss = 0.3969, val.acc = [0.6586, 0.7126, 0.7516, 0.7672]\n","Epoch 183, loss = 0.4275, val.acc = [0.6442, 0.7014, 0.748, 0.7576]\n","Epoch 184, loss = 0.3995, val.acc = [0.6356, 0.7166, 0.7512, 0.7732]\n","Epoch 185, loss = 0.4268, val.acc = [0.658, 0.72, 0.7548, 0.7688]\n","Epoch 186, loss = 0.3954, val.acc = [0.654, 0.7182, 0.7538, 0.7706]\n","Epoch 187, loss = 0.4001, val.acc = [0.6382, 0.708, 0.752, 0.7706]\n","Epoch 188, loss = 0.4292, val.acc = [0.6528, 0.7162, 0.7514, 0.768]\n","Epoch 189, loss = 0.3950, val.acc = [0.6494, 0.7194, 0.7502, 0.772]\n","Epoch 190, loss = 0.3765, val.acc = [0.6622, 0.7234, 0.7554, 0.775]\n","Epoch 191, loss = 0.4029, val.acc = [0.6536, 0.7108, 0.7498, 0.7692]\n","Epoch 192, loss = 0.4249, val.acc = [0.6528, 0.715, 0.7504, 0.77]\n","Epoch 193, loss = 0.4329, val.acc = [0.6592, 0.712, 0.7538, 0.7682]\n","Epoch 194, loss = 0.3785, val.acc = [0.6586, 0.7216, 0.7564, 0.7722]\n","Epoch 195, loss = 0.4042, val.acc = [0.6402, 0.7158, 0.7536, 0.768]\n","Epoch 196, loss = 0.4016, val.acc = [0.6514, 0.704, 0.7466, 0.7628]\n","Epoch 197, loss = 0.3811, val.acc = [0.6548, 0.722, 0.755, 0.761]\n","Epoch 198, loss = 0.4053, val.acc = [0.6624, 0.7232, 0.7548, 0.7746]\n","Epoch 199, loss = 0.3924, val.acc = [0.6584, 0.716, 0.7566, 0.7726]\n","Epoch 200, loss = 0.4068, val.acc = [0.6384, 0.704, 0.751, 0.7578]\n","Epoch 201, loss = 0.3591, val.acc = [0.6618, 0.7156, 0.7592, 0.772]\n","Epoch 202, loss = 0.3795, val.acc = [0.647, 0.7208, 0.7578, 0.7724]\n","Epoch 203, loss = 0.4027, val.acc = [0.6444, 0.7202, 0.749, 0.7712]\n","Epoch 204, loss = 0.4113, val.acc = [0.6468, 0.7162, 0.753, 0.7722]\n","Epoch 205, loss = 0.3076, val.acc = [0.634, 0.6912, 0.7448, 0.7596]\n","Epoch 206, loss = 0.3554, val.acc = [0.6494, 0.7158, 0.7548, 0.7704]\n","Epoch 207, loss = 0.3650, val.acc = [0.6462, 0.7232, 0.7544, 0.7668]\n","Epoch 208, loss = 0.3562, val.acc = [0.6628, 0.7248, 0.7586, 0.773]\n","Epoch 209, loss = 0.4173, val.acc = [0.6414, 0.7124, 0.755, 0.7738]\n","Epoch 210, loss = 0.3555, val.acc = [0.655, 0.72, 0.7556, 0.7712]\n","Epoch 211, loss = 0.3819, val.acc = [0.6584, 0.7206, 0.7588, 0.7712]\n","Epoch 212, loss = 0.3211, val.acc = [0.6372, 0.7242, 0.7562, 0.7718]\n","Epoch 213, loss = 0.3821, val.acc = [0.6496, 0.7156, 0.7558, 0.7698]\n","Epoch 214, loss = 0.3236, val.acc = [0.6548, 0.7174, 0.7592, 0.775]\n","Epoch 215, loss = 0.3090, val.acc = [0.6578, 0.719, 0.7512, 0.771]\n","Epoch 216, loss = 0.3296, val.acc = [0.6382, 0.7116, 0.742, 0.7604]\n","Epoch 217, loss = 0.3807, val.acc = [0.651, 0.711, 0.7524, 0.7712]\n","Epoch 218, loss = 0.3980, val.acc = [0.6528, 0.7222, 0.7548, 0.7712]\n","Epoch 219, loss = 0.3193, val.acc = [0.6486, 0.7198, 0.7526, 0.7734]\n","Epoch 220, loss = 0.2954, val.acc = [0.66, 0.7192, 0.7542, 0.7706]\n","Epoch 221, loss = 0.3466, val.acc = [0.6586, 0.7128, 0.755, 0.766]\n","Epoch 222, loss = 0.3375, val.acc = [0.654, 0.708, 0.7528, 0.7724]\n","Epoch 223, loss = 0.3445, val.acc = [0.6618, 0.7256, 0.7554, 0.769]\n","Epoch 224, loss = 0.3548, val.acc = [0.6554, 0.7158, 0.754, 0.7736]\n","Epoch 225, loss = 0.3306, val.acc = [0.6486, 0.7184, 0.7574, 0.7702]\n","Epoch 226, loss = 0.3182, val.acc = [0.6566, 0.723, 0.7554, 0.7714]\n","Epoch 227, loss = 0.3585, val.acc = [0.6586, 0.7114, 0.751, 0.768]\n","Epoch 228, loss = 0.3634, val.acc = [0.648, 0.7102, 0.7546, 0.773]\n","Epoch 229, loss = 0.3454, val.acc = [0.6544, 0.7192, 0.7522, 0.7676]\n","Epoch 230, loss = 0.2897, val.acc = [0.6582, 0.7124, 0.7558, 0.7684]\n","Epoch 231, loss = 0.3147, val.acc = [0.6562, 0.714, 0.7556, 0.7692]\n","Epoch 232, loss = 0.3155, val.acc = [0.6594, 0.725, 0.755, 0.7694]\n","Epoch 233, loss = 0.3325, val.acc = [0.6618, 0.723, 0.7554, 0.7684]\n","Epoch 234, loss = 0.3187, val.acc = [0.6616, 0.7214, 0.7542, 0.7704]\n","Epoch 235, loss = 0.3225, val.acc = [0.662, 0.7228, 0.7528, 0.7698]\n","Epoch 236, loss = 0.3041, val.acc = [0.6632, 0.7248, 0.756, 0.7666]\n","Epoch 237, loss = 0.3407, val.acc = [0.6628, 0.7196, 0.7554, 0.7724]\n","Epoch 238, loss = 0.3676, val.acc = [0.6322, 0.7098, 0.7368, 0.7504]\n","Epoch 239, loss = 0.2802, val.acc = [0.6576, 0.7192, 0.7554, 0.7704]\n","Epoch 240, loss = 0.3316, val.acc = [0.656, 0.718, 0.7584, 0.7698]\n","Epoch 241, loss = 0.2981, val.acc = [0.6294, 0.7122, 0.7504, 0.7602]\n","Epoch 242, loss = 0.3172, val.acc = [0.6594, 0.7138, 0.7538, 0.7672]\n","Epoch 243, loss = 0.3291, val.acc = [0.651, 0.7186, 0.7536, 0.7658]\n","Epoch 244, loss = 0.2754, val.acc = [0.6518, 0.7174, 0.7516, 0.7698]\n","Epoch 245, loss = 0.2833, val.acc = [0.6568, 0.7176, 0.7552, 0.7712]\n","Epoch 246, loss = 0.3228, val.acc = [0.6568, 0.7198, 0.7534, 0.7684]\n","Epoch 247, loss = 0.2821, val.acc = [0.651, 0.7172, 0.7522, 0.765]\n","Epoch 248, loss = 0.2937, val.acc = [0.6506, 0.7196, 0.7534, 0.771]\n","Epoch 249, loss = 0.3335, val.acc = [0.6584, 0.7178, 0.7536, 0.7698]\n","Epoch 250, loss = 0.2968, val.acc = [0.6588, 0.7234, 0.755, 0.7716]\n","Epoch 251, loss = 0.2826, val.acc = [0.659, 0.7164, 0.7562, 0.7716]\n","Epoch 252, loss = 0.2692, val.acc = [0.6508, 0.7204, 0.7564, 0.77]\n","Epoch 253, loss = 0.2809, val.acc = [0.6594, 0.7202, 0.7542, 0.771]\n","Epoch 254, loss = 0.2769, val.acc = [0.6624, 0.723, 0.7498, 0.7696]\n","Epoch 255, loss = 0.3370, val.acc = [0.6454, 0.7126, 0.7532, 0.7686]\n","Epoch 256, loss = 0.3345, val.acc = [0.6618, 0.72, 0.754, 0.7694]\n","Epoch 257, loss = 0.2404, val.acc = [0.6562, 0.7202, 0.7494, 0.7702]\n","Epoch 258, loss = 0.2926, val.acc = [0.657, 0.7118, 0.753, 0.7676]\n","Epoch 259, loss = 0.2800, val.acc = [0.6596, 0.718, 0.7552, 0.7706]\n","Epoch 260, loss = 0.3002, val.acc = [0.6446, 0.7162, 0.7538, 0.7662]\n","Epoch 261, loss = 0.2935, val.acc = [0.6418, 0.7162, 0.7532, 0.7672]\n","Epoch 262, loss = 0.2498, val.acc = [0.6596, 0.7118, 0.7494, 0.7652]\n","Epoch 263, loss = 0.2944, val.acc = [0.656, 0.7148, 0.7466, 0.7612]\n","Epoch 264, loss = 0.2399, val.acc = [0.6536, 0.7164, 0.753, 0.768]\n","Epoch 265, loss = 0.2515, val.acc = [0.6558, 0.7138, 0.7548, 0.766]\n","Epoch 266, loss = 0.2696, val.acc = [0.6524, 0.7192, 0.7508, 0.7692]\n","Epoch 267, loss = 0.2971, val.acc = [0.6534, 0.7084, 0.752, 0.7674]\n","Epoch 268, loss = 0.2564, val.acc = [0.66, 0.7108, 0.753, 0.766]\n","Epoch 269, loss = 0.2612, val.acc = [0.6624, 0.7198, 0.754, 0.7688]\n","Epoch 270, loss = 0.2550, val.acc = [0.651, 0.7142, 0.755, 0.766]\n","Epoch 271, loss = 0.2707, val.acc = [0.6494, 0.7196, 0.7594, 0.7702]\n","Epoch 272, loss = 0.2619, val.acc = [0.6536, 0.7052, 0.7516, 0.765]\n","Epoch 273, loss = 0.3016, val.acc = [0.6426, 0.7132, 0.7538, 0.7684]\n","Epoch 274, loss = 0.2791, val.acc = [0.6508, 0.7114, 0.754, 0.7674]\n","Epoch 275, loss = 0.2796, val.acc = [0.661, 0.7132, 0.7594, 0.7698]\n","Epoch 276, loss = 0.2324, val.acc = [0.65, 0.7142, 0.7554, 0.7674]\n","Epoch 277, loss = 0.3268, val.acc = [0.6576, 0.7144, 0.7498, 0.7628]\n","Epoch 278, loss = 0.2554, val.acc = [0.651, 0.7158, 0.7586, 0.7688]\n","Epoch 279, loss = 0.2711, val.acc = [0.6578, 0.719, 0.757, 0.7676]\n","Epoch 280, loss = 0.2648, val.acc = [0.6506, 0.7156, 0.7548, 0.7704]\n","Epoch 281, loss = 0.2661, val.acc = [0.6586, 0.714, 0.7512, 0.7696]\n","Epoch 282, loss = 0.2300, val.acc = [0.6506, 0.7132, 0.7502, 0.7658]\n","Epoch 283, loss = 0.2760, val.acc = [0.6544, 0.7126, 0.7506, 0.765]\n","Epoch 284, loss = 0.2785, val.acc = [0.66, 0.72, 0.755, 0.7706]\n","Epoch 285, loss = 0.2842, val.acc = [0.6396, 0.7104, 0.749, 0.762]\n","Epoch 286, loss = 0.2587, val.acc = [0.6514, 0.7152, 0.7552, 0.7704]\n","Epoch 287, loss = 0.2478, val.acc = [0.6566, 0.7182, 0.754, 0.7686]\n","Epoch 288, loss = 0.2570, val.acc = [0.6546, 0.7212, 0.755, 0.7688]\n","Epoch 289, loss = 0.2419, val.acc = [0.6534, 0.7138, 0.7532, 0.7684]\n","Epoch 290, loss = 0.2460, val.acc = [0.6524, 0.711, 0.7542, 0.7668]\n","Epoch 291, loss = 0.2293, val.acc = [0.6546, 0.7166, 0.7482, 0.7682]\n","Epoch 292, loss = 0.2313, val.acc = [0.6504, 0.711, 0.7576, 0.7716]\n","Epoch 293, loss = 0.2442, val.acc = [0.6506, 0.7162, 0.7574, 0.7708]\n","Epoch 294, loss = 0.2091, val.acc = [0.6508, 0.7104, 0.7542, 0.7698]\n","Epoch 295, loss = 0.2776, val.acc = [0.6498, 0.7138, 0.7528, 0.766]\n","Epoch 296, loss = 0.2400, val.acc = [0.6544, 0.718, 0.7558, 0.7652]\n","Epoch 297, loss = 0.2778, val.acc = [0.6554, 0.7218, 0.7544, 0.7684]\n","Epoch 298, loss = 0.3063, val.acc = [0.6524, 0.714, 0.7516, 0.7642]\n","Epoch 299, loss = 0.2296, val.acc = [0.6526, 0.7184, 0.7544, 0.769]\n","Epoch 300, loss = 0.2328, val.acc = [0.6532, 0.7116, 0.7526, 0.766]\n","Epoch 301, loss = 0.2283, val.acc = [0.6522, 0.7082, 0.7494, 0.759]\n","Epoch 302, loss = 0.2075, val.acc = [0.649, 0.7166, 0.7544, 0.7708]\n","Epoch 303, loss = 0.2653, val.acc = [0.6424, 0.7136, 0.7486, 0.7694]\n","Epoch 304, loss = 0.2269, val.acc = [0.6572, 0.7136, 0.7554, 0.771]\n","Epoch 305, loss = 0.2297, val.acc = [0.6514, 0.7122, 0.7484, 0.7614]\n","Epoch 306, loss = 0.2460, val.acc = [0.6514, 0.714, 0.7528, 0.7682]\n","Epoch 307, loss = 0.2246, val.acc = [0.6626, 0.7128, 0.7534, 0.7636]\n","Epoch 308, loss = 0.2057, val.acc = [0.6544, 0.7134, 0.7546, 0.7686]\n","Epoch 309, loss = 0.2666, val.acc = [0.6532, 0.71, 0.751, 0.7672]\n","Epoch 310, loss = 0.2715, val.acc = [0.6576, 0.714, 0.7506, 0.7642]\n","Epoch 311, loss = 0.2274, val.acc = [0.6456, 0.7096, 0.7442, 0.7584]\n","Epoch 312, loss = 0.2631, val.acc = [0.6568, 0.7116, 0.7496, 0.7702]\n","Epoch 313, loss = 0.2854, val.acc = [0.6594, 0.7136, 0.7552, 0.7684]\n","Epoch 314, loss = 0.2273, val.acc = [0.6524, 0.7146, 0.754, 0.7694]\n","Epoch 315, loss = 0.2622, val.acc = [0.6504, 0.7164, 0.754, 0.7686]\n","Epoch 316, loss = 0.2506, val.acc = [0.6544, 0.7154, 0.7528, 0.7694]\n","Epoch 317, loss = 0.2209, val.acc = [0.6596, 0.7174, 0.7544, 0.7696]\n","Epoch 318, loss = 0.1701, val.acc = [0.6462, 0.7098, 0.7518, 0.7674]\n","Epoch 319, loss = 0.2689, val.acc = [0.65, 0.7128, 0.7504, 0.764]\n","Epoch 320, loss = 0.2673, val.acc = [0.646, 0.7096, 0.7524, 0.7702]\n","Epoch 321, loss = 0.2339, val.acc = [0.6532, 0.7156, 0.752, 0.7672]\n","Epoch 322, loss = 0.2494, val.acc = [0.6506, 0.7068, 0.7546, 0.7684]\n","Epoch 323, loss = 0.2245, val.acc = [0.6512, 0.7142, 0.7538, 0.7702]\n","Epoch 324, loss = 0.2525, val.acc = [0.648, 0.7146, 0.7556, 0.768]\n","Epoch 325, loss = 0.2131, val.acc = [0.6432, 0.7144, 0.7506, 0.7694]\n","Epoch 326, loss = 0.2509, val.acc = [0.652, 0.7138, 0.7532, 0.7696]\n","Epoch 327, loss = 0.2791, val.acc = [0.6542, 0.713, 0.7542, 0.7716]\n","Epoch 328, loss = 0.2404, val.acc = [0.6572, 0.7186, 0.754, 0.7706]\n","Epoch 329, loss = 0.2278, val.acc = [0.6508, 0.7074, 0.7422, 0.7594]\n","Epoch 330, loss = 0.2106, val.acc = [0.6576, 0.717, 0.751, 0.77]\n","Epoch 331, loss = 0.2238, val.acc = [0.6516, 0.7184, 0.7542, 0.7668]\n","Epoch 332, loss = 0.2034, val.acc = [0.6552, 0.7138, 0.7514, 0.7634]\n","Epoch 333, loss = 0.2052, val.acc = [0.6574, 0.7128, 0.754, 0.7656]\n","Epoch 334, loss = 0.2520, val.acc = [0.65, 0.7054, 0.7512, 0.7614]\n","Epoch 335, loss = 0.1907, val.acc = [0.6556, 0.7126, 0.755, 0.767]\n","Epoch 336, loss = 0.2085, val.acc = [0.6544, 0.712, 0.7564, 0.7686]\n","Epoch 337, loss = 0.2455, val.acc = [0.6558, 0.7124, 0.7542, 0.769]\n","Epoch 338, loss = 0.1669, val.acc = [0.662, 0.7132, 0.7564, 0.7722]\n","Epoch 339, loss = 0.1919, val.acc = [0.6344, 0.7034, 0.7438, 0.7598]\n","Epoch 340, loss = 0.2005, val.acc = [0.6524, 0.713, 0.7526, 0.767]\n","Epoch 341, loss = 0.2424, val.acc = [0.6554, 0.7168, 0.7564, 0.7688]\n","Epoch 342, loss = 0.2089, val.acc = [0.6398, 0.715, 0.7508, 0.767]\n","Epoch 343, loss = 0.2223, val.acc = [0.6562, 0.7152, 0.754, 0.7664]\n","Epoch 344, loss = 0.2075, val.acc = [0.6496, 0.7086, 0.754, 0.7652]\n","Epoch 345, loss = 0.1867, val.acc = [0.6524, 0.711, 0.7526, 0.7638]\n","Epoch 346, loss = 0.2239, val.acc = [0.6572, 0.7134, 0.755, 0.7676]\n","Epoch 347, loss = 0.1902, val.acc = [0.6416, 0.7172, 0.754, 0.7678]\n","Epoch 348, loss = 0.1877, val.acc = [0.6534, 0.7088, 0.7518, 0.7614]\n","Epoch 349, loss = 0.2117, val.acc = [0.653, 0.7124, 0.7536, 0.7644]\n","Epoch 350, loss = 0.2030, val.acc = [0.6598, 0.7126, 0.7552, 0.7684]\n","Epoch 351, loss = 0.1892, val.acc = [0.6518, 0.719, 0.7592, 0.7734]\n","Epoch 352, loss = 0.2191, val.acc = [0.658, 0.7108, 0.7562, 0.7712]\n","Epoch 353, loss = 0.1898, val.acc = [0.6514, 0.7116, 0.7528, 0.769]\n","Epoch 354, loss = 0.1974, val.acc = [0.6538, 0.707, 0.753, 0.7652]\n","Epoch 355, loss = 0.2033, val.acc = [0.6466, 0.7042, 0.7504, 0.7612]\n","Epoch 356, loss = 0.1690, val.acc = [0.6548, 0.7116, 0.7526, 0.771]\n","Epoch 357, loss = 0.2009, val.acc = [0.6372, 0.708, 0.7518, 0.7654]\n","Epoch 358, loss = 0.1809, val.acc = [0.6548, 0.7088, 0.7564, 0.7718]\n","Epoch 359, loss = 0.1707, val.acc = [0.6566, 0.7144, 0.7532, 0.7722]\n","Epoch 360, loss = 0.1769, val.acc = [0.6542, 0.7102, 0.752, 0.7716]\n","Epoch 361, loss = 0.1941, val.acc = [0.6454, 0.7088, 0.754, 0.7648]\n","Epoch 362, loss = 0.2073, val.acc = [0.6532, 0.7086, 0.754, 0.7674]\n","Epoch 363, loss = 0.2166, val.acc = [0.6526, 0.7104, 0.7544, 0.7694]\n","Epoch 364, loss = 0.1830, val.acc = [0.6548, 0.7128, 0.7524, 0.767]\n","Epoch 365, loss = 0.1782, val.acc = [0.6536, 0.7092, 0.755, 0.7696]\n","Epoch 366, loss = 0.2173, val.acc = [0.6542, 0.7148, 0.7534, 0.769]\n","Epoch 367, loss = 0.2021, val.acc = [0.6518, 0.7118, 0.7546, 0.768]\n","Epoch 368, loss = 0.1799, val.acc = [0.6514, 0.713, 0.756, 0.77]\n","Epoch 369, loss = 0.1970, val.acc = [0.6528, 0.713, 0.7524, 0.7662]\n","Epoch 370, loss = 0.2393, val.acc = [0.6524, 0.7164, 0.7528, 0.772]\n","Epoch 371, loss = 0.1833, val.acc = [0.6494, 0.703, 0.752, 0.7656]\n","Epoch 372, loss = 0.2040, val.acc = [0.6466, 0.7126, 0.7548, 0.7656]\n","Epoch 373, loss = 0.1490, val.acc = [0.6468, 0.7156, 0.755, 0.7682]\n","Epoch 374, loss = 0.1986, val.acc = [0.6402, 0.708, 0.7568, 0.7668]\n","Epoch 375, loss = 0.1911, val.acc = [0.6582, 0.7078, 0.7526, 0.7696]\n","Epoch 376, loss = 0.1770, val.acc = [0.6506, 0.7098, 0.759, 0.7712]\n","Epoch 377, loss = 0.1719, val.acc = [0.645, 0.7108, 0.7566, 0.767]\n","Epoch 378, loss = 0.1773, val.acc = [0.6512, 0.7074, 0.753, 0.7668]\n","Epoch 379, loss = 0.2008, val.acc = [0.6528, 0.712, 0.7542, 0.7688]\n","Epoch 380, loss = 0.1891, val.acc = [0.658, 0.711, 0.7538, 0.7672]\n","Epoch 381, loss = 0.1376, val.acc = [0.6466, 0.7078, 0.753, 0.7678]\n","Epoch 382, loss = 0.1915, val.acc = [0.6242, 0.7088, 0.7478, 0.7554]\n","Epoch 383, loss = 0.1984, val.acc = [0.65, 0.713, 0.7536, 0.7682]\n","Epoch 384, loss = 0.1713, val.acc = [0.6504, 0.7082, 0.7568, 0.7682]\n","Epoch 385, loss = 0.2142, val.acc = [0.6486, 0.7076, 0.7534, 0.7674]\n","Epoch 386, loss = 0.1870, val.acc = [0.6546, 0.7092, 0.7536, 0.7634]\n","Epoch 387, loss = 0.1890, val.acc = [0.6564, 0.7098, 0.7508, 0.7696]\n","Epoch 388, loss = 0.1569, val.acc = [0.6508, 0.7092, 0.7536, 0.7694]\n","Epoch 389, loss = 0.1935, val.acc = [0.6576, 0.7126, 0.7554, 0.769]\n","Epoch 390, loss = 0.1548, val.acc = [0.658, 0.71, 0.7554, 0.7678]\n","Epoch 391, loss = 0.2263, val.acc = [0.66, 0.7142, 0.7558, 0.7672]\n","Epoch 392, loss = 0.1830, val.acc = [0.6572, 0.71, 0.7566, 0.7652]\n","Epoch 393, loss = 0.1552, val.acc = [0.635, 0.7062, 0.7548, 0.7664]\n","Epoch 394, loss = 0.1860, val.acc = [0.6532, 0.7086, 0.7524, 0.7656]\n","Epoch 395, loss = 0.1856, val.acc = [0.651, 0.7074, 0.7522, 0.767]\n","Epoch 396, loss = 0.1694, val.acc = [0.6554, 0.7114, 0.7512, 0.7676]\n","Epoch 397, loss = 0.1770, val.acc = [0.6574, 0.7124, 0.756, 0.7674]\n","Epoch 398, loss = 0.1559, val.acc = [0.6562, 0.7112, 0.7568, 0.7688]\n","Epoch 399, loss = 0.1748, val.acc = [0.6522, 0.7098, 0.7556, 0.7648]\n","Rep: 4, te.acc = [0.6416, 0.6936, 0.7406, 0.753]\n","\n","Rep 5\n","Sequential(\n","  (layer0): Sequential(\n","    (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer1): Sequential(\n","    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n","    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n","Sequential(\n","  (aux0): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=8192, out_features=10, bias=True)\n","  )\n","  (aux1): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n","  (aux2): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n","  (aux3): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (fc): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n","Epoch 0, loss = 2.0981, val.acc = [0.3364, 0.3354, 0.2712, 0.2224]\n","Epoch 1, loss = 1.9372, val.acc = [0.3816, 0.3766, 0.3128, 0.2642]\n","Epoch 2, loss = 1.8193, val.acc = [0.4186, 0.3998, 0.3546, 0.3098]\n","Epoch 3, loss = 1.7541, val.acc = [0.4352, 0.4246, 0.3994, 0.3366]\n","Epoch 4, loss = 1.6791, val.acc = [0.4446, 0.4348, 0.4112, 0.3568]\n","Epoch 5, loss = 1.6658, val.acc = [0.4558, 0.4598, 0.4256, 0.3706]\n","Epoch 6, loss = 1.5933, val.acc = [0.467, 0.4828, 0.4508, 0.3944]\n","Epoch 7, loss = 1.5646, val.acc = [0.4502, 0.484, 0.4728, 0.4104]\n","Epoch 8, loss = 1.5228, val.acc = [0.4806, 0.506, 0.4852, 0.4352]\n","Epoch 9, loss = 1.4934, val.acc = [0.4822, 0.5168, 0.4974, 0.4492]\n","Epoch 10, loss = 1.4634, val.acc = [0.4692, 0.5242, 0.4858, 0.4358]\n","Epoch 11, loss = 1.4480, val.acc = [0.4906, 0.5318, 0.5182, 0.4756]\n","Epoch 12, loss = 1.4070, val.acc = [0.4918, 0.5308, 0.536, 0.485]\n","Epoch 13, loss = 1.3735, val.acc = [0.5056, 0.5354, 0.5464, 0.4958]\n","Epoch 14, loss = 1.3694, val.acc = [0.5186, 0.538, 0.546, 0.5064]\n","Epoch 15, loss = 1.3465, val.acc = [0.4982, 0.5506, 0.5458, 0.506]\n","Epoch 16, loss = 1.3335, val.acc = [0.4942, 0.5294, 0.5232, 0.496]\n","Epoch 17, loss = 1.3229, val.acc = [0.4954, 0.5254, 0.5318, 0.496]\n","Epoch 18, loss = 1.2990, val.acc = [0.5084, 0.5524, 0.5598, 0.5232]\n","Epoch 19, loss = 1.2839, val.acc = [0.5264, 0.5522, 0.5528, 0.535]\n","Epoch 20, loss = 1.2629, val.acc = [0.5298, 0.5702, 0.571, 0.5374]\n","Epoch 21, loss = 1.2828, val.acc = [0.5328, 0.5676, 0.585, 0.55]\n","Epoch 22, loss = 1.2369, val.acc = [0.533, 0.5824, 0.5942, 0.565]\n","Epoch 23, loss = 1.2263, val.acc = [0.5328, 0.5862, 0.5952, 0.5688]\n","Epoch 24, loss = 1.1979, val.acc = [0.531, 0.5704, 0.5964, 0.5682]\n","Epoch 25, loss = 1.2042, val.acc = [0.531, 0.597, 0.6064, 0.5766]\n","Epoch 26, loss = 1.2011, val.acc = [0.5114, 0.5864, 0.6006, 0.5786]\n","Epoch 27, loss = 1.1706, val.acc = [0.525, 0.6036, 0.6118, 0.5904]\n","Epoch 28, loss = 1.1692, val.acc = [0.5436, 0.605, 0.6194, 0.6]\n","Epoch 29, loss = 1.1591, val.acc = [0.5444, 0.6036, 0.6276, 0.6052]\n","Epoch 30, loss = 1.1323, val.acc = [0.5498, 0.6052, 0.6288, 0.5988]\n","Epoch 31, loss = 1.1222, val.acc = [0.554, 0.605, 0.6306, 0.6084]\n","Epoch 32, loss = 1.1460, val.acc = [0.5608, 0.619, 0.6392, 0.6192]\n","Epoch 33, loss = 1.1159, val.acc = [0.5566, 0.6206, 0.636, 0.618]\n","Epoch 34, loss = 1.1095, val.acc = [0.537, 0.6058, 0.6314, 0.6202]\n","Epoch 35, loss = 1.0861, val.acc = [0.5602, 0.6306, 0.648, 0.6338]\n","Epoch 36, loss = 1.0787, val.acc = [0.5634, 0.613, 0.6502, 0.6256]\n","Epoch 37, loss = 1.0432, val.acc = [0.567, 0.634, 0.6558, 0.6396]\n","Epoch 38, loss = 1.0678, val.acc = [0.5446, 0.6068, 0.6452, 0.6384]\n","Epoch 39, loss = 1.0387, val.acc = [0.5696, 0.637, 0.6608, 0.6504]\n","Epoch 40, loss = 1.0348, val.acc = [0.553, 0.6188, 0.6326, 0.6362]\n","Epoch 41, loss = 1.0289, val.acc = [0.5676, 0.634, 0.6632, 0.6436]\n","Epoch 42, loss = 1.0275, val.acc = [0.5676, 0.6188, 0.657, 0.6332]\n","Epoch 43, loss = 1.0307, val.acc = [0.5706, 0.616, 0.6682, 0.6632]\n","Epoch 44, loss = 1.0136, val.acc = [0.5464, 0.609, 0.6372, 0.6162]\n","Epoch 45, loss = 1.0021, val.acc = [0.5254, 0.6324, 0.6522, 0.6608]\n","Epoch 46, loss = 0.9819, val.acc = [0.5652, 0.644, 0.6654, 0.6636]\n","Epoch 47, loss = 0.9931, val.acc = [0.5926, 0.6576, 0.675, 0.6734]\n","Epoch 48, loss = 0.9935, val.acc = [0.5886, 0.6618, 0.6748, 0.6764]\n","Epoch 49, loss = 0.9707, val.acc = [0.5888, 0.6482, 0.675, 0.6686]\n","Epoch 50, loss = 0.9532, val.acc = [0.574, 0.6418, 0.6566, 0.6706]\n","Epoch 51, loss = 0.9489, val.acc = [0.5856, 0.6584, 0.6796, 0.6876]\n","Epoch 52, loss = 0.9727, val.acc = [0.5884, 0.6618, 0.6824, 0.6898]\n","Epoch 53, loss = 0.9537, val.acc = [0.5874, 0.6688, 0.6882, 0.6914]\n","Epoch 54, loss = 0.9360, val.acc = [0.5776, 0.6642, 0.688, 0.6858]\n","Epoch 55, loss = 0.9265, val.acc = [0.5958, 0.6644, 0.693, 0.6916]\n","Epoch 56, loss = 0.9283, val.acc = [0.588, 0.6448, 0.686, 0.6914]\n","Epoch 57, loss = 0.8900, val.acc = [0.5996, 0.663, 0.6902, 0.6942]\n","Epoch 58, loss = 0.9418, val.acc = [0.5936, 0.6662, 0.6954, 0.6932]\n","Epoch 59, loss = 0.8893, val.acc = [0.6104, 0.6668, 0.6984, 0.7018]\n","Epoch 60, loss = 0.9035, val.acc = [0.5936, 0.6596, 0.6926, 0.7032]\n","Epoch 61, loss = 0.9002, val.acc = [0.6014, 0.6722, 0.6978, 0.6976]\n","Epoch 62, loss = 0.8729, val.acc = [0.6074, 0.6662, 0.6984, 0.7034]\n","Epoch 63, loss = 0.8814, val.acc = [0.6094, 0.66, 0.6922, 0.694]\n","Epoch 64, loss = 0.8397, val.acc = [0.5942, 0.6662, 0.7062, 0.708]\n","Epoch 65, loss = 0.8983, val.acc = [0.5928, 0.6716, 0.7008, 0.6982]\n","Epoch 66, loss = 0.8714, val.acc = [0.5898, 0.6752, 0.7078, 0.716]\n","Epoch 67, loss = 0.8759, val.acc = [0.5764, 0.6684, 0.7028, 0.7112]\n","Epoch 68, loss = 0.8402, val.acc = [0.6046, 0.6802, 0.7114, 0.7216]\n","Epoch 69, loss = 0.8428, val.acc = [0.6228, 0.6828, 0.7144, 0.7178]\n","Epoch 70, loss = 0.8381, val.acc = [0.6102, 0.6734, 0.7024, 0.7196]\n","Epoch 71, loss = 0.8348, val.acc = [0.6194, 0.679, 0.7138, 0.7204]\n","Epoch 72, loss = 0.8321, val.acc = [0.5966, 0.6504, 0.6948, 0.7146]\n","Epoch 73, loss = 0.8408, val.acc = [0.6142, 0.6782, 0.7204, 0.7266]\n","Epoch 74, loss = 0.8124, val.acc = [0.617, 0.6858, 0.7176, 0.7274]\n","Epoch 75, loss = 0.7922, val.acc = [0.6236, 0.6894, 0.7196, 0.7302]\n","Epoch 76, loss = 0.8105, val.acc = [0.5986, 0.6702, 0.7088, 0.7078]\n","Epoch 77, loss = 0.7783, val.acc = [0.619, 0.6844, 0.7234, 0.7324]\n","Epoch 78, loss = 0.8376, val.acc = [0.607, 0.6836, 0.7078, 0.7234]\n","Epoch 79, loss = 0.8042, val.acc = [0.633, 0.6926, 0.7256, 0.736]\n","Epoch 80, loss = 0.8068, val.acc = [0.6158, 0.6842, 0.7138, 0.7234]\n","Epoch 81, loss = 0.7731, val.acc = [0.6168, 0.664, 0.7076, 0.7178]\n","Epoch 82, loss = 0.7755, val.acc = [0.6296, 0.6872, 0.7224, 0.7294]\n","Epoch 83, loss = 0.7792, val.acc = [0.616, 0.686, 0.7244, 0.7346]\n","Epoch 84, loss = 0.7795, val.acc = [0.6322, 0.6824, 0.7212, 0.735]\n","Epoch 85, loss = 0.7939, val.acc = [0.6192, 0.6882, 0.7256, 0.737]\n","Epoch 86, loss = 0.7684, val.acc = [0.5984, 0.6576, 0.7206, 0.7302]\n","Epoch 87, loss = 0.7557, val.acc = [0.6246, 0.6878, 0.727, 0.7398]\n","Epoch 88, loss = 0.7595, val.acc = [0.5904, 0.6766, 0.712, 0.7228]\n","Epoch 89, loss = 0.7565, val.acc = [0.6278, 0.6946, 0.7318, 0.74]\n","Epoch 90, loss = 0.7352, val.acc = [0.6294, 0.6926, 0.7298, 0.7444]\n","Epoch 91, loss = 0.7290, val.acc = [0.6328, 0.7002, 0.734, 0.7442]\n","Epoch 92, loss = 0.7143, val.acc = [0.5968, 0.6942, 0.7196, 0.7374]\n","Epoch 93, loss = 0.7562, val.acc = [0.6348, 0.6924, 0.7376, 0.7416]\n","Epoch 94, loss = 0.7165, val.acc = [0.6388, 0.684, 0.7262, 0.7364]\n","Epoch 95, loss = 0.7271, val.acc = [0.6282, 0.6946, 0.7336, 0.7424]\n","Epoch 96, loss = 0.7260, val.acc = [0.6426, 0.701, 0.7318, 0.7494]\n","Epoch 97, loss = 0.7136, val.acc = [0.616, 0.693, 0.7346, 0.7478]\n","Epoch 98, loss = 0.6890, val.acc = [0.631, 0.7048, 0.7414, 0.7516]\n","Epoch 99, loss = 0.6816, val.acc = [0.628, 0.6892, 0.7212, 0.7432]\n","Epoch 100, loss = 0.6593, val.acc = [0.6284, 0.6992, 0.732, 0.7456]\n","Epoch 101, loss = 0.7002, val.acc = [0.6442, 0.7038, 0.7412, 0.7532]\n","Epoch 102, loss = 0.6605, val.acc = [0.6344, 0.6956, 0.7352, 0.743]\n","Epoch 103, loss = 0.6678, val.acc = [0.6314, 0.7042, 0.7402, 0.7552]\n","Epoch 104, loss = 0.6618, val.acc = [0.623, 0.6924, 0.7272, 0.746]\n","Epoch 105, loss = 0.7235, val.acc = [0.6434, 0.7036, 0.7398, 0.7542]\n","Epoch 106, loss = 0.6707, val.acc = [0.6324, 0.7016, 0.7446, 0.7488]\n","Epoch 107, loss = 0.6712, val.acc = [0.636, 0.7078, 0.738, 0.7482]\n","Epoch 108, loss = 0.6787, val.acc = [0.6466, 0.7086, 0.74, 0.7562]\n","Epoch 109, loss = 0.6552, val.acc = [0.6426, 0.706, 0.7374, 0.7518]\n","Epoch 110, loss = 0.6848, val.acc = [0.6396, 0.7038, 0.7326, 0.751]\n","Epoch 111, loss = 0.6539, val.acc = [0.6228, 0.7114, 0.742, 0.7616]\n","Epoch 112, loss = 0.6481, val.acc = [0.6276, 0.703, 0.7378, 0.7498]\n","Epoch 113, loss = 0.6656, val.acc = [0.615, 0.68, 0.7266, 0.7304]\n","Epoch 114, loss = 0.6260, val.acc = [0.641, 0.7044, 0.7422, 0.7524]\n","Epoch 115, loss = 0.6131, val.acc = [0.6284, 0.701, 0.7408, 0.753]\n","Epoch 116, loss = 0.6357, val.acc = [0.6294, 0.6976, 0.7386, 0.7508]\n","Epoch 117, loss = 0.6443, val.acc = [0.6506, 0.7018, 0.746, 0.758]\n","Epoch 118, loss = 0.6237, val.acc = [0.6426, 0.7102, 0.742, 0.7564]\n","Epoch 119, loss = 0.6179, val.acc = [0.6086, 0.704, 0.7344, 0.7542]\n","Epoch 120, loss = 0.6542, val.acc = [0.6438, 0.7084, 0.7446, 0.7548]\n","Epoch 121, loss = 0.6195, val.acc = [0.6366, 0.7138, 0.7464, 0.7614]\n","Epoch 122, loss = 0.6185, val.acc = [0.6368, 0.697, 0.7432, 0.7508]\n","Epoch 123, loss = 0.5954, val.acc = [0.648, 0.7146, 0.7442, 0.7548]\n","Epoch 124, loss = 0.6006, val.acc = [0.6492, 0.7158, 0.7474, 0.761]\n","Epoch 125, loss = 0.5884, val.acc = [0.6316, 0.7036, 0.7308, 0.7306]\n","Epoch 126, loss = 0.6305, val.acc = [0.6484, 0.7132, 0.747, 0.7626]\n","Epoch 127, loss = 0.5983, val.acc = [0.646, 0.7156, 0.7458, 0.7596]\n","Epoch 128, loss = 0.5455, val.acc = [0.6468, 0.7102, 0.7432, 0.7638]\n","Epoch 129, loss = 0.5610, val.acc = [0.6346, 0.7072, 0.7426, 0.76]\n","Epoch 130, loss = 0.5590, val.acc = [0.6092, 0.6972, 0.7356, 0.7488]\n","Epoch 131, loss = 0.5750, val.acc = [0.609, 0.6912, 0.7408, 0.7558]\n","Epoch 132, loss = 0.5827, val.acc = [0.6496, 0.709, 0.7464, 0.7566]\n","Epoch 133, loss = 0.5830, val.acc = [0.6306, 0.7122, 0.7488, 0.7574]\n","Epoch 134, loss = 0.5438, val.acc = [0.6454, 0.7136, 0.7468, 0.762]\n","Epoch 135, loss = 0.5325, val.acc = [0.6498, 0.7112, 0.7526, 0.7622]\n","Epoch 136, loss = 0.5571, val.acc = [0.642, 0.7164, 0.7532, 0.762]\n","Epoch 137, loss = 0.5566, val.acc = [0.65, 0.7066, 0.7528, 0.7596]\n","Epoch 138, loss = 0.5717, val.acc = [0.6414, 0.7158, 0.7552, 0.7616]\n","Epoch 139, loss = 0.5772, val.acc = [0.637, 0.717, 0.75, 0.7608]\n","Epoch 140, loss = 0.5629, val.acc = [0.647, 0.7148, 0.7496, 0.7588]\n","Epoch 141, loss = 0.5154, val.acc = [0.6404, 0.7126, 0.7466, 0.7608]\n","Epoch 142, loss = 0.5237, val.acc = [0.6504, 0.7132, 0.7444, 0.7566]\n","Epoch 143, loss = 0.5408, val.acc = [0.6518, 0.7104, 0.7484, 0.766]\n","Epoch 144, loss = 0.5425, val.acc = [0.6522, 0.7146, 0.7506, 0.7672]\n","Epoch 145, loss = 0.5522, val.acc = [0.6348, 0.7114, 0.7452, 0.7598]\n","Epoch 146, loss = 0.5526, val.acc = [0.6408, 0.7134, 0.7436, 0.7558]\n","Epoch 147, loss = 0.5210, val.acc = [0.6424, 0.7132, 0.7518, 0.7594]\n","Epoch 148, loss = 0.5387, val.acc = [0.6456, 0.7106, 0.7434, 0.7594]\n","Epoch 149, loss = 0.5302, val.acc = [0.647, 0.7142, 0.7514, 0.7622]\n","Epoch 150, loss = 0.5340, val.acc = [0.6524, 0.713, 0.7544, 0.7574]\n","Epoch 151, loss = 0.5116, val.acc = [0.6526, 0.7154, 0.7514, 0.7606]\n","Epoch 152, loss = 0.5393, val.acc = [0.638, 0.7056, 0.75, 0.7594]\n","Epoch 153, loss = 0.4763, val.acc = [0.6398, 0.7066, 0.7408, 0.757]\n","Epoch 154, loss = 0.5025, val.acc = [0.6578, 0.7136, 0.7438, 0.7638]\n","Epoch 155, loss = 0.4430, val.acc = [0.6556, 0.7194, 0.7556, 0.7624]\n","Epoch 156, loss = 0.5250, val.acc = [0.6366, 0.7148, 0.7488, 0.7546]\n","Epoch 157, loss = 0.4777, val.acc = [0.6458, 0.718, 0.7556, 0.7644]\n","Epoch 158, loss = 0.5215, val.acc = [0.6408, 0.7148, 0.7428, 0.7558]\n","Epoch 159, loss = 0.4837, val.acc = [0.6316, 0.7048, 0.7494, 0.7566]\n","Epoch 160, loss = 0.4974, val.acc = [0.6528, 0.7136, 0.7552, 0.7586]\n","Epoch 161, loss = 0.4649, val.acc = [0.6612, 0.7158, 0.7564, 0.7632]\n","Epoch 162, loss = 0.4778, val.acc = [0.6544, 0.7182, 0.7506, 0.766]\n","Epoch 163, loss = 0.5081, val.acc = [0.6538, 0.7202, 0.7546, 0.7658]\n","Epoch 164, loss = 0.4682, val.acc = [0.6306, 0.6912, 0.7398, 0.748]\n","Epoch 165, loss = 0.4729, val.acc = [0.6502, 0.7066, 0.744, 0.7646]\n","Epoch 166, loss = 0.4628, val.acc = [0.6382, 0.7096, 0.7396, 0.759]\n","Epoch 167, loss = 0.4481, val.acc = [0.6296, 0.717, 0.744, 0.7612]\n","Epoch 168, loss = 0.4965, val.acc = [0.6112, 0.705, 0.7494, 0.7482]\n","Epoch 169, loss = 0.4834, val.acc = [0.6568, 0.7144, 0.752, 0.7636]\n","Epoch 170, loss = 0.4504, val.acc = [0.6624, 0.7196, 0.7584, 0.7666]\n","Epoch 171, loss = 0.4648, val.acc = [0.6474, 0.7178, 0.754, 0.7644]\n","Epoch 172, loss = 0.4035, val.acc = [0.6608, 0.7238, 0.7562, 0.765]\n","Epoch 173, loss = 0.4052, val.acc = [0.6524, 0.716, 0.7554, 0.7648]\n","Epoch 174, loss = 0.4314, val.acc = [0.6406, 0.709, 0.7398, 0.75]\n","Epoch 175, loss = 0.4177, val.acc = [0.6488, 0.7114, 0.7544, 0.7596]\n","Epoch 176, loss = 0.4456, val.acc = [0.653, 0.7168, 0.7518, 0.7608]\n","Epoch 177, loss = 0.4422, val.acc = [0.6412, 0.7146, 0.7528, 0.762]\n","Epoch 178, loss = 0.4157, val.acc = [0.6388, 0.7172, 0.7554, 0.7624]\n","Epoch 179, loss = 0.4190, val.acc = [0.6534, 0.7184, 0.7496, 0.7536]\n","Epoch 180, loss = 0.4210, val.acc = [0.6418, 0.7038, 0.7398, 0.7572]\n","Epoch 181, loss = 0.4198, val.acc = [0.6566, 0.718, 0.7478, 0.7558]\n","Epoch 182, loss = 0.4373, val.acc = [0.6516, 0.7168, 0.7592, 0.7664]\n","Epoch 183, loss = 0.4123, val.acc = [0.6548, 0.7176, 0.755, 0.7608]\n","Epoch 184, loss = 0.3718, val.acc = [0.6546, 0.7208, 0.7522, 0.7642]\n","Epoch 185, loss = 0.4004, val.acc = [0.6354, 0.715, 0.752, 0.7622]\n","Epoch 186, loss = 0.4504, val.acc = [0.6526, 0.72, 0.7534, 0.7642]\n","Epoch 187, loss = 0.3693, val.acc = [0.6468, 0.72, 0.751, 0.7606]\n","Epoch 188, loss = 0.3502, val.acc = [0.6488, 0.714, 0.7514, 0.7632]\n","Epoch 189, loss = 0.3861, val.acc = [0.6552, 0.718, 0.7578, 0.762]\n","Epoch 190, loss = 0.4180, val.acc = [0.657, 0.7234, 0.7546, 0.763]\n","Epoch 191, loss = 0.4207, val.acc = [0.6476, 0.7158, 0.7482, 0.7518]\n","Epoch 192, loss = 0.3698, val.acc = [0.6548, 0.7126, 0.753, 0.761]\n","Epoch 193, loss = 0.4170, val.acc = [0.648, 0.7232, 0.7562, 0.764]\n","Epoch 194, loss = 0.3596, val.acc = [0.6582, 0.7172, 0.754, 0.7646]\n","Epoch 195, loss = 0.3876, val.acc = [0.6566, 0.7148, 0.7544, 0.7618]\n","Epoch 196, loss = 0.4090, val.acc = [0.6426, 0.718, 0.7546, 0.763]\n","Epoch 197, loss = 0.3708, val.acc = [0.6514, 0.7176, 0.754, 0.7618]\n","Epoch 198, loss = 0.3994, val.acc = [0.6464, 0.7186, 0.7526, 0.7586]\n","Epoch 199, loss = 0.3739, val.acc = [0.6576, 0.72, 0.753, 0.7672]\n","Epoch 200, loss = 0.3478, val.acc = [0.6416, 0.714, 0.754, 0.7678]\n","Epoch 201, loss = 0.3946, val.acc = [0.6538, 0.7194, 0.752, 0.7636]\n","Epoch 202, loss = 0.3349, val.acc = [0.6496, 0.7196, 0.7552, 0.76]\n","Epoch 203, loss = 0.3745, val.acc = [0.6446, 0.7194, 0.7538, 0.7564]\n","Epoch 204, loss = 0.3327, val.acc = [0.6582, 0.7198, 0.753, 0.7596]\n","Epoch 205, loss = 0.3979, val.acc = [0.6598, 0.7148, 0.7524, 0.7644]\n","Epoch 206, loss = 0.3736, val.acc = [0.6544, 0.72, 0.7486, 0.7628]\n","Epoch 207, loss = 0.3376, val.acc = [0.6456, 0.708, 0.7504, 0.7594]\n","Epoch 208, loss = 0.3523, val.acc = [0.6542, 0.722, 0.7562, 0.7616]\n","Epoch 209, loss = 0.3208, val.acc = [0.6396, 0.7124, 0.7536, 0.7618]\n","Epoch 210, loss = 0.3382, val.acc = [0.6628, 0.7168, 0.757, 0.763]\n","Epoch 211, loss = 0.3313, val.acc = [0.6452, 0.7148, 0.753, 0.763]\n","Epoch 212, loss = 0.3288, val.acc = [0.6404, 0.7048, 0.748, 0.7582]\n","Epoch 213, loss = 0.3723, val.acc = [0.6524, 0.7172, 0.7532, 0.7604]\n","Epoch 214, loss = 0.3284, val.acc = [0.6494, 0.7162, 0.7538, 0.755]\n","Epoch 215, loss = 0.3656, val.acc = [0.6552, 0.7194, 0.7512, 0.7612]\n","Epoch 216, loss = 0.3812, val.acc = [0.639, 0.7194, 0.7562, 0.7622]\n","Epoch 217, loss = 0.3866, val.acc = [0.6372, 0.7172, 0.751, 0.7616]\n","Epoch 218, loss = 0.3400, val.acc = [0.6448, 0.7154, 0.7506, 0.7574]\n","Epoch 219, loss = 0.3364, val.acc = [0.6532, 0.7196, 0.7534, 0.7588]\n","Epoch 220, loss = 0.3559, val.acc = [0.6496, 0.7162, 0.758, 0.762]\n","Epoch 221, loss = 0.3514, val.acc = [0.6596, 0.72, 0.7518, 0.7598]\n","Epoch 222, loss = 0.3465, val.acc = [0.6562, 0.7184, 0.7546, 0.7596]\n","Epoch 223, loss = 0.3693, val.acc = [0.654, 0.7162, 0.7496, 0.7556]\n","Epoch 224, loss = 0.3747, val.acc = [0.6472, 0.7118, 0.7546, 0.7612]\n","Epoch 225, loss = 0.3445, val.acc = [0.6516, 0.7236, 0.7572, 0.762]\n","Epoch 226, loss = 0.3826, val.acc = [0.644, 0.7174, 0.7538, 0.7616]\n","Epoch 227, loss = 0.3078, val.acc = [0.6482, 0.7114, 0.7504, 0.7624]\n","Epoch 228, loss = 0.2890, val.acc = [0.6564, 0.7208, 0.749, 0.7632]\n","Epoch 229, loss = 0.3236, val.acc = [0.645, 0.714, 0.75, 0.764]\n","Epoch 230, loss = 0.3302, val.acc = [0.6584, 0.7108, 0.7474, 0.757]\n","Epoch 231, loss = 0.3303, val.acc = [0.6546, 0.7144, 0.7544, 0.7616]\n","Epoch 232, loss = 0.3323, val.acc = [0.6626, 0.7218, 0.757, 0.763]\n","Epoch 233, loss = 0.3307, val.acc = [0.6524, 0.7192, 0.752, 0.7594]\n","Epoch 234, loss = 0.3374, val.acc = [0.6522, 0.7108, 0.7454, 0.7522]\n","Epoch 235, loss = 0.3457, val.acc = [0.6482, 0.7164, 0.7558, 0.7626]\n","Epoch 236, loss = 0.3579, val.acc = [0.6502, 0.7152, 0.7488, 0.7552]\n","Epoch 237, loss = 0.3086, val.acc = [0.6388, 0.7162, 0.7482, 0.758]\n","Epoch 238, loss = 0.3198, val.acc = [0.6442, 0.7144, 0.7504, 0.7582]\n","Epoch 239, loss = 0.3207, val.acc = [0.653, 0.7162, 0.7458, 0.759]\n","Epoch 240, loss = 0.3058, val.acc = [0.6586, 0.7146, 0.7506, 0.7588]\n","Epoch 241, loss = 0.3303, val.acc = [0.6458, 0.7178, 0.7516, 0.7598]\n","Epoch 242, loss = 0.3320, val.acc = [0.6562, 0.713, 0.7504, 0.7604]\n","Epoch 243, loss = 0.3059, val.acc = [0.639, 0.7112, 0.7506, 0.7572]\n","Epoch 244, loss = 0.2800, val.acc = [0.6456, 0.715, 0.7484, 0.7582]\n","Epoch 245, loss = 0.2989, val.acc = [0.6536, 0.716, 0.7528, 0.7624]\n","Epoch 246, loss = 0.2635, val.acc = [0.6512, 0.7174, 0.7572, 0.7638]\n","Epoch 247, loss = 0.3101, val.acc = [0.6544, 0.7144, 0.7538, 0.7582]\n","Epoch 248, loss = 0.3072, val.acc = [0.653, 0.7184, 0.7534, 0.7586]\n","Epoch 249, loss = 0.2664, val.acc = [0.6436, 0.7138, 0.7498, 0.7598]\n","Epoch 250, loss = 0.2822, val.acc = [0.655, 0.7182, 0.7486, 0.7572]\n","Epoch 251, loss = 0.2820, val.acc = [0.6458, 0.7162, 0.7492, 0.7582]\n","Epoch 252, loss = 0.2753, val.acc = [0.6278, 0.7148, 0.7494, 0.7562]\n","Epoch 253, loss = 0.3000, val.acc = [0.6574, 0.7144, 0.749, 0.763]\n","Epoch 254, loss = 0.2262, val.acc = [0.6562, 0.7118, 0.748, 0.7572]\n","Epoch 255, loss = 0.2896, val.acc = [0.643, 0.7174, 0.7488, 0.7616]\n","Epoch 256, loss = 0.2762, val.acc = [0.6556, 0.716, 0.753, 0.7624]\n","Epoch 257, loss = 0.2900, val.acc = [0.6524, 0.7146, 0.7476, 0.7578]\n","Epoch 258, loss = 0.3221, val.acc = [0.6518, 0.72, 0.7514, 0.763]\n","Epoch 259, loss = 0.2546, val.acc = [0.6524, 0.7128, 0.7546, 0.7612]\n","Epoch 260, loss = 0.2817, val.acc = [0.6494, 0.7182, 0.7488, 0.76]\n","Epoch 261, loss = 0.2956, val.acc = [0.6514, 0.7156, 0.754, 0.7582]\n","Epoch 262, loss = 0.2798, val.acc = [0.6526, 0.7204, 0.7518, 0.7604]\n","Epoch 263, loss = 0.3301, val.acc = [0.6566, 0.7148, 0.7538, 0.7602]\n","Epoch 264, loss = 0.2850, val.acc = [0.6572, 0.7156, 0.7522, 0.76]\n","Epoch 265, loss = 0.2842, val.acc = [0.6502, 0.7166, 0.7508, 0.761]\n","Epoch 266, loss = 0.2563, val.acc = [0.6442, 0.7072, 0.7488, 0.7578]\n","Epoch 267, loss = 0.3280, val.acc = [0.6594, 0.7154, 0.7508, 0.7618]\n","Epoch 268, loss = 0.2749, val.acc = [0.641, 0.717, 0.7506, 0.7554]\n","Epoch 269, loss = 0.2530, val.acc = [0.649, 0.716, 0.7478, 0.7614]\n","Epoch 270, loss = 0.2424, val.acc = [0.6606, 0.7172, 0.7504, 0.761]\n","Epoch 271, loss = 0.2982, val.acc = [0.6542, 0.7168, 0.7504, 0.7606]\n","Epoch 272, loss = 0.2486, val.acc = [0.648, 0.7178, 0.7486, 0.7596]\n","Epoch 273, loss = 0.3321, val.acc = [0.655, 0.7186, 0.7536, 0.7604]\n","Epoch 274, loss = 0.3135, val.acc = [0.6102, 0.7086, 0.7426, 0.758]\n","Epoch 275, loss = 0.2522, val.acc = [0.6494, 0.7126, 0.7456, 0.7564]\n","Epoch 276, loss = 0.2530, val.acc = [0.653, 0.7168, 0.7538, 0.7626]\n","Epoch 277, loss = 0.2527, val.acc = [0.6504, 0.7148, 0.7486, 0.7604]\n","Epoch 278, loss = 0.2772, val.acc = [0.6404, 0.7196, 0.7516, 0.7644]\n","Epoch 279, loss = 0.2260, val.acc = [0.6464, 0.7146, 0.7496, 0.7608]\n","Epoch 280, loss = 0.2731, val.acc = [0.6518, 0.7084, 0.7514, 0.7596]\n","Epoch 281, loss = 0.2455, val.acc = [0.6478, 0.7128, 0.748, 0.758]\n","Epoch 282, loss = 0.2066, val.acc = [0.6518, 0.7118, 0.7514, 0.7584]\n","Epoch 283, loss = 0.2272, val.acc = [0.6548, 0.7164, 0.7506, 0.7622]\n","Epoch 284, loss = 0.2305, val.acc = [0.6512, 0.708, 0.7486, 0.7596]\n","Epoch 285, loss = 0.2415, val.acc = [0.6418, 0.715, 0.7476, 0.7562]\n","Epoch 286, loss = 0.2615, val.acc = [0.6582, 0.7096, 0.7514, 0.7596]\n","Epoch 287, loss = 0.2755, val.acc = [0.6536, 0.7104, 0.7514, 0.7596]\n","Epoch 288, loss = 0.2607, val.acc = [0.638, 0.712, 0.748, 0.7588]\n","Epoch 289, loss = 0.2826, val.acc = [0.6406, 0.719, 0.7534, 0.7594]\n","Epoch 290, loss = 0.2492, val.acc = [0.6532, 0.7144, 0.7534, 0.763]\n","Epoch 291, loss = 0.1664, val.acc = [0.6496, 0.7106, 0.7504, 0.7606]\n","Epoch 292, loss = 0.2267, val.acc = [0.6574, 0.7076, 0.75, 0.7592]\n","Epoch 293, loss = 0.2360, val.acc = [0.6476, 0.7156, 0.751, 0.7596]\n","Epoch 294, loss = 0.2560, val.acc = [0.6508, 0.7146, 0.7522, 0.7604]\n","Epoch 295, loss = 0.2739, val.acc = [0.6332, 0.7066, 0.7512, 0.758]\n","Epoch 296, loss = 0.2477, val.acc = [0.6402, 0.711, 0.7502, 0.7596]\n","Epoch 297, loss = 0.2135, val.acc = [0.653, 0.7162, 0.7542, 0.7608]\n","Epoch 298, loss = 0.2404, val.acc = [0.649, 0.7178, 0.7536, 0.76]\n","Epoch 299, loss = 0.2532, val.acc = [0.65, 0.7134, 0.751, 0.757]\n","Epoch 300, loss = 0.2014, val.acc = [0.6478, 0.7166, 0.7538, 0.7602]\n","Epoch 301, loss = 0.2180, val.acc = [0.6456, 0.7134, 0.7522, 0.7588]\n","Epoch 302, loss = 0.3203, val.acc = [0.6506, 0.7144, 0.7514, 0.7606]\n","Epoch 303, loss = 0.2246, val.acc = [0.6498, 0.7144, 0.7512, 0.7602]\n","Epoch 304, loss = 0.2236, val.acc = [0.6506, 0.7132, 0.7538, 0.7576]\n","Epoch 305, loss = 0.2703, val.acc = [0.6478, 0.7138, 0.7514, 0.759]\n","Epoch 306, loss = 0.2679, val.acc = [0.6454, 0.7152, 0.7498, 0.7582]\n","Epoch 307, loss = 0.2558, val.acc = [0.6566, 0.7156, 0.7512, 0.7594]\n","Epoch 308, loss = 0.2080, val.acc = [0.6536, 0.7162, 0.7524, 0.76]\n","Epoch 309, loss = 0.2253, val.acc = [0.66, 0.7154, 0.753, 0.7618]\n","Epoch 310, loss = 0.2323, val.acc = [0.6544, 0.7132, 0.7522, 0.7578]\n","Epoch 311, loss = 0.2717, val.acc = [0.6388, 0.7058, 0.7504, 0.76]\n","Epoch 312, loss = 0.2487, val.acc = [0.6492, 0.7082, 0.7502, 0.7556]\n","Epoch 313, loss = 0.2680, val.acc = [0.6532, 0.7134, 0.7516, 0.7614]\n","Epoch 314, loss = 0.2108, val.acc = [0.6492, 0.7168, 0.7508, 0.7624]\n","Epoch 315, loss = 0.2388, val.acc = [0.645, 0.704, 0.75, 0.7592]\n","Epoch 316, loss = 0.2288, val.acc = [0.6548, 0.7148, 0.7518, 0.759]\n","Epoch 317, loss = 0.2269, val.acc = [0.645, 0.7116, 0.7558, 0.7592]\n","Epoch 318, loss = 0.2051, val.acc = [0.6518, 0.712, 0.752, 0.7586]\n","Epoch 319, loss = 0.1805, val.acc = [0.6384, 0.7128, 0.752, 0.7578]\n","Epoch 320, loss = 0.2105, val.acc = [0.6474, 0.7164, 0.7536, 0.758]\n","Epoch 321, loss = 0.2406, val.acc = [0.655, 0.7128, 0.753, 0.7578]\n","Epoch 322, loss = 0.2064, val.acc = [0.6554, 0.711, 0.7526, 0.7556]\n","Epoch 323, loss = 0.2684, val.acc = [0.647, 0.7082, 0.7486, 0.7618]\n","Epoch 324, loss = 0.2337, val.acc = [0.6508, 0.7108, 0.7494, 0.7586]\n","Epoch 325, loss = 0.2387, val.acc = [0.66, 0.7136, 0.7538, 0.7598]\n","Epoch 326, loss = 0.2028, val.acc = [0.6528, 0.7134, 0.7522, 0.7592]\n","Epoch 327, loss = 0.2087, val.acc = [0.6406, 0.7062, 0.7476, 0.7596]\n","Epoch 328, loss = 0.1726, val.acc = [0.6446, 0.7114, 0.7518, 0.7588]\n","Epoch 329, loss = 0.2212, val.acc = [0.6492, 0.716, 0.7468, 0.759]\n","Epoch 330, loss = 0.2242, val.acc = [0.6458, 0.7128, 0.7522, 0.7622]\n","Epoch 331, loss = 0.2542, val.acc = [0.6532, 0.7076, 0.75, 0.7614]\n","Epoch 332, loss = 0.2613, val.acc = [0.648, 0.7102, 0.75, 0.7628]\n","Epoch 333, loss = 0.2070, val.acc = [0.6526, 0.7106, 0.7484, 0.7608]\n","Epoch 334, loss = 0.1831, val.acc = [0.6438, 0.7112, 0.7526, 0.7626]\n","Epoch 335, loss = 0.2109, val.acc = [0.651, 0.7126, 0.7486, 0.7574]\n","Epoch 336, loss = 0.2206, val.acc = [0.6544, 0.7078, 0.7538, 0.7576]\n","Epoch 337, loss = 0.2380, val.acc = [0.6362, 0.7046, 0.7474, 0.755]\n","Epoch 338, loss = 0.1633, val.acc = [0.656, 0.7154, 0.7536, 0.7574]\n","Epoch 339, loss = 0.2337, val.acc = [0.6458, 0.7148, 0.7522, 0.7624]\n","Epoch 340, loss = 0.1905, val.acc = [0.6498, 0.7104, 0.7462, 0.7578]\n","Epoch 341, loss = 0.2173, val.acc = [0.6552, 0.712, 0.7522, 0.7604]\n","Epoch 342, loss = 0.2130, val.acc = [0.65, 0.7122, 0.7524, 0.758]\n","Epoch 343, loss = 0.2093, val.acc = [0.6442, 0.7106, 0.7556, 0.7608]\n","Epoch 344, loss = 0.2029, val.acc = [0.648, 0.7114, 0.7516, 0.76]\n","Epoch 345, loss = 0.1895, val.acc = [0.6378, 0.7128, 0.7506, 0.7612]\n","Epoch 346, loss = 0.1975, val.acc = [0.646, 0.7036, 0.7462, 0.7602]\n","Epoch 347, loss = 0.2081, val.acc = [0.6508, 0.7108, 0.7526, 0.7602]\n","Epoch 348, loss = 0.2135, val.acc = [0.6324, 0.708, 0.7544, 0.7592]\n","Epoch 349, loss = 0.2076, val.acc = [0.653, 0.7094, 0.7548, 0.7628]\n","Epoch 350, loss = 0.1863, val.acc = [0.6462, 0.7036, 0.7532, 0.759]\n","Epoch 351, loss = 0.1991, val.acc = [0.6324, 0.7126, 0.7492, 0.7564]\n","Epoch 352, loss = 0.1857, val.acc = [0.6502, 0.7112, 0.751, 0.7598]\n","Epoch 353, loss = 0.1791, val.acc = [0.6532, 0.7126, 0.7566, 0.758]\n","Epoch 354, loss = 0.1865, val.acc = [0.62, 0.6896, 0.743, 0.751]\n","Epoch 355, loss = 0.2169, val.acc = [0.652, 0.7014, 0.752, 0.762]\n","Epoch 356, loss = 0.1805, val.acc = [0.6422, 0.71, 0.755, 0.7606]\n","Epoch 357, loss = 0.1986, val.acc = [0.6496, 0.7134, 0.7528, 0.762]\n","Epoch 358, loss = 0.2062, val.acc = [0.6568, 0.7116, 0.753, 0.7584]\n","Epoch 359, loss = 0.1901, val.acc = [0.6468, 0.7108, 0.7498, 0.7578]\n","Epoch 360, loss = 0.1594, val.acc = [0.6408, 0.7122, 0.7486, 0.7608]\n","Epoch 361, loss = 0.2156, val.acc = [0.645, 0.7064, 0.7522, 0.7584]\n","Epoch 362, loss = 0.1946, val.acc = [0.6362, 0.7082, 0.7518, 0.7596]\n","Epoch 363, loss = 0.2383, val.acc = [0.6458, 0.7116, 0.7528, 0.761]\n","Epoch 364, loss = 0.1893, val.acc = [0.6502, 0.709, 0.753, 0.7604]\n","Epoch 365, loss = 0.1947, val.acc = [0.6412, 0.7066, 0.7474, 0.7594]\n","Epoch 366, loss = 0.2353, val.acc = [0.641, 0.7074, 0.7488, 0.755]\n","Epoch 367, loss = 0.1807, val.acc = [0.6492, 0.7082, 0.7532, 0.7588]\n","Epoch 368, loss = 0.1996, val.acc = [0.642, 0.709, 0.7526, 0.759]\n","Epoch 369, loss = 0.2166, val.acc = [0.6478, 0.7078, 0.7514, 0.757]\n","Epoch 370, loss = 0.1777, val.acc = [0.6544, 0.7084, 0.752, 0.7546]\n","Epoch 371, loss = 0.1799, val.acc = [0.6448, 0.7074, 0.7506, 0.763]\n","Epoch 372, loss = 0.2022, val.acc = [0.6484, 0.7086, 0.7544, 0.7592]\n","Epoch 373, loss = 0.1467, val.acc = [0.6408, 0.7094, 0.7546, 0.7622]\n","Epoch 374, loss = 0.1841, val.acc = [0.6482, 0.7108, 0.7526, 0.759]\n","Epoch 375, loss = 0.2261, val.acc = [0.652, 0.7114, 0.7566, 0.7608]\n","Epoch 376, loss = 0.1844, val.acc = [0.6364, 0.7076, 0.7554, 0.7608]\n","Epoch 377, loss = 0.2089, val.acc = [0.6482, 0.7094, 0.7516, 0.7638]\n","Epoch 378, loss = 0.1744, val.acc = [0.6516, 0.71, 0.7488, 0.7624]\n","Epoch 379, loss = 0.1753, val.acc = [0.6512, 0.707, 0.7552, 0.7586]\n","Epoch 380, loss = 0.2090, val.acc = [0.6536, 0.7046, 0.7542, 0.762]\n","Epoch 381, loss = 0.1330, val.acc = [0.6516, 0.706, 0.7524, 0.7602]\n","Epoch 382, loss = 0.1765, val.acc = [0.6476, 0.7082, 0.7518, 0.7594]\n","Epoch 383, loss = 0.1959, val.acc = [0.6492, 0.7112, 0.7554, 0.7574]\n","Epoch 384, loss = 0.1950, val.acc = [0.6402, 0.7096, 0.7522, 0.7608]\n","Epoch 385, loss = 0.1955, val.acc = [0.643, 0.7088, 0.756, 0.7612]\n","Epoch 386, loss = 0.2139, val.acc = [0.6418, 0.7008, 0.7494, 0.7552]\n","Epoch 387, loss = 0.1840, val.acc = [0.646, 0.7082, 0.7538, 0.7602]\n","Epoch 388, loss = 0.2063, val.acc = [0.6548, 0.709, 0.7512, 0.7616]\n","Epoch 389, loss = 0.1847, val.acc = [0.6446, 0.7076, 0.754, 0.7584]\n","Epoch 390, loss = 0.1961, val.acc = [0.6492, 0.705, 0.7494, 0.7604]\n","Epoch 391, loss = 0.1725, val.acc = [0.6438, 0.7124, 0.7562, 0.7628]\n","Epoch 392, loss = 0.1810, val.acc = [0.64, 0.7096, 0.7546, 0.7616]\n","Epoch 393, loss = 0.1671, val.acc = [0.6474, 0.709, 0.7548, 0.7604]\n","Epoch 394, loss = 0.1639, val.acc = [0.6446, 0.707, 0.7502, 0.759]\n","Epoch 395, loss = 0.1844, val.acc = [0.6452, 0.706, 0.7522, 0.7606]\n","Epoch 396, loss = 0.1746, val.acc = [0.6442, 0.7104, 0.755, 0.7618]\n","Epoch 397, loss = 0.1693, val.acc = [0.649, 0.7088, 0.7526, 0.757]\n","Epoch 398, loss = 0.1975, val.acc = [0.6314, 0.704, 0.7546, 0.7606]\n","Epoch 399, loss = 0.1700, val.acc = [0.6494, 0.7068, 0.753, 0.7608]\n","Rep: 5, te.acc = [0.6366, 0.6984, 0.7344, 0.7487]\n","\n","All reps test.acc:\n","[0.6347, 0.6957, 0.7417, 0.7521]\n","[0.6279, 0.6932, 0.7397, 0.754]\n","[0.6355, 0.6965, 0.7354, 0.746]\n","[0.6416, 0.6936, 0.7406, 0.753]\n","[0.6366, 0.6984, 0.7344, 0.7487]\n"],"name":"stdout"}]}]}